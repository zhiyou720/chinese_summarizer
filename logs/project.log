[2020-07-21 11:51:07,157 INFO] Device ID 0
[2020-07-21 11:51:07,157 INFO] Device cuda
[2020-07-21 11:51:08,016 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to C:\Users\VY\AppData\Local\Temp\tmpuoyro7js
[2020-07-21 11:53:08,669 INFO] Device ID 0
[2020-07-21 11:53:08,669 INFO] Device cuda
[2020-07-21 11:53:09,639 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to C:\Users\VY\AppData\Local\Temp\tmpozxm2ato
[2020-07-21 12:03:33,773 INFO] Device ID 0
[2020-07-21 12:03:33,773 INFO] Device cuda
[2020-07-21 12:03:34,879 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to C:\Users\VY\AppData\Local\Temp\tmpstaz4yox
[2020-07-21 12:04:33,500 INFO] Device ID 0
[2020-07-21 12:04:33,500 INFO] Device cuda
[2020-07-21 12:04:34,367 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to C:\Users\VY\AppData\Local\Temp\tmptkqa4izq
[2020-07-21 12:05:44,031 INFO] Device ID 0
[2020-07-21 12:05:44,031 INFO] Device cuda
[2020-07-21 12:05:44,060 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:05:44,061 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:08:43,679 INFO] Device ID 0
[2020-07-21 12:08:43,679 INFO] Device cuda
[2020-07-21 12:08:43,706 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:08:43,707 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:09:21,868 INFO] Device ID 0
[2020-07-21 12:09:21,868 INFO] Device cuda
[2020-07-21 12:09:21,891 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:09:21,891 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:09:23,904 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:09:23,914 INFO] * number of parameters: 113297921
[2020-07-21 12:10:37,153 INFO] Device ID 0
[2020-07-21 12:10:37,153 INFO] Device cuda
[2020-07-21 12:10:37,181 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:10:37,181 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:10:39,204 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:10:39,214 INFO] * number of parameters: 113297921
[2020-07-21 12:11:18,010 INFO] Device ID 0
[2020-07-21 12:11:18,010 INFO] Device cuda
[2020-07-21 12:11:18,033 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:11:18,034 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:11:20,113 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:11:20,122 INFO] * number of parameters: 113297921
[2020-07-21 12:12:05,346 INFO] Device ID 0
[2020-07-21 12:12:05,346 INFO] Device cuda
[2020-07-21 12:12:05,373 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:12:05,373 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:12:07,389 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:12:07,399 INFO] * number of parameters: 113297921
[2020-07-21 12:12:48,785 INFO] Device ID 0
[2020-07-21 12:12:48,785 INFO] Device cuda
[2020-07-21 12:12:48,809 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:12:48,809 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:12:50,821 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:12:50,830 INFO] * number of parameters: 113297921
[2020-07-21 12:13:26,979 INFO] Device ID 0
[2020-07-21 12:13:26,979 INFO] Device cuda
[2020-07-21 12:13:27,002 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:13:27,002 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:13:29,026 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:13:29,036 INFO] * number of parameters: 113297921
[2020-07-21 12:13:29,052 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.20.bert.pt, number of examples: 862
[2020-07-21 12:13:29,053 INFO] Start training...
[2020-07-21 12:15:14,581 INFO] Device ID 0
[2020-07-21 12:15:14,581 INFO] Device cuda
[2020-07-21 12:15:14,605 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-21 12:15:14,605 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-21 12:15:16,666 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 12:15:16,674 INFO] * number of parameters: 113297921
[2020-07-21 12:15:16,674 INFO] Start training...
[2020-07-21 12:15:16,686 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.20.bert.pt, number of examples: 862
[2020-07-21 12:15:31,097 INFO] Step 50/50000; xent: 1.28; lr: 0.0000001; 103 docs/s;     14 sec
[2020-07-21 12:15:33,381 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.607.bert.pt, number of examples: 733
[2020-07-21 12:15:44,993 INFO] Step 100/50000; xent: 0.70; lr: 0.0000003; 109 docs/s;     28 sec
[2020-07-21 12:15:46,688 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.609.bert.pt, number of examples: 772
[2020-07-21 12:15:58,591 INFO] Step 150/50000; xent: 0.67; lr: 0.0000004; 110 docs/s;     42 sec
[2020-07-21 12:16:00,788 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.168.bert.pt, number of examples: 937
[2020-07-21 15:01:14,360 INFO] Device ID 0
[2020-07-21 15:01:14,360 INFO] Device cuda
[2020-07-21 15:01:14,385 INFO] Loading checkpoint from ./models/model_step_50000.pt
[2020-07-21 15:01:55,576 INFO] Device ID 0
[2020-07-21 15:01:55,577 INFO] Device cuda
[2020-07-21 15:01:55,599 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:03:00,061 INFO] Device ID 0
[2020-07-21 15:03:00,061 INFO] Device cuda
[2020-07-21 15:03:00,087 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:04:05,892 INFO] Device ID 0
[2020-07-21 15:04:05,892 INFO] Device cuda
[2020-07-21 15:04:05,915 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:06:59,319 INFO] Device ID 0
[2020-07-21 15:06:59,319 INFO] Device cuda
[2020-07-21 15:06:59,345 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:08:58,398 INFO] Device ID 0
[2020-07-21 15:08:58,398 INFO] Device cuda
[2020-07-21 15:08:58,426 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:09:29,877 INFO] Device ID 0
[2020-07-21 15:09:29,877 INFO] Device cuda
[2020-07-21 15:09:29,907 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:09:32,106 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:09:32,109 INFO] * number of parameters: 113297921
[2020-07-21 15:09:37,050 INFO] Loading test dataset from ./data/oov_data\vy_text.test.1.bert.pt, number of examples: 1047
[2020-07-21 15:09:42,700 INFO] Loading test dataset from ./data/oov_data\vy_text.test.10.bert.pt, number of examples: 1207
[2020-07-21 15:09:48,945 INFO] Loading test dataset from ./data/oov_data\vy_text.test.11.bert.pt, number of examples: 738
[2020-07-21 15:09:52,772 INFO] Loading test dataset from ./data/oov_data\vy_text.test.12.bert.pt, number of examples: 936
[2020-07-21 15:09:57,635 INFO] Loading test dataset from ./data/oov_data\vy_text.test.13.bert.pt, number of examples: 973
[2020-07-21 15:10:02,683 INFO] Loading test dataset from ./data/oov_data\vy_text.test.14.bert.pt, number of examples: 927
[2020-07-21 15:10:07,522 INFO] Loading test dataset from ./data/oov_data\vy_text.test.15.bert.pt, number of examples: 974
[2020-07-21 15:10:12,602 INFO] Loading test dataset from ./data/oov_data\vy_text.test.16.bert.pt, number of examples: 1065
[2020-07-21 15:10:18,108 INFO] Loading test dataset from ./data/oov_data\vy_text.test.17.bert.pt, number of examples: 1047
[2020-07-21 15:10:23,590 INFO] Loading test dataset from ./data/oov_data\vy_text.test.18.bert.pt, number of examples: 1016
[2020-07-21 15:10:28,909 INFO] Loading test dataset from ./data/oov_data\vy_text.test.19.bert.pt, number of examples: 843
[2020-07-21 15:10:33,310 INFO] Loading test dataset from ./data/oov_data\vy_text.test.2.bert.pt, number of examples: 1150
[2020-07-21 15:10:39,339 INFO] Loading test dataset from ./data/oov_data\vy_text.test.20.bert.pt, number of examples: 1115
[2020-07-21 15:10:45,134 INFO] Loading test dataset from ./data/oov_data\vy_text.test.21.bert.pt, number of examples: 1001
[2020-07-21 15:10:50,355 INFO] Loading test dataset from ./data/oov_data\vy_text.test.22.bert.pt, number of examples: 992
[2020-07-21 15:10:55,586 INFO] Loading test dataset from ./data/oov_data\vy_text.test.23.bert.pt, number of examples: 1345
[2020-07-21 15:11:02,569 INFO] Loading test dataset from ./data/oov_data\vy_text.test.24.bert.pt, number of examples: 992
[2020-07-21 15:11:07,797 INFO] Loading test dataset from ./data/oov_data\vy_text.test.25.bert.pt, number of examples: 1133
[2020-07-21 15:11:13,676 INFO] Loading test dataset from ./data/oov_data\vy_text.test.26.bert.pt, number of examples: 1030
[2020-07-21 15:11:18,997 INFO] Loading test dataset from ./data/oov_data\vy_text.test.27.bert.pt, number of examples: 1015
[2020-07-21 15:11:24,291 INFO] Loading test dataset from ./data/oov_data\vy_text.test.28.bert.pt, number of examples: 905
[2020-07-21 15:11:28,988 INFO] Loading test dataset from ./data/oov_data\vy_text.test.29.bert.pt, number of examples: 988
[2020-07-21 15:11:34,202 INFO] Loading test dataset from ./data/oov_data\vy_text.test.3.bert.pt, number of examples: 1058
[2020-07-21 15:11:39,716 INFO] Loading test dataset from ./data/oov_data\vy_text.test.30.bert.pt, number of examples: 940
[2020-07-21 15:11:44,613 INFO] Loading test dataset from ./data/oov_data\vy_text.test.31.bert.pt, number of examples: 896
[2020-07-21 15:11:49,359 INFO] Loading test dataset from ./data/oov_data\vy_text.test.32.bert.pt, number of examples: 875
[2020-07-21 15:11:53,952 INFO] Loading test dataset from ./data/oov_data\vy_text.test.33.bert.pt, number of examples: 955
[2020-07-21 15:11:58,983 INFO] Loading test dataset from ./data/oov_data\vy_text.test.34.bert.pt, number of examples: 937
[2020-07-21 15:12:03,899 INFO] Loading test dataset from ./data/oov_data\vy_text.test.35.bert.pt, number of examples: 1353
[2020-07-21 15:12:10,980 INFO] Loading test dataset from ./data/oov_data\vy_text.test.36.bert.pt, number of examples: 1201
[2020-07-21 15:12:17,262 INFO] Loading test dataset from ./data/oov_data\vy_text.test.37.bert.pt, number of examples: 903
[2020-07-21 15:12:22,108 INFO] Loading test dataset from ./data/oov_data\vy_text.test.38.bert.pt, number of examples: 1040
[2020-07-21 15:12:27,568 INFO] Loading test dataset from ./data/oov_data\vy_text.test.39.bert.pt, number of examples: 1214
[2020-07-21 15:12:33,889 INFO] Loading test dataset from ./data/oov_data\vy_text.test.4.bert.pt, number of examples: 1027
[2020-07-21 15:12:39,284 INFO] Loading test dataset from ./data/oov_data\vy_text.test.40.bert.pt, number of examples: 1136
[2020-07-21 15:12:45,254 INFO] Loading test dataset from ./data/oov_data\vy_text.test.41.bert.pt, number of examples: 981
[2020-07-21 15:12:50,384 INFO] Loading test dataset from ./data/oov_data\vy_text.test.42.bert.pt, number of examples: 1015
[2020-07-21 15:12:55,765 INFO] Loading test dataset from ./data/oov_data\vy_text.test.43.bert.pt, number of examples: 1178
[2020-07-21 15:13:01,992 INFO] Loading test dataset from ./data/oov_data\vy_text.test.44.bert.pt, number of examples: 870
[2020-07-21 15:13:06,600 INFO] Loading test dataset from ./data/oov_data\vy_text.test.45.bert.pt, number of examples: 934
[2020-07-21 15:13:11,507 INFO] Loading test dataset from ./data/oov_data\vy_text.test.46.bert.pt, number of examples: 934
[2020-07-21 15:13:16,433 INFO] Loading test dataset from ./data/oov_data\vy_text.test.47.bert.pt, number of examples: 1064
[2020-07-21 15:13:21,986 INFO] Loading test dataset from ./data/oov_data\vy_text.test.48.bert.pt, number of examples: 1013
[2020-07-21 15:13:27,299 INFO] Loading test dataset from ./data/oov_data\vy_text.test.49.bert.pt, number of examples: 1116
[2020-07-21 15:17:18,613 INFO] Device ID 0
[2020-07-21 15:17:18,614 INFO] Device cuda
[2020-07-21 15:17:18,644 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:17:20,840 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:17:20,843 INFO] * number of parameters: 113297921
[2020-07-21 15:17:25,659 INFO] Loading test dataset from ./data/oov_data\vy_text.test.1.bert.pt, number of examples: 1047
[2020-07-21 15:17:31,159 INFO] Loading test dataset from ./data/oov_data\vy_text.test.10.bert.pt, number of examples: 1207
[2020-07-21 15:17:37,652 INFO] Loading test dataset from ./data/oov_data\vy_text.test.11.bert.pt, number of examples: 738
[2020-07-21 15:17:41,600 INFO] Loading test dataset from ./data/oov_data\vy_text.test.12.bert.pt, number of examples: 936
[2020-07-21 15:17:46,525 INFO] Loading test dataset from ./data/oov_data\vy_text.test.13.bert.pt, number of examples: 973
[2020-07-21 15:17:51,663 INFO] Loading test dataset from ./data/oov_data\vy_text.test.14.bert.pt, number of examples: 927
[2020-07-21 15:17:56,585 INFO] Loading test dataset from ./data/oov_data\vy_text.test.15.bert.pt, number of examples: 974
[2020-07-21 15:18:01,731 INFO] Loading test dataset from ./data/oov_data\vy_text.test.16.bert.pt, number of examples: 1065
[2020-07-21 15:18:07,299 INFO] Loading test dataset from ./data/oov_data\vy_text.test.17.bert.pt, number of examples: 1047
[2020-07-21 15:18:12,974 INFO] Loading test dataset from ./data/oov_data\vy_text.test.18.bert.pt, number of examples: 1016
[2020-07-21 15:18:18,313 INFO] Loading test dataset from ./data/oov_data\vy_text.test.19.bert.pt, number of examples: 843
[2020-07-21 15:18:22,739 INFO] Loading test dataset from ./data/oov_data\vy_text.test.2.bert.pt, number of examples: 1150
[2020-07-21 15:18:28,812 INFO] Loading test dataset from ./data/oov_data\vy_text.test.20.bert.pt, number of examples: 1115
[2020-07-21 15:18:34,687 INFO] Loading test dataset from ./data/oov_data\vy_text.test.21.bert.pt, number of examples: 1001
[2020-07-21 15:18:39,925 INFO] Loading test dataset from ./data/oov_data\vy_text.test.22.bert.pt, number of examples: 992
[2020-07-21 15:18:45,228 INFO] Loading test dataset from ./data/oov_data\vy_text.test.23.bert.pt, number of examples: 1345
[2020-07-21 15:18:52,293 INFO] Loading test dataset from ./data/oov_data\vy_text.test.24.bert.pt, number of examples: 992
[2020-07-21 15:18:57,549 INFO] Loading test dataset from ./data/oov_data\vy_text.test.25.bert.pt, number of examples: 1133
[2020-07-21 15:19:03,529 INFO] Loading test dataset from ./data/oov_data\vy_text.test.26.bert.pt, number of examples: 1030
[2020-07-21 15:19:09,034 INFO] Loading test dataset from ./data/oov_data\vy_text.test.27.bert.pt, number of examples: 1015
[2020-07-21 15:19:14,493 INFO] Loading test dataset from ./data/oov_data\vy_text.test.28.bert.pt, number of examples: 905
[2020-07-21 15:19:19,343 INFO] Loading test dataset from ./data/oov_data\vy_text.test.29.bert.pt, number of examples: 988
[2020-07-21 15:19:24,705 INFO] Loading test dataset from ./data/oov_data\vy_text.test.3.bert.pt, number of examples: 1058
[2020-07-21 15:19:30,485 INFO] Loading test dataset from ./data/oov_data\vy_text.test.30.bert.pt, number of examples: 940
[2020-07-21 15:19:35,598 INFO] Loading test dataset from ./data/oov_data\vy_text.test.31.bert.pt, number of examples: 896
[2020-07-21 15:19:40,502 INFO] Loading test dataset from ./data/oov_data\vy_text.test.32.bert.pt, number of examples: 875
[2020-07-21 15:19:45,220 INFO] Loading test dataset from ./data/oov_data\vy_text.test.33.bert.pt, number of examples: 955
[2020-07-21 15:19:50,345 INFO] Loading test dataset from ./data/oov_data\vy_text.test.34.bert.pt, number of examples: 937
[2020-07-21 15:19:55,403 INFO] Loading test dataset from ./data/oov_data\vy_text.test.35.bert.pt, number of examples: 1353
[2020-07-21 15:20:02,729 INFO] Loading test dataset from ./data/oov_data\vy_text.test.36.bert.pt, number of examples: 1201
[2020-07-21 15:20:09,115 INFO] Loading test dataset from ./data/oov_data\vy_text.test.37.bert.pt, number of examples: 903
[2020-07-21 15:20:14,015 INFO] Loading test dataset from ./data/oov_data\vy_text.test.38.bert.pt, number of examples: 1040
[2020-07-21 15:20:19,639 INFO] Loading test dataset from ./data/oov_data\vy_text.test.39.bert.pt, number of examples: 1214
[2020-07-21 15:20:26,208 INFO] Loading test dataset from ./data/oov_data\vy_text.test.4.bert.pt, number of examples: 1027
[2020-07-21 15:20:31,681 INFO] Loading test dataset from ./data/oov_data\vy_text.test.40.bert.pt, number of examples: 1136
[2020-07-21 15:20:37,732 INFO] Loading test dataset from ./data/oov_data\vy_text.test.41.bert.pt, number of examples: 981
[2020-07-21 15:20:42,898 INFO] Loading test dataset from ./data/oov_data\vy_text.test.42.bert.pt, number of examples: 1015
[2020-07-21 15:20:48,315 INFO] Loading test dataset from ./data/oov_data\vy_text.test.43.bert.pt, number of examples: 1178
[2020-07-21 15:20:54,613 INFO] Loading test dataset from ./data/oov_data\vy_text.test.44.bert.pt, number of examples: 870
[2020-07-21 15:20:59,256 INFO] Loading test dataset from ./data/oov_data\vy_text.test.45.bert.pt, number of examples: 934
[2020-07-21 15:21:04,267 INFO] Loading test dataset from ./data/oov_data\vy_text.test.46.bert.pt, number of examples: 934
[2020-07-21 15:21:09,188 INFO] Loading test dataset from ./data/oov_data\vy_text.test.47.bert.pt, number of examples: 1064
[2020-07-21 15:21:14,757 INFO] Loading test dataset from ./data/oov_data\vy_text.test.48.bert.pt, number of examples: 1013
[2020-07-21 15:21:20,081 INFO] Loading test dataset from ./data/oov_data\vy_text.test.5.bert.pt, number of examples: 835
[2020-07-21 15:21:24,448 INFO] Loading test dataset from ./data/oov_data\vy_text.test.50.bert.pt, number of examples: 1117
[2020-07-21 15:21:30,287 INFO] Loading test dataset from ./data/oov_data\vy_text.test.51.bert.pt, number of examples: 1049
[2020-07-21 15:21:35,799 INFO] Loading test dataset from ./data/oov_data\vy_text.test.52.bert.pt, number of examples: 1220
[2020-07-21 15:21:42,230 INFO] Loading test dataset from ./data/oov_data\vy_text.test.53.bert.pt, number of examples: 934
[2020-07-21 15:21:47,134 INFO] Loading test dataset from ./data/oov_data\vy_text.test.54.bert.pt, number of examples: 1177
[2020-07-21 15:22:37,175 INFO] Device ID 0
[2020-07-21 15:22:37,175 INFO] Device cuda
[2020-07-21 15:22:37,199 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:22:39,400 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:22:39,404 INFO] * number of parameters: 113297921
[2020-07-21 15:22:44,355 INFO] Loading test dataset from ./data/oov_data\vy_text.test.1.bert.pt, number of examples: 1047
[2020-07-21 15:22:49,880 INFO] Loading test dataset from ./data/oov_data\vy_text.test.10.bert.pt, number of examples: 1207
[2020-07-21 15:22:56,235 INFO] Loading test dataset from ./data/oov_data\vy_text.test.11.bert.pt, number of examples: 738
[2020-07-21 15:23:00,165 INFO] Loading test dataset from ./data/oov_data\vy_text.test.12.bert.pt, number of examples: 936
[2020-07-21 15:23:05,164 INFO] Loading test dataset from ./data/oov_data\vy_text.test.13.bert.pt, number of examples: 973
[2020-07-21 15:23:10,356 INFO] Loading test dataset from ./data/oov_data\vy_text.test.14.bert.pt, number of examples: 927
[2020-07-21 15:23:15,333 INFO] Loading test dataset from ./data/oov_data\vy_text.test.15.bert.pt, number of examples: 974
[2020-07-21 15:23:20,547 INFO] Loading test dataset from ./data/oov_data\vy_text.test.16.bert.pt, number of examples: 1065
[2020-07-21 15:23:26,208 INFO] Loading test dataset from ./data/oov_data\vy_text.test.17.bert.pt, number of examples: 1047
[2020-07-21 15:23:31,863 INFO] Loading test dataset from ./data/oov_data\vy_text.test.18.bert.pt, number of examples: 1016
[2020-07-21 15:23:37,291 INFO] Loading test dataset from ./data/oov_data\vy_text.test.19.bert.pt, number of examples: 843
[2020-07-21 15:23:41,761 INFO] Loading test dataset from ./data/oov_data\vy_text.test.2.bert.pt, number of examples: 1150
[2020-07-21 15:23:47,875 INFO] Loading test dataset from ./data/oov_data\vy_text.test.20.bert.pt, number of examples: 1115
[2020-07-21 15:23:53,797 INFO] Loading test dataset from ./data/oov_data\vy_text.test.21.bert.pt, number of examples: 1001
[2020-07-21 15:23:59,106 INFO] Loading test dataset from ./data/oov_data\vy_text.test.22.bert.pt, number of examples: 992
[2020-07-21 15:24:04,520 INFO] Loading test dataset from ./data/oov_data\vy_text.test.23.bert.pt, number of examples: 1345
[2020-07-21 15:24:11,717 INFO] Loading test dataset from ./data/oov_data\vy_text.test.24.bert.pt, number of examples: 992
[2020-07-21 15:24:17,005 INFO] Loading test dataset from ./data/oov_data\vy_text.test.25.bert.pt, number of examples: 1133
[2020-07-21 15:24:22,971 INFO] Loading test dataset from ./data/oov_data\vy_text.test.26.bert.pt, number of examples: 1030
[2020-07-21 15:24:28,421 INFO] Loading test dataset from ./data/oov_data\vy_text.test.27.bert.pt, number of examples: 1015
[2020-07-21 15:24:33,819 INFO] Loading test dataset from ./data/oov_data\vy_text.test.28.bert.pt, number of examples: 905
[2020-07-21 15:24:38,756 INFO] Loading test dataset from ./data/oov_data\vy_text.test.29.bert.pt, number of examples: 988
[2020-07-21 15:24:44,222 INFO] Loading test dataset from ./data/oov_data\vy_text.test.3.bert.pt, number of examples: 1058
[2020-07-21 15:24:49,882 INFO] Loading test dataset from ./data/oov_data\vy_text.test.30.bert.pt, number of examples: 940
[2020-07-21 15:24:54,870 INFO] Loading test dataset from ./data/oov_data\vy_text.test.31.bert.pt, number of examples: 896
[2020-07-21 15:24:59,649 INFO] Loading test dataset from ./data/oov_data\vy_text.test.32.bert.pt, number of examples: 875
[2020-07-21 15:25:04,265 INFO] Loading test dataset from ./data/oov_data\vy_text.test.33.bert.pt, number of examples: 955
[2020-07-21 15:25:09,311 INFO] Loading test dataset from ./data/oov_data\vy_text.test.34.bert.pt, number of examples: 937
[2020-07-21 15:25:14,255 INFO] Loading test dataset from ./data/oov_data\vy_text.test.35.bert.pt, number of examples: 1353
[2020-07-21 15:25:21,349 INFO] Loading test dataset from ./data/oov_data\vy_text.test.36.bert.pt, number of examples: 1201
[2020-07-21 15:25:27,733 INFO] Loading test dataset from ./data/oov_data\vy_text.test.37.bert.pt, number of examples: 903
[2020-07-21 15:25:32,590 INFO] Loading test dataset from ./data/oov_data\vy_text.test.38.bert.pt, number of examples: 1040
[2020-07-21 15:25:38,075 INFO] Loading test dataset from ./data/oov_data\vy_text.test.39.bert.pt, number of examples: 1214
[2020-07-21 15:25:44,422 INFO] Loading test dataset from ./data/oov_data\vy_text.test.4.bert.pt, number of examples: 1027
[2020-07-21 15:25:49,840 INFO] Loading test dataset from ./data/oov_data\vy_text.test.40.bert.pt, number of examples: 1136
[2020-07-21 15:25:55,826 INFO] Loading test dataset from ./data/oov_data\vy_text.test.41.bert.pt, number of examples: 981
[2020-07-21 15:26:00,977 INFO] Loading test dataset from ./data/oov_data\vy_text.test.42.bert.pt, number of examples: 1015
[2020-07-21 15:26:06,379 INFO] Loading test dataset from ./data/oov_data\vy_text.test.43.bert.pt, number of examples: 1178
[2020-07-21 15:26:12,620 INFO] Loading test dataset from ./data/oov_data\vy_text.test.44.bert.pt, number of examples: 870
[2020-07-21 15:26:17,222 INFO] Loading test dataset from ./data/oov_data\vy_text.test.45.bert.pt, number of examples: 934
[2020-07-21 15:26:22,119 INFO] Loading test dataset from ./data/oov_data\vy_text.test.46.bert.pt, number of examples: 934
[2020-07-21 15:26:27,035 INFO] Loading test dataset from ./data/oov_data\vy_text.test.47.bert.pt, number of examples: 1064
[2020-07-21 15:26:32,578 INFO] Loading test dataset from ./data/oov_data\vy_text.test.48.bert.pt, number of examples: 1013
[2020-07-21 15:26:37,875 INFO] Loading test dataset from ./data/oov_data\vy_text.test.5.bert.pt, number of examples: 835
[2020-07-21 15:26:42,236 INFO] Loading test dataset from ./data/oov_data\vy_text.test.50.bert.pt, number of examples: 1117
[2020-07-21 15:26:48,074 INFO] Loading test dataset from ./data/oov_data\vy_text.test.51.bert.pt, number of examples: 1049
[2020-07-21 15:26:53,589 INFO] Loading test dataset from ./data/oov_data\vy_text.test.52.bert.pt, number of examples: 1220
[2020-07-21 15:27:00,025 INFO] Loading test dataset from ./data/oov_data\vy_text.test.53.bert.pt, number of examples: 934
[2020-07-21 15:27:04,924 INFO] Loading test dataset from ./data/oov_data\vy_text.test.55.bert.pt, number of examples: 1071
[2020-07-21 15:27:10,526 INFO] Loading test dataset from ./data/oov_data\vy_text.test.56.bert.pt, number of examples: 746
[2020-07-21 15:27:14,416 INFO] Loading test dataset from ./data/oov_data\vy_text.test.6.bert.pt, number of examples: 948
[2020-07-21 15:27:19,377 INFO] Loading test dataset from ./data/oov_data\vy_text.test.7.bert.pt, number of examples: 997
[2020-07-21 15:27:24,609 INFO] Loading test dataset from ./data/oov_data\vy_text.test.9.bert.pt, number of examples: 1083
[2020-07-21 15:27:54,781 INFO] Writing summaries.
[2020-07-21 15:27:54,781 INFO] Processing summaries. Saving system files to ./temp/tmpooq5nlwk\system and model files to ./temp/tmpooq5nlwk\model.
[2020-07-21 15:27:54,781 INFO] Processing files in ./temp/rouge-tmp-2020-07-21-15-27-30/candidate/.
[2020-07-21 15:28:21,426 INFO] Saved processed files to ./temp/tmpooq5nlwk\system.
[2020-07-21 15:28:21,427 INFO] Processing files in ./temp/rouge-tmp-2020-07-21-15-27-30/reference/.
[2020-07-21 15:28:48,898 INFO] Saved processed files to ./temp/tmpooq5nlwk\model.
[2020-07-21 15:28:49,247 INFO] Written ROUGE configuration to ./temp/tmpvfxonln2\rouge_conf.xml
[2020-07-21 15:28:49,247 INFO] Running ROUGE with command C:\Users\VY\Desktop\Project\pyrouge\evaluation\ROUGE-RELEASE-1.5.5\ROUGE-1.5.5.pl -e C:\Users\VY\Desktop\Project\pyrouge\evaluation\ROUGE-RELEASE-1.5.5\data -c 95 -m -r 1000 -n 2 -a ./temp/tmpvfxonln2\rouge_conf.xml
[2020-07-21 15:40:26,750 INFO] Device ID 0
[2020-07-21 15:40:26,750 INFO] Device cuda
[2020-07-21 15:40:26,774 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:40:28,951 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:40:28,954 INFO] * number of parameters: 113297921
[2020-07-21 15:41:04,291 INFO] Device ID 0
[2020-07-21 15:41:04,291 INFO] Device cuda
[2020-07-21 15:41:04,316 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:41:06,549 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:41:06,552 INFO] * number of parameters: 113297921
[2020-07-21 15:51:33,939 INFO] Device ID 0
[2020-07-21 15:51:33,939 INFO] Device cuda
[2020-07-21 15:51:33,962 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:51:36,273 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:51:36,277 INFO] * number of parameters: 113297921
[2020-07-21 15:57:47,390 INFO] Device ID 0
[2020-07-21 15:57:47,390 INFO] Device cuda
[2020-07-21 15:57:47,415 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:57:49,645 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:57:49,649 INFO] * number of parameters: 113297921
[2020-07-21 15:57:59,455 INFO] Device ID 0
[2020-07-21 15:57:59,455 INFO] Device cuda
[2020-07-21 15:57:59,484 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:58:01,695 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:58:01,699 INFO] * number of parameters: 113297921
[2020-07-21 15:59:14,940 INFO] Device ID 0
[2020-07-21 15:59:14,940 INFO] Device cuda
[2020-07-21 15:59:14,963 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:59:17,158 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:59:17,161 INFO] * number of parameters: 113297921
[2020-07-21 15:59:26,275 INFO] Device ID 0
[2020-07-21 15:59:26,275 INFO] Device cuda
[2020-07-21 15:59:26,299 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:59:28,532 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:59:28,535 INFO] * number of parameters: 113297921
[2020-07-21 15:59:38,668 INFO] Device ID 0
[2020-07-21 15:59:38,669 INFO] Device cuda
[2020-07-21 15:59:38,691 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:59:40,890 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:59:40,893 INFO] * number of parameters: 113297921
[2020-07-21 15:59:53,170 INFO] Device ID 0
[2020-07-21 15:59:53,170 INFO] Device cuda
[2020-07-21 15:59:53,193 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 15:59:55,427 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 15:59:55,431 INFO] * number of parameters: 113297921
[2020-07-21 16:03:08,476 INFO] Device ID 0
[2020-07-21 16:03:08,476 INFO] Device cuda
[2020-07-21 16:03:08,499 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:03:10,747 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:03:10,750 INFO] * number of parameters: 113297921
[2020-07-21 16:03:38,284 INFO] Device ID 0
[2020-07-21 16:03:38,284 INFO] Device cuda
[2020-07-21 16:03:38,307 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:03:40,574 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:03:40,577 INFO] * number of parameters: 113297921
[2020-07-21 16:32:52,185 INFO] Device ID 0
[2020-07-21 16:32:52,185 INFO] Device cuda
[2020-07-21 16:32:52,211 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:32:54,454 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:32:54,458 INFO] * number of parameters: 113297921
[2020-07-21 16:33:03,227 INFO] Device ID 0
[2020-07-21 16:33:03,227 INFO] Device cuda
[2020-07-21 16:33:03,250 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:33:05,471 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:33:05,474 INFO] * number of parameters: 113297921
[2020-07-21 16:33:30,928 INFO] Device ID 0
[2020-07-21 16:33:30,928 INFO] Device cuda
[2020-07-21 16:33:30,951 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:33:33,178 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:33:33,181 INFO] * number of parameters: 113297921
[2020-07-21 16:35:15,386 INFO] Device ID 0
[2020-07-21 16:35:15,386 INFO] Device cuda
[2020-07-21 16:35:15,408 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:35:17,677 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:35:17,688 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:35:17,692 INFO] * number of parameters: 113297921
[2020-07-21 16:37:11,125 INFO] Device ID 0
[2020-07-21 16:37:11,126 INFO] Device cuda
[2020-07-21 16:37:11,151 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:37:13,386 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:37:13,398 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:37:13,402 INFO] * number of parameters: 113297921
[2020-07-21 16:37:22,805 INFO] Device ID 0
[2020-07-21 16:37:22,806 INFO] Device cuda
[2020-07-21 16:37:22,830 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:37:25,050 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:37:25,065 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:37:25,068 INFO] * number of parameters: 113297921
[2020-07-21 16:37:44,684 INFO] Device ID 0
[2020-07-21 16:37:44,684 INFO] Device cuda
[2020-07-21 16:37:44,708 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:37:46,901 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:37:46,914 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:37:46,917 INFO] * number of parameters: 113297921
[2020-07-21 16:38:18,599 INFO] Device ID 0
[2020-07-21 16:38:18,599 INFO] Device cuda
[2020-07-21 16:38:18,623 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:38:20,859 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:38:20,874 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:38:20,877 INFO] * number of parameters: 113297921
[2020-07-21 16:38:50,338 INFO] Device ID 0
[2020-07-21 16:38:50,338 INFO] Device cuda
[2020-07-21 16:38:50,365 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:38:52,603 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:38:52,615 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:38:52,618 INFO] * number of parameters: 113297921
[2020-07-21 16:39:43,569 INFO] Device ID 0
[2020-07-21 16:39:43,569 INFO] Device cuda
[2020-07-21 16:39:43,592 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:39:45,854 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:39:45,867 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:39:45,870 INFO] * number of parameters: 113297921
[2020-07-21 16:40:31,396 INFO] Device ID 0
[2020-07-21 16:40:31,397 INFO] Device cuda
[2020-07-21 16:40:31,421 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:40:33,676 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-21 16:40:33,688 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:40:33,692 INFO] * number of parameters: 113297921
[2020-07-21 16:44:51,533 INFO] Device ID 0
[2020-07-21 16:44:51,534 INFO] Device cuda
[2020-07-21 16:44:51,556 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:44:53,788 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:44:53,791 INFO] * number of parameters: 113297921
[2020-07-21 16:50:43,628 INFO] Device ID 0
[2020-07-21 16:50:43,628 INFO] Device cuda
[2020-07-21 16:50:43,652 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:50:45,904 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:50:45,941 INFO] * number of parameters: 113297921
[2020-07-21 16:51:24,599 INFO] Device ID 0
[2020-07-21 16:51:24,599 INFO] Device cuda
[2020-07-21 16:51:24,624 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:51:26,870 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:51:26,906 INFO] * number of parameters: 113297921
[2020-07-21 16:53:40,443 INFO] Device ID 0
[2020-07-21 16:53:40,443 INFO] Device cuda
[2020-07-21 16:53:40,470 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:53:42,696 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:54:45,730 INFO] Device ID 0
[2020-07-21 16:54:45,730 INFO] Device cuda
[2020-07-21 16:54:45,760 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:54:47,936 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:55:22,201 INFO] Device ID 0
[2020-07-21 16:55:22,201 INFO] Device cuda
[2020-07-21 16:55:22,231 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:55:24,502 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:55:24,505 INFO] * number of parameters: 113297921
[2020-07-21 16:57:39,038 INFO] Device ID 0
[2020-07-21 16:57:39,038 INFO] Device cuda
[2020-07-21 16:57:39,068 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 16:57:41,358 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 16:57:41,361 INFO] * number of parameters: 113297921
[2020-07-21 17:00:27,778 INFO] Device ID 0
[2020-07-21 17:00:27,778 INFO] Device cuda
[2020-07-21 17:00:27,802 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:00:30,068 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:00:30,071 INFO] * number of parameters: 113297921
[2020-07-21 17:03:05,565 INFO] Device ID 0
[2020-07-21 17:03:05,565 INFO] Device cuda
[2020-07-21 17:03:05,597 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:03:07,796 INFO] * number of parameters: 113297921
[2020-07-21 17:03:07,804 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:05:50,386 INFO] Device ID 0
[2020-07-21 17:05:50,386 INFO] Device cuda
[2020-07-21 17:05:50,409 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:05:52,666 INFO] * number of parameters: 113297921
[2020-07-21 17:05:52,673 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:08:29,435 INFO] Device ID 0
[2020-07-21 17:08:29,435 INFO] Device cuda
[2020-07-21 17:08:29,458 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:08:31,662 INFO] * number of parameters: 113297921
[2020-07-21 17:08:31,669 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:11:28,460 INFO] Device ID 0
[2020-07-21 17:11:28,460 INFO] Device cuda
[2020-07-21 17:11:28,483 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:11:30,689 INFO] * number of parameters: 113297921
[2020-07-21 17:11:30,696 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:11:42,242 INFO] Device ID 0
[2020-07-21 17:11:42,242 INFO] Device cuda
[2020-07-21 17:11:42,272 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:11:44,511 INFO] * number of parameters: 113297921
[2020-07-21 17:11:44,519 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:16:57,938 INFO] Device ID 0
[2020-07-21 17:16:57,938 INFO] Device cuda
[2020-07-21 17:16:57,961 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:17:00,197 INFO] * number of parameters: 113297921
[2020-07-21 17:17:00,205 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:17:00,207 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:17:26,130 INFO] Device ID 0
[2020-07-21 17:17:26,130 INFO] Device cuda
[2020-07-21 17:17:26,154 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:17:28,379 INFO] * number of parameters: 113297921
[2020-07-21 17:17:28,386 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:17:28,388 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:19:26,305 INFO] Device ID 0
[2020-07-21 17:19:26,305 INFO] Device cuda
[2020-07-21 17:19:26,332 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:19:28,561 INFO] * number of parameters: 113297921
[2020-07-21 17:19:28,569 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:19:28,570 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:19:52,908 INFO] Device ID 0
[2020-07-21 17:19:52,908 INFO] Device cuda
[2020-07-21 17:19:52,933 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:19:55,174 INFO] * number of parameters: 113297921
[2020-07-21 17:19:55,182 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:19:55,184 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:20:33,131 INFO] Device ID 0
[2020-07-21 17:20:33,132 INFO] Device cuda
[2020-07-21 17:20:33,156 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:20:35,368 INFO] * number of parameters: 113297921
[2020-07-21 17:20:35,375 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:20:35,378 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:30:10,311 INFO] Device ID 0
[2020-07-21 17:30:10,311 INFO] Device cuda
[2020-07-21 17:30:10,335 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:30:12,568 INFO] * number of parameters: 113297921
[2020-07-21 17:30:12,575 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:30:12,578 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:30:12,801 INFO] origin sent: [['"               8 0                    ', '                                ', '          "                                       "'], ['"                        "', '                                  ', '                                      "'], ['"  1 9 9 0                    "     "  "    "    ', '              y b a                    ', '                             "'], ['"             4 9             "    "   "           "', '     "                       ', '                                 " "'], ['"                                       ', '"                                                   "', '                                  "'], ['"                                  ', '"           "                                   ', '                             "'], ['" 1 5 0 1                                  ', '                    1 6                             ', '                7                "']]
[2020-07-21 17:30:12,844 INFO] origin sent: [['" "                               " h a r \' e l ', '                                  ', '                                "'], ['"                                                  "       "    ', '       "   "         ', '                                        "'], ['"  b o f i l l                                  ', '                         ', '                                         "'], ['"  c o r b e r o                            ', '                                           ', '                                            "'], ['"                                           ', '                                ', '                       "'], ['"                                      " h & m       "                            ', '                              ', '                   "'], ['"                                                          ', '                                            ', '                    "']]
[2020-07-21 17:30:12,886 INFO] origin sent: [['"             "                 " "              "                                             ', '                   ', '               "'], ['"        k r a v i t z   t i f f a n y               ', 't i f f a n y        "                        ', '                      "'], ['"            2 1   1 0 0       1 6                      ... ...                  ', '                  ', '2 0 2 0       1 0                        y o o    "'], ['"                                                    ', '                              ', '                 ? "'], ['"  3 4                           3 4 a  ', '                    l', '                               a              b   "'], ['"                                                    ', '                      ', '               (  3 5 a )                (  3 4 a )     "'], ['"                    ?', '                                   ', '          7  2 8                           "']]
[2020-07-21 17:30:12,929 INFO] origin sent: [['"                                  ', '              ', '                                                  "'], ['"          "   "                              ', ' 1 9 9 7       1 7                     ', '                   "'], ['"                                 ', '                 ', '             9 2 9 0 0          5 6                  1 6 0 9        "'], ['"                  -- --                          "       "               ', '                    ', '                                    "'], ['"                            1 1   ', '       1 1      1 1      ', '         1 5 0 0      "   "                                       "'], ['"                ', '                                                 ', '                                 "'], ['" 1 9 9 5  6  1 7        5 0             1 0              1 .', '5                              ', '                               "']]
[2020-07-21 17:30:12,965 INFO] origin sent: [['"                                              ', '                     "    "  ', '                                           "'], ['"                                      ', '                                   ', '                      "'], ['"                          -                              ', '               ', '                                            "'], ['"                                 ', '                                                   ', '                                "'], ['"   1 9 9 6                                   ', '            "                                   ', '                 "'], ['"                                                         ', '                                        ', '                              "'], ['" 7 2 9         9                                              ', '                    1 1         ', '                                   "']]
[2020-07-21 17:30:13,001 INFO] origin sent: [['"                          ', '                                    ', '                                                    "'], ['"                         ', '                                                       ', '                                      "'], ['" "                                          "', '              ', '           8 0 0                             6 0       "'], ['"                                            ', '                          ', '                                       "'], ['"         ', '                                                                 ', '                                 "'], ['"                              ', '0 1                     "                                           "', '                           "'], ['"                               ', '                                                     ', '                              "']]
[2020-07-21 17:30:13,039 INFO] origin sent: [['"                                                       ', '                      ', '                   "'], ['"                                                                          ', '                   ', '               "'], ['"                "                                                "', '                 ', '                                          "'], ['" 0 0 7                                        ', '                               ', '0 0 8                                 "'], ['"                                                   ', '0 0 9                                      ', '  1 9                    "'], ['" 0 1 0                                         ', '                                   ', '                                   "'], ['"                     ', '                                                        ', '                 -- --                           "']]
[2020-07-21 17:30:13,077 INFO] origin sent: [['"                                      ', '                                  ', '                                    "'], ['"                                          ', '           "                             "', '                      "'], ['"                                       ', '                    2 0 0    ', '                                            "'], ['"                      ', '            ', '                "         "      z z x r                                                      "'], ['"                                               ', '                           ', '         "                                 " "'], ['"         "             ', '                                     ', '                                 "'], ['"                         ', '                 ', '          n                                          "']]
[2020-07-21 17:30:13,115 INFO] origin sent: [['"   "    "       2 0 1 8                                       ', '                                 ', '                      "'], ['"                           ', '            "                      "', '                                    "'], ['"                                       ', '  8 4                             ', '                "   "              "'], ['"                   1 9            6 0          ', '                  ', '     "                               " "'], ['"       ', '0 2                            6 7            ', '                                                    4 0      "'], ['"                                        ', '                     ', '                  "                  " "'], ['"                              ', '                                     ', '"   "                                                     "']]
[2020-07-21 17:30:13,151 INFO] origin sent: [['"                             ', '                                                   ', '           "     " "'], ['"                                                       ', '  3                                ', '               "            " "'], ['"                                "                                "', '                                ', '0 3 "            " "'], ['"                                           8 4            : "              "', '                             ', '                 "'], ['"            "                                           "', '                             6 0          8 0', ' "     "                    "'], ['"                                                        ', '                     ', '                 "'], ['"                                                        ', '                                          ', '                      "']]
[2020-07-21 17:30:13,187 INFO] origin sent: [['"                                        ', '     s t s            ', '                                     "'], ['"                                         ', '                                           ', '              t e a m l a b                     "'], ['"                           ', '                                     ', '                                            "'], ['"                                       ', '                                   ', '-- --                                           2 0 1 8 "'], ['"        6 0                          ', '                                     ', '-- --                             a p e x            "'], ['"                                                   ', '                  -- --                          ', '     l i z t h o m a s           "'], ['"                         m e o w w o l f        t e a m l a b     ', '                              ', '                                   "']]
[2020-07-21 17:30:13,224 INFO] origin sent: [['"                     ', '                                          ', '                                                             "'], ['"          t e a m l a b          ', '                                                      ', '                                           "'], ['"                                                    ', '                                           ', '"          `   \'                " "'], ['"             ', '                                        ', '                                             "'], ['"                             "   "   ', '    1 2                                  ', '1  2 2                           "'], ['"                     2 1                                  ', '                                               ', '                    "'], ['"                       ', '         "  "              ', '                 2 0 2 0                                        "']]
[2020-07-21 17:30:13,261 INFO] origin sent: [['"                                        ', '                   ', '                         a                   "'], ['"                            ', '                                                   "             "', '"                 " "'], ['"                                              ', '                 ', '                                                    "'], ['"                 ', '                                                              ', '                      "'], ['" 7                                                      ', '              ', '                                                  "'], ['"                                                 ... ...     ', '              ', '                                           "          " "'], ['"                                                                  ', '                 ', '                                         "']]
[2020-07-21 17:30:13,299 INFO] origin sent: [['"          "     "   ', '                              ', '                           1 3                  1 5 0                      "'], ['"                                                      ', '                        ', '               "  " "'], ['"                                                        ', '         p s               -- -- ', '                                 "'], ['" -- --                                        ', '                                     ', '                                 "'], ['"                                     ', '                                       ', '                             "'], ['"                  ', '    "     "                                "         "     ', '                        "'], ['"                                                                  "             "  "          "', '                 ', '              "']]
[2020-07-21 17:30:13,336 INFO] origin sent: [['"                     ', '      1 2 0 1 0 0 c m                                      "   "', '                                          "'], ['" -- --    k 1 1       k 1 1       1 4                 "      "   ', '                         ', '                                                 "'], ['"                                           ', '                                 ', '                        "'], ['"                                                    ', '                           ', '                              "'], ['"        3 8             "                                       ', '                   ', '                                   " "'], ['" 2           9 .', '7           -- --           ', '                                                                "'], ['"                                                               ', '5            9 .', '7                                          "']]
[2020-07-21 17:30:13,372 INFO] origin sent: [['"                                                                                ', '                ', '                        "'], ['"                                                 ', '1 9 6 6                                       ', '                "'], ['"                     ', '             -- --               ', '    1 9 7 8             1 / 4                         "'], ['"     "         "               ', '  p r a d a                                 v o g u e               ', '                          "'], ['"                                                                     ', '                     ', '             "'], ['"                                        ', '              ... ...                                     ', '                 "'], ['"               "                             "', '                  ', '                               5 7                           "']]
[2020-07-21 17:30:13,407 INFO] origin sent: [['"                                                         ', '                                    ', '"               " "'], ['"                                "   "', '                                               ', '                       "'], ['"                                                                             ', '      "    "          ', '          "'], ['"     s l a t    1 6         ', '2 0 1 1   1 6   s l a t                                              ', '                       "'], ['"                                                          ', '                   ', '2 0 1 3                        "   "                "'], ['"   s l a t                    2 0 1 2      t e d x  ', 't e d                                            ', '        s l a t               s l a t   "'], ['"                   -- --                            ', '                                  ', ' s l a t                                 "']]
[2020-07-21 17:30:13,444 INFO] origin sent: [['"  2 0 1 7                s l a t    "             ...                   "', '           s l a t                    ', '                         "'], ['"                                                   ', '                                        ', '                          "'], ['"     s l a t                               -- --                          ', '2 0 1 9  6                   ', ' 1 9  1 0   s l a t                         "'], ['"                                                               ', '                            ', '                        "'], ['"                  ', 's l a t          c n e t         2 0 1 9          6 0              1 .', '4                                                    "'], ['"  s l a t        "                                             ', '                   "', '                                            "'], ['"                                    ', 's l a t                               ', '                      1 %       8 0 %        "']]
[2020-07-21 17:30:13,482 INFO] origin sent: [['"                           ', '                       -- --        5             1      ', '                  "'], ['"                                       ', '             9                       ', '                                                   "'], ['"                                3 1 5 0   ', '               ', 's l a t                                               "'], ['"               ', '  /                                         "                "              ', '"                 " "'], ['"                                       4 2 0                            ', '                 ', '                 "     "    "'], ['"                                 2 0 0 5  "  "                ', '                 ', '                                    "'], ['"                           "   "      "    "    "  "', '                   -- --      o d e o       ', '                                         ... ... "']]
[2020-07-21 17:30:13,522 INFO] origin sent: [['"                  ', '                                        ', '                                             "'], ['"          ', '2 0 0 9  5           "                            "     "     "           s q u a r e', '  s q u a r e                             "'], ['"  "     "  c e o         5 9              3 6   ', '                            ', '    "    "                                          "'], ['"                                   1 .', '        "   "                ', '     "       "      d i o r       p r a d a           "'], ['"       2 0 1 9                                 ', '                        1 0               c e o  ', '           "   "          "'], ['"                                                      "    "   "         ', '               "', '                     "          " "'], ['"       "     "         u f c           "               9 9 %                           "', '         ', '                         "']]
[2020-07-21 17:30:13,558 INFO] origin sent: [['"                                   ', '    3  8    1  3 8                         -             u f c       ', '                2 1   "'], ['"                          u f c                              ', '             2 0 1 9  8  3 1     ', '                                      "'], ['"            ', ' 2 0 1 7                                       "   "   ', '                                    "'], ['"           ', '                            2 1         u f c                   -              u f c         ', '               "        " "'], ['"                   "                  "', '1 6                    -- --        ', ' 1 4          1 8         8                 "     "          "'], ['"                       "    "                                        ', '                              ', '                        "'], ['"        "  "    "                    "', '"          "                                ', '           6                        "']]
[2020-07-21 17:30:13,594 INFO] origin sent: [['"                               ', '                                                ', '              "         " "'], ['"                                                   o k    ', '                           "      "    ', '               "'], ['"       -                                 1 7             ', '                  "        "', '              "'], ['"                                                 "              "', '                         ', '             "       " "'], ['"                                      ', '                  ', '           "                            " "'], ['"        "      "       "  " ', '                         -- --            ', '                                                  "'], ['"                                                                      ', '                        ', '                              "']]
[2020-07-21 17:30:13,631 INFO] origin sent: [['"                    "                 ', '                                              ', '            5 0 0          "'], ['"          " 1 9 3 5              ... ... "                               ', '                                          ', '                "'], ['"                                    ', '                    ', '                                                      ... ... "'], ['"          1 9 3 6                                                                                       7 .', '7 6    3 .', '4 9             "'], ['"                                                      -- --         ', '                          ', '                   "'], ['"                     ', '                                   ', '                                               ... ... "'], ['"                                         ', '     "              "', '                                               "']]
[2020-07-21 17:30:13,705 INFO] origin sent: [['"                   ', '            .', '        "                                                                                       " "'], ['"       1 9 8 4                      ', '                                                   ', '                  2 0                "'], ['"     "  "                                 ', '                            ', '                                           "'], ['"                             ', '       9                                           ', '                              "'], ['"                                    "', '                                            ', '                                      "'], ['"                                  ', '                                               ', '                  '], ['"               9 0   0 0                     ', '                                 ', '                                       "']]
[2020-07-21 17:30:13,744 INFO] origin sent: [['"                            -- --      ', '          "     "                       ', '                       2 0                 "   "  1 0   "'], ['"        1 0 3                                    ', '                                   ', '                           "'], ['"                                                                   ', '   "                                 "', '           "'], ['"                   0 3             ', '                                 "      "', '                                                   "'], ['"                      ', '              ', '           "     "                                                        "'], ['"                     ', '                                                                 ', '0 2                            "'], ['"                                             ', '                                 ', '                       "']]
[2020-07-21 17:30:13,781 INFO] origin sent: [['"                            ', '                 ', '                                                            "'], ['"                                                 ', '0 3               ', '                                               "'], ['"                                                   ', '                      ', '                               "'], ['"                        ', '                                    ', '                                                         "'], ['"                       ', '                                ', '                                                                     "'], ['"                                                   ', '                                     ', '            "'], ['"                    ', '                                   1                                            ', '            2 4   "']]
[2020-07-21 17:30:13,817 INFO] origin sent: [['"                                                          ', '                    ', '                           q q          "'], ['"   q q                                              ', '                                                   ', '                        "'], ['"                                               ', '                                      "   "', '           "'], ['"                                                                              b .', '        ', '                                     "'], ['"                                      ', '                                     ', '                                "'], ['"                                                                     ', '                           ', '                       "'], ['"                                                                ', '                                               ', '              "']]
[2020-07-21 17:30:13,854 INFO] origin sent: [['"                                     ', '                                                        ', '              "'], ['"                                                                 ', '            1 8            ', '                   "'], ['"          ... .', '                1 2                       ', '                       "   "     "    "                    "     "     "'], ['"                                                             ', '                                         ', '                   "'], ['"     " p y t h o n     "    "     "       p y t h o n                      g i t            ', ' s h e l l                   ', '    p y t h o n            "'], ['"        s t r e a m                      g i t d b             g i t        ', '                 g i t ', '          "'], ['"            g i t    ... ...                  ', '    g i t            ', '         s h e l l       s t d i o            p y t h o n    g i t             "']]
[2020-07-21 17:30:13,890 INFO] origin sent: [['                   ', '                           ', '                                   ', '                          "'], ['"                                              ', '                                   ', '                      ', '                "'], ['"             "                         "', '                            "         "', '    "          "', '                       "'], ['"                             ', '                      ', '                         ', '                                                "'], ['" 2 0 1 5                                                 ', '      i n s          "             "    ', '                       ', '     "'], ['"                             ', '         ', '  "     "                                    ', '                                "'], ['"                    ', '                              -- --            ', '          "   "       ', '                                   (  3 5 ) "']]
[2020-07-21 17:30:13,929 INFO] origin sent: [['"                                     ', '(             )', '                              ', '                           (          ) "'], ['"                                                       ', '                           ', '                       ', '             "'], ['"       "                      "', '  "        "  1 9 6 8             ', '               -- --       ', '1                 "   "                     "'], ['"                                          ', '              ', '       "   "     ', '                             "'], ['"                               ', '                     ', '               ', '                                     "'], ['"                                  ', '     "                                    ', '                    "', '                             "'], ['"    t a l k s                   ', '                                                                  ?', '  7   2  ', '   7   2    "']]
[2020-07-21 17:30:13,967 INFO] origin sent: [['"                                              ', '                                       ', '              ', '           "'], ['"                        ', '                  "                                        "', '    y y        ', '                        "'], ['"                               ', '"      ', '                                             "', '                  "'], ['"                                   ', '                         ', '       ', '                              "'], ['"                                     ', '0 4                    "    "     ', '                                 ', '          "            " "'], ['"           5                    ', '         "            "', '                             ', '0 5                                   "'], ['"                                        ', '               ', '1  1 8                    ', '                               "']]
[2020-07-21 17:30:14,004 INFO] origin sent: [['"                               ', '                ', '           6 7                    : "                        ', '          " "'], ['"                                 ', '     "                      "', '                       8 7 %', '                           "'], ['"                                            ', '1 9 5 9                     ', ' 4 0 0       5 4 .', '2              "'], ['"                                                               ', '                      i f .', '                             ', '         "'], ['"                  "       "', '            "                         "', '              ', '                               "'], ['"                  3 0                         t       ', '                           ', '                 ', '                         "'], ['"                                 ', '                         ', '                          ', '                                    "']]
[2020-07-21 17:30:14,041 INFO] origin sent: [['"                             ', ' 2 0 1 8                  ', '        ', '                                  "'], ['"                                     ', '                     ', '                      "     "               ', '                "'], ['"                      ', '                ', '                               ', '                        "'], ['" a p p                      "    "    ', '                                8 4   ', '              ', '             "'], ['"                 ', '                         "     "', '                          ', '                             "'], ['"           ', '                             ', '        ', '                                            "'], ['" e n d     1 .', '                                   2 .', '                             3 .', '8 4               1 7                  "']]
[2020-07-21 17:30:14,075 INFO] origin sent: [['"                   "     "                        ', '                              ', '                    ', '         "'], ['"                                   ', '                                            ', '                      ', '                   "'], ['"          " o k "      "  "                                    ', '              b r a', '                                 ', '               "'], ['"        ', '                           ', '                   ', ' -                                                   "'], ['"                                    ', '                         ', '           ', '                          "'], ['"                    "     "                            ', '3           9 .', '8          7 0 %            "    "', '       8 0 0 0                    "'], ['"                              ', '"            "', '  "    "                     ', '                     2 0 0 8                       "']]
[2020-07-21 17:30:14,112 INFO] origin sent: [['"          ', '                  ', '                        ... ...                    ', '                        3 5      "'], ['"                           -- --     3 9     ', '        5 0      ', '                    -- --  ', '                          "'], ['"                               ', '             ', '                               ', '                5                 "'], ['"                                     ', '     3                                       ', '                ', '"                    " "'], ['"        -- --                  ', '                 8                    ', '                        ', '        "'], ['"     p a r t y         ', '      ', '                                                ', '                                "'], ['"      2 0   7 0              ', '                          ', '                         ', '   2 0 1 5                    3 0              "']]
[2020-07-21 17:30:14,149 INFO] origin sent: [['"          1 2 0         ', '                                     ', '                           1 6 0         ', '1 6 0           3       "'], ['"                            ', '              ', '                  ', '                                           2 0 0 0               "'], ['"                                 ', '               ', '              1 %               ', '                         "'], ['"                2 9              c e o             ', '      "    "          ', '      "   "                     ', '   c e o          c e o   "'], ['"   s q u a r e                 ', '2 0 1 1                 ', '           ', '                              "      " "'], ['"                                s q u a r e ', '  2 0 1 5  1 0           c e o  ', '      s q u a r e    ', '                    c e o   "'], ['"                                  ', '                  "   "          ', '2 0 1 6                                     ', '            "']]
[2020-07-21 17:30:14,187 INFO] origin sent: [['"   4 2    t k o    ', '                 "                  "              -- --       u f c  ', '                     ', '                      "'], ['"            ', '                  ', '                                        ', '                              "'], ['" "       "    2 0 1 9           u f c              ', '     u f c       "    "      ', '       3  u f c  ', '                                    "   " "'], ['" 2 0 1 8  8  5     u f c      "     "      ', '                                     ', '             u f c   ', '               "'], ['"                       "                  "', '            ', '                                  ', '                   "  " "'], ['"          ', '                        ', '                ', '   8 0     9 0                                    "      " "'], ['" 1 9 8 1  1 1  1 6                2 1                             ', '                       ', '            ', '                   "']]
[2020-07-21 17:30:14,223 INFO] origin sent: [['" 1 9 8 6                                 ', '    "     "              ', '2 0 1 2                    ', '           "     " "'], ['" 2 0 1 0                      ', '"   "                                   ', '              "   "            ', '     "    "                   "'], ['"                   "      "', '                  "                              "', '            "  "   ', '   u f c                         "'], ['"                     ', '                      ', '         8   1 1                                    ', '                    "'], ['"                           e m s             ', '                           ', '               -- --  ', '                         2 4         "'], ['"                   ', '           ', '                          ', '                                                                   "'], ['"                          ', '                                 ', '         "                 "', '                                     "']]
[2020-07-21 17:30:14,260 INFO] origin sent: [['"   3 3                    c o o k b o o k     -- --          "      ? " "', '                 ', '              ', '                "'], ['"                                    1 .', '      a p p    "    "      2 .', '         5             ?', '            1 0  2 2 : 0 0       "'], ['"                                      ', '                                     ', '          ', '                    "'], ['"                 i p            i p', '                       ', '                                      5 .', '6       "'], ['"                      ', '   1 9 4 4        8        ', '                            ', '                                                 "'], ['"                                                   ', '                  8            ', '       ', '                           "'], ['"                                                         ', '              ', '                     ', '                               "']]
[2020-07-21 17:30:14,298 INFO] origin sent: [['"                                ', '                           -- --                1               9 .', '9                     ', '2 0 2 0        ! "'], ['"              3 .', '7    1 .', '5                                           ', '                                                "'], ['"                    ', '                  2 .', '                                     3 .', '                                                "'], ['"                    ', '                               ', '               ', '                                   "'], ['"                           ', '                   ', '                              ', '                                     "'], ['"        3 2                                                       ', '                 ', '   "     "       ', '0 2          "'], ['"                            ', '            "            ', '                                   "', '                           "']]
[2020-07-21 17:30:14,338 INFO] origin sent: [['"                      ', '                 ', '   "      "           ', '                                                   ... ...            "'], ['"              5 5  ', '             9 0 %                           ', '                   ', '            5 2                             "'], ['"                                    ', '                              ', '          ', '                         "'], ['" 3                       ', '                ', '                                               ', '                           "'], ['"                     ', '                  ', '7               ', '                                             "'], ['"              q q          ', '           ', '                                                        ', '                      "'], ['"                                          ', '                        k i n d l e    ', '                           ', '                "']]
[2020-07-21 17:30:14,378 INFO] origin sent: [['          ', '                                                                 ', '                               "', '           "'], ['"              ', '                                                 ', '                         ', '              "'], ['"                                                        ', '                         ', '       ', '                                    "'], ['"                           ', '                                  ', '                                           ', '                "'], ['"                              ', '                 ', '                                    ', '                i n t e g r i t y       "'], ['"                           ', '1 1                                                  ', '              9          5 0  ', '                "'], ['"        l i b g i t 2      p y t h o n ', '   c     p y t h o n                        ', '              l i b g i t 2', '           g i t      "']]
[2020-07-21 17:30:14,413 INFO] origin sent: [['                   ', '                      ', '                              ', '                                     "'], ['"   2 0 1 9  i p p a            "    ', '                            ', '                          ', '     ', '                       " "'], ['" "                      "', '                        ', '                       ', '     ', '                          "'], ['"                                                         "     "', '                   ', '             ', '              ', '           "'], ['"                ', '                      ', '                                 ', '                  ', '                          "'], ['" 0 2                     ', '              ', '                                 ', '            ', '            "'], ['"                                             ', '       "                        "', '           ', '0 3                 ', '               "']]
[2020-07-21 17:30:14,449 INFO] origin sent: [['"                                    ', '                 ', '               ', '                    ', '                             "'], ['"                          ', '      ', '            8 4              ', '                               ', '0 1 8 4         "'], ['" 0 8                                   ', '                  ', '                    ', '                    ', '                      ... "'], ['"                     ', '              ', '                   ', '                               ', '                   "'], ['"                             ', '                ', '                ', '                     ', '                        "'], ['"                                ', '               ', '                  ', '                               ', '                 "'], ['"                       "     "', '                         ', '                   ', '          ', '                                   "']]
[2020-07-21 17:30:14,485 INFO] origin sent: [['"                         ', '            ', '            ', '                    ', '                     /              "'], ['"                  ', '                      ', '   1 0                     ', '    /   n e o         ', '                 1 0 0 0          "'], ['"                    ', '               ', '                            ', '                                ', '                           "'], ['" 1 9 2 9                 ', '                ', '                        ', '       1 9                          ', '                   "'], ['"          8              4 - 1 6 ', '                 1 .', '8       ', '                                             "', '8        "'], ['"             ', '          ', '               s l a t                            ', '     s l a t   ', '            6 0 0             c            "'], ['"                                   ', '2 0 0 2                    "    "', '     2 6 ', '             ', '                      "']]
[2020-07-21 17:30:14,523 INFO] origin sent: [['"               "', '"                      "', '                     ', '2 0 0 8           "  "      c e o       ', '                              "'], ['"                 ', '    e s p n                       "            "', '          ', '       -- --        "       "', '         "    "   "'], ['"             u f c   -- --                u f c   2 6             ', '                       1 .', '8     ', '                 ', '                "'], ['"                                 ', '                        "             ', '                 "', '       "      "', '            "'], ['" 2 0 1 1  6                        ', '                          -- --        ', '      ', '           ', '2 0 1 4                   "'], ['"     u f c                            ', '                   ', '          ', '                  ', '                       "'], ['"               6         ', '     "     "               ', '                          ', '              ', '               3 0 0 0        "']]
[2020-07-21 17:30:14,561 INFO] origin sent: [['"            ', '                                      ', '         ', '      1 3                          ', '          "'], ['"                            ', '               ', '                       ', '                           ', '             "'], ['"                        v i p                    1 .', '                   2 .', '                    3 .', '                  4 .', '                  "'], ['"                               "', '     2 2                       ', '                     ', '                     ', '                  "'], ['" 1           ', '                                              ', '                        ', '                     ', '                  "'], ['" 2           ', '                         ', '               ', '                   ', '                                   "'], ['"             ', '4         ', '                 ', '                                                  ', '                    "']]
[2020-07-21 17:30:14,600 INFO] origin sent: [['"                     ', '                      ', '                 ', '6         ', '                                 "'], ['"                          ', '            ', '                                   ', '8               ', '       "'], ['"                              ', '                ', '                      ', '                              ', '9                "'], ['"                          1 8 0      8 1 .', '6              1 2      5 .', '4 4       ', '          ', '      "                                         "'], ['"                                            ', '       1 .', '                ', '             ', '                          "'], ['         6 .', '                 7 .', '        8 .', '                            ', '                                             "'], ['"             ', '        "    "           ', '                         ', '       "          "', '                      ', '      2 0             "']]
[2020-07-21 17:30:14,638 INFO] origin sent: [['"                    ', '"                   "        ', '                  ', '                    ', '          ', '                    "'], ['"                    2 0               ', '         "          "', '        ', '                    ', '                   ', '                 "'], ['"                      ', '           ', '         ', '        3                    ', '                         ', '    5              "'], ['"               ', '                    ', '5                         ', '          ', '                    ', '               "'], ['" 0 1                       b               ', ' "   "      ', '         ', '           ', '         ', '                                    "'], ['"           ', '                 ', '                         ', '                     ', '1 0           ', '          ', '                   "'], ['"          ', '               ', '            ', '                     ', '              ', '                  ', '           ', '               "']]
[2020-07-21 17:30:14,676 INFO] origin sent: [['                          0 2                     @                 "   "', '                                ', '                    "'], ['"                                                    ', '                   ', '           " "              " "                ! "'], ['"                                       ', '                                      ', '                                    ? "'], ['"                                     ', '                 ', '                                              ... ... "'], ['"   "           "                                                          ', '                    ', '@              "'], ['"                                  ', '                               ', '@ k r i s                         "'], ['"                                              ', '                                         "     "         ', '               "']]
[2020-07-21 17:30:14,713 INFO] origin sent: [['"                                                                            ', '                      ', '                          "'], ['"                                             ', '                                 ', '                              "'], ['"                              1 0                ', '@                                     ', '              "'], ['"                                               ', '                           ', '                            "'], ['"                                       ', '                                      ', '           "          1 0                     " "'], ['"                   "        "   ', '                                ', '                                            "'], ['"                                  ', '2                                                      ', '                  "    "   "']]
[2020-07-21 17:30:14,750 INFO] origin sent: [['"                                         ', '                         ', '                                                "'], ['"                                                     ', '                                   "         "', '                   "'], ['"                                                              ', '               ', '                                    "'], ['"                                                              ', '                               ', '                      "'], ['"          7                   "   "', '                                                    ', '                  "'], ['"                              ', '                                       ', '                                      "'], ['"           ... ...                                          ', '               ', '3                                              "']]
[2020-07-21 17:30:14,785 INFO] origin sent: [['"                                    ', '                                  ', '                                         "'], ['" 4                                            ', '                                             ', '                                  "'], ['"                                                       ', '               ', '                                                   "'], ['"                                                     ', '                     ', '                                                  "'], ['" 2                             ', '                                     ', '                                  "'], ['"                                            ', '                  3                ', '                                  "'], ['"               ', '                     ', '                                                                                         "']]
[2020-07-21 17:30:14,823 INFO] origin sent: [['"                   ', '                                    ', '            "                    "    "                    " "'], ['" "    "                         "                         ', '                     ', '                                          "'], ['"                               ', '                                  ', '                                    "'], ['"                                                       ', '              ', '                                      "'], ['"                            ', '                               ', '3                                                               "'], ['"                                           ', '1 9 3 8  2                               ', '                                   2 4 3 2 4 1    "'], ['"                             ', '4                                                       ', '                                         "']]
[2020-07-21 17:30:14,860 INFO] origin sent: [['"                       ', '                   ', '                                                          "'], ['            "   "     "   "     "   "      "   "                      ', '       "   "    "   "', '          "        " "'], ['"  "      "                                                  ', '                    ', '               "            " "'], ['"                                                            ', '                       ', '                  "'], ['"                                                                 ', '                       ', '                   "'], ['"                                                 ', '                                   ', '                         "'], ['j p g       d r i b b b l e                         ', '        h r                 ', '                                      "'], ['"                                                ', '                                ', '                         "']]
[2020-07-21 17:30:14,896 INFO] origin sent: [['" 1          "                                            ', '                        ', '                         "'], ['"                           ', '                                                    ', '                      "             "       "'], ['"                                         ', '                    ', '                                                             "'], ['"   s e a r l e                         ', '          s e a r l e                                  ', 's e a r l e    "     "                          "'], ['" 4                                     ', '                                   ', '                  5 0 % "'], ['"                                                      ', '                           ', '                           "'], ['"                              ', '        "     "                                           ', '5             "      "              "']]
[2020-07-21 17:30:14,932 INFO] origin sent: [['"                                       "      "        ', '          "      "       ', '     "      "                        "'], ['" t a                              ', '                                           ', '  t a        "   "                   "'], ['"                       1      "  -      "        7           ', '                            ', '"     "                               "'], ['"                                     ', '                 "    "                         "  "    "  "  ', '"  "                        "'], ['" 4               "      "  "      "  "          "', '      2 0 1 7 "      "                 ', '                "     r n a    "                  "'], ['"                    ', '           ', '                                                               "'], ['" 5      "      "      ', '                                             ', '                                                   "']]
[2020-07-21 17:30:14,969 INFO] origin sent: [['"                         "   "                                                1 0   2 0        ', '"       ', '          " "'], ['"                                       ', '                  ', '    "   "          "                                                 " "'], ['"              -- --              "            "  "     "      "          "    "     "       ', '"                          "', '               "   " "'], ['"                             ', '"                                               "              ', '"             "'], ['"                                                            ', '                      ', '                                         "'], ['"                           ... ...                 "', '"                                         "', '    "              "'], ['"                   ', '                                                      ', '    "                     `          \' "']]
[2020-07-21 17:30:35,576 INFO] Device ID 0
[2020-07-21 17:30:35,577 INFO] Device cuda
[2020-07-21 17:30:35,601 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:30:37,828 INFO] * number of parameters: 113297921
[2020-07-21 17:30:37,836 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:30:37,838 INFO] origin sent: [['"                                                                           ', '                        ', '           "'], ['"    1 9 6 8       1 9 9 0                     ', '                  ', '                                   "    "   "'], ['"                                                                 ', '                         ', '             "'], ['"                         ', '1 9 6 9  3  2 5                            "       "', '                                                   " "'], ['"                                                ', '                          g e a h         -- --               ', '                 "'], ['"                                      ', '                                    ', '                      "'], ['" 1 9 8 0  1 2  8         5              ', '                                                      ', '          3 9                       "']]
[2020-07-21 17:33:12,895 INFO] Device ID 0
[2020-07-21 17:33:12,896 INFO] Device cuda
[2020-07-21 17:33:12,919 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:33:15,147 INFO] * number of parameters: 113297921
[2020-07-21 17:33:15,154 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:33:34,526 INFO] Device ID 0
[2020-07-21 17:33:34,526 INFO] Device cuda
[2020-07-21 17:33:34,549 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:33:36,786 INFO] * number of parameters: 113297921
[2020-07-21 17:33:36,793 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:33:36,795 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:34:31,629 INFO] Device ID 0
[2020-07-21 17:34:31,629 INFO] Device cuda
[2020-07-21 17:34:31,653 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:34:33,858 INFO] * number of parameters: 113297921
[2020-07-21 17:34:33,866 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:34:33,868 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:36:20,356 INFO] Device ID 0
[2020-07-21 17:36:20,357 INFO] Device cuda
[2020-07-21 17:36:20,379 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:36:22,615 INFO] * number of parameters: 113297921
[2020-07-21 17:36:22,622 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:36:22,624 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:39:13,691 INFO] Device ID 0
[2020-07-21 17:39:13,691 INFO] Device cuda
[2020-07-21 17:39:13,717 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:39:15,934 INFO] * number of parameters: 113297921
[2020-07-21 17:39:15,941 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:39:15,945 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:40:35,307 INFO] Device ID 0
[2020-07-21 17:40:35,307 INFO] Device cuda
[2020-07-21 17:40:35,331 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:40:37,541 INFO] * number of parameters: 113297921
[2020-07-21 17:40:37,548 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:40:37,554 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:44:23,679 INFO] Device ID 0
[2020-07-21 17:44:23,679 INFO] Device cuda
[2020-07-21 17:44:23,704 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:44:25,907 INFO] * number of parameters: 113297921
[2020-07-21 17:44:25,915 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:44:25,922 INFO] origin sent: ['"                                                                           ', '                        ', '           "']
[2020-07-21 17:47:36,332 INFO] Device ID 0
[2020-07-21 17:47:36,332 INFO] Device cuda
[2020-07-21 17:47:36,356 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:47:38,565 INFO] * number of parameters: 113297921
[2020-07-21 17:47:38,572 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:47:38,574 INFO] origin sent: 7
[2020-07-21 17:47:38,795 INFO] origin sent: 7
[2020-07-21 17:47:38,838 INFO] origin sent: 7
[2020-07-21 17:47:38,881 INFO] origin sent: 7
[2020-07-21 17:47:38,927 INFO] origin sent: 7
[2020-07-21 17:47:38,965 INFO] origin sent: 7
[2020-07-21 17:47:39,000 INFO] origin sent: 7
[2020-07-21 17:47:39,036 INFO] origin sent: 7
[2020-07-21 17:47:39,072 INFO] origin sent: 7
[2020-07-21 17:47:39,108 INFO] origin sent: 7
[2020-07-21 17:47:39,143 INFO] origin sent: 7
[2020-07-21 17:47:39,179 INFO] origin sent: 7
[2020-07-21 17:47:39,215 INFO] origin sent: 7
[2020-07-21 17:47:39,251 INFO] origin sent: 7
[2020-07-21 17:47:39,289 INFO] origin sent: 7
[2020-07-21 17:47:39,326 INFO] origin sent: 7
[2020-07-21 17:47:39,362 INFO] origin sent: 7
[2020-07-21 17:47:39,397 INFO] origin sent: 7
[2020-07-21 17:47:39,433 INFO] origin sent: 7
[2020-07-21 17:47:39,469 INFO] origin sent: 7
[2020-07-21 17:47:39,508 INFO] origin sent: 7
[2020-07-21 17:47:39,543 INFO] origin sent: 7
[2020-07-21 17:47:39,579 INFO] origin sent: 7
[2020-07-21 17:47:39,615 INFO] origin sent: 7
[2020-07-21 17:47:39,651 INFO] origin sent: 7
[2020-07-21 17:47:39,687 INFO] origin sent: 7
[2020-07-21 17:47:39,725 INFO] origin sent: 7
[2020-07-21 17:47:39,761 INFO] origin sent: 7
[2020-07-21 17:47:39,797 INFO] origin sent: 7
[2020-07-21 17:47:39,834 INFO] origin sent: 7
[2020-07-21 17:47:39,869 INFO] origin sent: 7
[2020-07-21 17:47:39,906 INFO] origin sent: 7
[2020-07-21 17:47:39,944 INFO] origin sent: 7
[2020-07-21 17:47:39,981 INFO] origin sent: 7
[2020-07-21 17:47:40,018 INFO] origin sent: 7
[2020-07-21 17:47:40,051 INFO] origin sent: 7
[2020-07-21 17:47:40,087 INFO] origin sent: 7
[2020-07-21 17:47:40,122 INFO] origin sent: 7
[2020-07-21 17:47:40,159 INFO] origin sent: 7
[2020-07-21 17:47:40,196 INFO] origin sent: 7
[2020-07-21 17:47:40,233 INFO] origin sent: 7
[2020-07-21 17:47:40,269 INFO] origin sent: 7
[2020-07-21 17:47:40,306 INFO] origin sent: 7
[2020-07-21 17:47:40,344 INFO] origin sent: 7
[2020-07-21 17:47:40,381 INFO] origin sent: 7
[2020-07-21 17:47:40,418 INFO] origin sent: 7
[2020-07-21 17:47:40,454 INFO] origin sent: 7
[2020-07-21 17:47:40,490 INFO] origin sent: 7
[2020-07-21 17:47:40,525 INFO] origin sent: 7
[2020-07-21 17:47:40,563 INFO] origin sent: 7
[2020-07-21 17:47:40,601 INFO] origin sent: 7
[2020-07-21 17:47:40,640 INFO] origin sent: 7
[2020-07-21 17:47:40,676 INFO] origin sent: 7
[2020-07-21 17:47:40,713 INFO] origin sent: 7
[2020-07-21 17:47:40,747 INFO] origin sent: 7
[2020-07-21 17:47:40,784 INFO] origin sent: 7
[2020-07-21 17:47:40,821 INFO] origin sent: 8
[2020-07-21 17:47:40,857 INFO] origin sent: 7
[2020-07-21 17:47:40,893 INFO] origin sent: 7
[2020-07-21 17:47:40,929 INFO] origin sent: 7
[2020-07-21 17:47:40,965 INFO] origin sent: 7
[2020-07-21 17:47:41,001 INFO] origin sent: 4
[2020-07-21 17:47:41,036 INFO] origin sent: 7
[2020-07-21 17:47:41,072 INFO] origin sent: 7
[2020-07-21 17:47:41,110 INFO] origin sent: 7
[2020-07-21 17:47:41,146 INFO] origin sent: 7
[2020-07-21 17:47:41,182 INFO] origin sent: 7
[2020-07-21 17:47:41,219 INFO] origin sent: 7
[2020-07-21 17:47:41,255 INFO] origin sent: 7
[2020-07-21 17:47:41,294 INFO] origin sent: 7
[2020-07-21 17:47:41,330 INFO] origin sent: 7
[2020-07-21 17:47:41,363 INFO] origin sent: 7
[2020-07-21 17:47:41,399 INFO] origin sent: 7
[2020-07-21 17:47:41,436 INFO] origin sent: 7
[2020-07-21 17:47:41,474 INFO] origin sent: 7
[2020-07-21 17:47:41,511 INFO] origin sent: 7
[2020-07-21 17:47:41,548 INFO] origin sent: 7
[2020-07-21 17:47:41,585 INFO] origin sent: 7
[2020-07-21 17:47:41,620 INFO] origin sent: 7
[2020-07-21 17:47:41,656 INFO] origin sent: 7
[2020-07-21 17:47:41,694 INFO] origin sent: 7
[2020-07-21 17:47:41,732 INFO] origin sent: 7
[2020-07-21 17:47:41,768 INFO] origin sent: 7
[2020-07-21 17:47:41,804 INFO] origin sent: 7
[2020-07-21 17:47:41,840 INFO] origin sent: 7
[2020-07-21 17:47:41,877 INFO] origin sent: 5
[2020-07-21 17:47:41,908 INFO] origin sent: 7
[2020-07-21 17:47:41,945 INFO] origin sent: 7
[2020-07-21 17:47:41,978 INFO] origin sent: 8
[2020-07-21 17:47:42,015 INFO] origin sent: 7
[2020-07-21 17:47:42,050 INFO] origin sent: 7
[2020-07-21 17:47:42,087 INFO] origin sent: 7
[2020-07-21 17:47:42,124 INFO] origin sent: 7
[2020-07-21 17:47:42,162 INFO] origin sent: 7
[2020-07-21 17:47:42,198 INFO] origin sent: 7
[2020-07-21 17:47:42,235 INFO] origin sent: 7
[2020-07-21 17:47:42,271 INFO] origin sent: 7
[2020-07-21 17:47:42,308 INFO] origin sent: 7
[2020-07-21 17:47:42,345 INFO] origin sent: 7
[2020-07-21 17:47:42,381 INFO] origin sent: 7
[2020-07-21 17:47:42,418 INFO] origin sent: 7
[2020-07-21 17:47:42,454 INFO] origin sent: 7
[2020-07-21 17:47:42,490 INFO] origin sent: 7
[2020-07-21 17:47:42,526 INFO] origin sent: 7
[2020-07-21 17:47:42,563 INFO] origin sent: 7
[2020-07-21 17:47:42,600 INFO] origin sent: 7
[2020-07-21 17:47:42,637 INFO] origin sent: 7
[2020-07-21 17:47:42,673 INFO] origin sent: 7
[2020-07-21 17:47:42,710 INFO] origin sent: 7
[2020-07-21 17:47:42,747 INFO] origin sent: 7
[2020-07-21 17:47:42,784 INFO] origin sent: 7
[2020-07-21 17:47:42,819 INFO] origin sent: 7
[2020-07-21 17:47:42,855 INFO] origin sent: 7
[2020-07-21 17:47:42,891 INFO] origin sent: 7
[2020-07-21 17:47:42,927 INFO] origin sent: 7
[2020-07-21 17:47:42,965 INFO] origin sent: 7
[2020-07-21 17:47:43,002 INFO] origin sent: 7
[2020-07-21 17:47:43,039 INFO] origin sent: 7
[2020-07-21 17:47:43,073 INFO] origin sent: 7
[2020-07-21 17:47:43,109 INFO] origin sent: 7
[2020-07-21 17:47:43,145 INFO] origin sent: 7
[2020-07-21 17:47:43,181 INFO] origin sent: 5
[2020-07-21 17:47:43,219 INFO] origin sent: 7
[2020-07-21 17:47:43,256 INFO] origin sent: 7
[2020-07-21 17:47:43,295 INFO] origin sent: 5
[2020-07-21 17:47:43,327 INFO] origin sent: 7
[2020-07-21 17:47:43,360 INFO] origin sent: 7
[2020-07-21 17:47:43,397 INFO] origin sent: 5
[2020-07-21 17:47:43,831 INFO] Writing summaries.
[2020-07-21 17:47:43,831 INFO] Processing summaries. Saving system files to ./temp/tmp99hl0meh\system and model files to ./temp/tmp99hl0meh\model.
[2020-07-21 17:47:43,831 INFO] Processing files in ./temp/rouge-tmp-2020-07-21-17-47-43/candidate/.
[2020-07-21 17:48:15,697 INFO] Device ID 0
[2020-07-21 17:48:15,697 INFO] Device cuda
[2020-07-21 17:48:15,721 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:48:17,961 INFO] * number of parameters: 113297921
[2020-07-21 17:48:17,968 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:48:33,620 INFO] Device ID 0
[2020-07-21 17:48:33,620 INFO] Device cuda
[2020-07-21 17:48:33,646 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:48:35,884 INFO] * number of parameters: 113297921
[2020-07-21 17:48:35,892 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:49:03,923 INFO] Device ID 0
[2020-07-21 17:49:03,923 INFO] Device cuda
[2020-07-21 17:49:03,947 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:49:06,171 INFO] * number of parameters: 113297921
[2020-07-21 17:49:06,178 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:49:19,312 INFO] Device ID 0
[2020-07-21 17:49:19,312 INFO] Device cuda
[2020-07-21 17:49:19,335 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:49:21,603 INFO] * number of parameters: 113297921
[2020-07-21 17:49:21,610 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:49:21,612 INFO] origin sent: 7
[2020-07-21 17:49:21,830 INFO] origin sent: 7
[2020-07-21 17:49:21,872 INFO] origin sent: 7
[2020-07-21 17:49:21,914 INFO] origin sent: 7
[2020-07-21 17:49:21,958 INFO] origin sent: 7
[2020-07-21 17:49:22,000 INFO] origin sent: 7
[2020-07-21 17:49:22,038 INFO] origin sent: 7
[2020-07-21 17:49:22,074 INFO] origin sent: 7
[2020-07-21 17:49:22,110 INFO] origin sent: 7
[2020-07-21 17:49:22,145 INFO] origin sent: 7
[2020-07-21 17:49:22,181 INFO] origin sent: 7
[2020-07-21 17:49:22,217 INFO] origin sent: 7
[2020-07-21 17:49:22,253 INFO] origin sent: 7
[2020-07-21 17:49:22,290 INFO] origin sent: 7
[2020-07-21 17:49:22,327 INFO] origin sent: 7
[2020-07-21 17:49:22,364 INFO] origin sent: 7
[2020-07-21 17:49:22,400 INFO] origin sent: 7
[2020-07-21 17:49:22,436 INFO] origin sent: 7
[2020-07-21 17:49:22,472 INFO] origin sent: 7
[2020-07-21 17:49:22,508 INFO] origin sent: 7
[2020-07-21 17:49:22,547 INFO] origin sent: 7
[2020-07-21 17:49:22,581 INFO] origin sent: 7
[2020-07-21 17:49:22,617 INFO] origin sent: 7
[2020-07-21 17:49:22,653 INFO] origin sent: 7
[2020-07-21 17:49:22,691 INFO] origin sent: 7
[2020-07-21 17:49:22,728 INFO] origin sent: 7
[2020-07-21 17:49:22,766 INFO] origin sent: 7
[2020-07-21 17:49:22,803 INFO] origin sent: 7
[2020-07-21 17:49:22,839 INFO] origin sent: 7
[2020-07-21 17:49:22,874 INFO] origin sent: 7
[2020-07-21 17:49:22,912 INFO] origin sent: 7
[2020-07-21 17:49:22,951 INFO] origin sent: 7
[2020-07-21 17:49:22,989 INFO] origin sent: 7
[2020-07-21 17:49:23,027 INFO] origin sent: 7
[2020-07-21 17:49:23,066 INFO] origin sent: 7
[2020-07-21 17:49:23,102 INFO] origin sent: 7
[2020-07-21 17:49:23,140 INFO] origin sent: 7
[2020-07-21 17:49:23,177 INFO] origin sent: 7
[2020-07-21 17:49:23,213 INFO] origin sent: 7
[2020-07-21 17:49:23,248 INFO] origin sent: 7
[2020-07-21 17:49:23,285 INFO] origin sent: 7
[2020-07-21 17:49:23,320 INFO] origin sent: 7
[2020-07-21 17:49:23,358 INFO] origin sent: 7
[2020-07-21 17:49:23,397 INFO] origin sent: 7
[2020-07-21 17:49:23,433 INFO] origin sent: 7
[2020-07-21 17:49:23,469 INFO] origin sent: 7
[2020-07-21 17:49:23,504 INFO] origin sent: 7
[2020-07-21 17:49:23,540 INFO] origin sent: 7
[2020-07-21 17:49:23,577 INFO] origin sent: 7
[2020-07-21 17:49:23,617 INFO] origin sent: 7
[2020-07-21 17:49:23,655 INFO] origin sent: 7
[2020-07-21 17:49:23,696 INFO] origin sent: 7
[2020-07-21 17:49:23,733 INFO] origin sent: 7
[2020-07-21 17:49:23,768 INFO] origin sent: 7
[2020-07-21 17:49:23,802 INFO] origin sent: 7
[2020-07-21 17:49:23,838 INFO] origin sent: 7
[2020-07-21 17:49:23,874 INFO] origin sent: 8
[2020-07-21 17:49:23,910 INFO] origin sent: 7
[2020-07-21 17:49:23,946 INFO] origin sent: 7
[2020-07-21 17:49:23,981 INFO] origin sent: 7
[2020-07-21 17:49:24,017 INFO] origin sent: 7
[2020-07-21 17:49:24,054 INFO] origin sent: 4
[2020-07-21 17:49:24,087 INFO] origin sent: 7
[2020-07-21 17:49:24,123 INFO] origin sent: 7
[2020-07-21 17:49:24,159 INFO] origin sent: 7
[2020-07-21 17:49:24,195 INFO] origin sent: 7
[2020-07-21 17:49:24,233 INFO] origin sent: 7
[2020-07-21 17:49:24,269 INFO] origin sent: 7
[2020-07-21 17:49:24,305 INFO] origin sent: 7
[2020-07-21 17:49:24,343 INFO] origin sent: 7
[2020-07-21 17:49:24,377 INFO] origin sent: 7
[2020-07-21 17:49:24,411 INFO] origin sent: 7
[2020-07-21 17:49:24,446 INFO] origin sent: 7
[2020-07-21 17:49:24,483 INFO] origin sent: 7
[2020-07-21 17:49:24,519 INFO] origin sent: 7
[2020-07-21 17:49:24,555 INFO] origin sent: 7
[2020-07-21 17:49:24,591 INFO] origin sent: 7
[2020-07-21 17:49:24,629 INFO] origin sent: 7
[2020-07-21 17:49:24,666 INFO] origin sent: 7
[2020-07-21 17:49:24,704 INFO] origin sent: 7
[2020-07-21 17:49:24,742 INFO] origin sent: 7
[2020-07-21 17:49:24,777 INFO] origin sent: 7
[2020-07-21 17:49:24,813 INFO] origin sent: 7
[2020-07-21 17:49:24,849 INFO] origin sent: 7
[2020-07-21 17:49:24,885 INFO] origin sent: 7
[2020-07-21 17:49:24,922 INFO] origin sent: 5
[2020-07-21 17:49:24,952 INFO] origin sent: 7
[2020-07-21 17:49:24,988 INFO] origin sent: 7
[2020-07-21 17:49:25,021 INFO] origin sent: 8
[2020-07-21 17:49:25,058 INFO] origin sent: 7
[2020-07-21 17:49:25,094 INFO] origin sent: 7
[2020-07-21 17:49:25,130 INFO] origin sent: 7
[2020-07-21 17:49:25,166 INFO] origin sent: 7
[2020-07-21 17:49:25,204 INFO] origin sent: 7
[2020-07-21 17:49:25,240 INFO] origin sent: 7
[2020-07-21 17:49:25,276 INFO] origin sent: 7
[2020-07-21 17:49:25,312 INFO] origin sent: 7
[2020-07-21 17:49:25,349 INFO] origin sent: 7
[2020-07-21 17:49:25,385 INFO] origin sent: 7
[2020-07-21 17:49:25,421 INFO] origin sent: 7
[2020-07-21 17:49:25,457 INFO] origin sent: 7
[2020-07-21 17:49:25,492 INFO] origin sent: 7
[2020-07-21 17:49:25,528 INFO] origin sent: 7
[2020-07-21 17:49:25,565 INFO] origin sent: 7
[2020-07-21 17:49:25,601 INFO] origin sent: 7
[2020-07-21 17:49:25,637 INFO] origin sent: 7
[2020-07-21 17:49:25,673 INFO] origin sent: 7
[2020-07-21 17:49:32,246 INFO] Device ID 0
[2020-07-21 17:49:32,246 INFO] Device cuda
[2020-07-21 17:49:32,272 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:49:34,494 INFO] * number of parameters: 113297921
[2020-07-21 17:49:34,501 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:49:49,504 INFO] Device ID 0
[2020-07-21 17:49:49,504 INFO] Device cuda
[2020-07-21 17:49:49,528 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:49:51,767 INFO] * number of parameters: 113297921
[2020-07-21 17:49:51,774 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:50:29,599 INFO] Device ID 0
[2020-07-21 17:50:29,599 INFO] Device cuda
[2020-07-21 17:50:29,631 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:50:31,896 INFO] * number of parameters: 113297921
[2020-07-21 17:50:31,904 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 17:51:17,333 INFO] Device ID 0
[2020-07-21 17:51:17,333 INFO] Device cuda
[2020-07-21 17:51:17,364 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 17:51:19,569 INFO] * number of parameters: 113297921
[2020-07-21 17:51:19,576 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:52:55,406 INFO] Device ID 0
[2020-07-21 18:52:55,406 INFO] Device cuda
[2020-07-21 18:52:55,429 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:52:57,664 INFO] * number of parameters: 113297921
[2020-07-21 18:52:57,671 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:53:44,381 INFO] Device ID 0
[2020-07-21 18:53:44,381 INFO] Device cuda
[2020-07-21 18:53:44,406 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:53:46,648 INFO] * number of parameters: 113297921
[2020-07-21 18:53:46,656 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:53:46,658 INFO] origin sent: 7
[2020-07-21 18:54:26,604 INFO] Device ID 0
[2020-07-21 18:54:26,604 INFO] Device cuda
[2020-07-21 18:54:26,627 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:54:28,837 INFO] * number of parameters: 113297921
[2020-07-21 18:54:28,845 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:54:28,847 INFO] origin sent: 7
[2020-07-21 18:55:07,396 INFO] Device ID 0
[2020-07-21 18:55:07,396 INFO] Device cuda
[2020-07-21 18:55:07,420 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:55:09,632 INFO] * number of parameters: 113297921
[2020-07-21 18:55:09,639 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:55:09,641 INFO] origin sent: 7
[2020-07-21 18:55:51,277 INFO] Device ID 0
[2020-07-21 18:55:51,277 INFO] Device cuda
[2020-07-21 18:55:51,300 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:55:53,542 INFO] * number of parameters: 113297921
[2020-07-21 18:55:53,550 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:55:53,552 INFO] origin sent: 7
[2020-07-21 18:56:09,608 INFO] Device ID 0
[2020-07-21 18:56:09,609 INFO] Device cuda
[2020-07-21 18:56:09,633 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:56:11,859 INFO] * number of parameters: 113297921
[2020-07-21 18:56:11,866 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:56:11,868 INFO] origin sent: 7
[2020-07-21 18:56:33,818 INFO] Device ID 0
[2020-07-21 18:56:33,818 INFO] Device cuda
[2020-07-21 18:56:33,849 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:56:36,073 INFO] * number of parameters: 113297921
[2020-07-21 18:56:36,081 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:56:36,083 INFO] origin sent: 7
[2020-07-21 18:56:40,500 INFO] Device ID 0
[2020-07-21 18:56:40,500 INFO] Device cuda
[2020-07-21 18:56:40,522 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:56:42,754 INFO] * number of parameters: 113297921
[2020-07-21 18:56:42,762 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:56:42,764 INFO] origin sent: 7
[2020-07-21 18:56:52,115 INFO] Device ID 0
[2020-07-21 18:56:52,115 INFO] Device cuda
[2020-07-21 18:56:52,142 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:56:54,361 INFO] * number of parameters: 113297921
[2020-07-21 18:56:54,369 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:56:54,371 INFO] origin sent: 7
[2020-07-21 18:57:04,268 INFO] Device ID 0
[2020-07-21 18:57:04,268 INFO] Device cuda
[2020-07-21 18:57:04,291 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:57:06,551 INFO] * number of parameters: 113297921
[2020-07-21 18:57:06,559 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:57:06,561 INFO] origin sent: 7
[2020-07-21 18:57:15,138 INFO] Device ID 0
[2020-07-21 18:57:15,138 INFO] Device cuda
[2020-07-21 18:57:15,162 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 18:57:17,397 INFO] * number of parameters: 113297921
[2020-07-21 18:57:17,405 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 18:57:17,407 INFO] origin sent: 7
[2020-07-21 19:03:59,476 INFO] Device ID 0
[2020-07-21 19:03:59,477 INFO] Device cuda
[2020-07-21 19:03:59,500 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:04:01,801 INFO] * number of parameters: 113297921
[2020-07-21 19:04:01,809 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:04:01,811 INFO] origin sent: 7
[2020-07-21 19:04:02,031 INFO] origin sent: 7
[2020-07-21 19:04:02,076 INFO] origin sent: 7
[2020-07-21 19:04:02,122 INFO] origin sent: 7
[2020-07-21 19:04:02,170 INFO] origin sent: 7
[2020-07-21 19:04:02,215 INFO] origin sent: 7
[2020-07-21 19:04:02,261 INFO] origin sent: 7
[2020-07-21 19:04:02,308 INFO] origin sent: 7
[2020-07-21 19:04:02,348 INFO] origin sent: 7
[2020-07-21 19:04:02,386 INFO] origin sent: 7
[2020-07-21 19:04:02,425 INFO] origin sent: 7
[2020-07-21 19:04:02,465 INFO] origin sent: 7
[2020-07-21 19:04:02,504 INFO] origin sent: 7
[2020-07-21 19:04:02,544 INFO] origin sent: 7
[2020-07-21 19:04:02,584 INFO] origin sent: 7
[2020-07-21 19:04:02,622 INFO] origin sent: 7
[2020-07-21 19:04:02,661 INFO] origin sent: 7
[2020-07-21 19:04:02,701 INFO] origin sent: 7
[2020-07-21 19:04:02,740 INFO] origin sent: 7
[2020-07-21 19:04:02,780 INFO] origin sent: 7
[2020-07-21 19:04:02,822 INFO] origin sent: 7
[2020-07-21 19:04:02,858 INFO] origin sent: 7
[2020-07-21 19:04:02,897 INFO] origin sent: 7
[2020-07-21 19:04:02,937 INFO] origin sent: 7
[2020-07-21 19:04:02,977 INFO] origin sent: 7
[2020-07-21 19:04:03,017 INFO] origin sent: 7
[2020-07-21 19:04:03,057 INFO] origin sent: 7
[2020-07-21 19:04:03,096 INFO] origin sent: 7
[2020-07-21 19:04:03,134 INFO] origin sent: 7
[2020-07-21 19:04:03,174 INFO] origin sent: 7
[2020-07-21 19:04:03,213 INFO] origin sent: 7
[2020-07-21 19:04:03,254 INFO] origin sent: 7
[2020-07-21 19:04:03,293 INFO] origin sent: 7
[2020-07-21 19:04:03,332 INFO] origin sent: 7
[2020-07-21 19:04:03,371 INFO] origin sent: 7
[2020-07-21 19:04:03,409 INFO] origin sent: 7
[2020-07-21 19:04:03,449 INFO] origin sent: 7
[2020-07-21 19:04:03,488 INFO] origin sent: 7
[2020-07-21 19:04:03,527 INFO] origin sent: 7
[2020-07-21 19:04:03,566 INFO] origin sent: 7
[2020-07-21 19:04:03,605 INFO] origin sent: 7
[2020-07-21 19:04:03,644 INFO] origin sent: 7
[2020-07-21 19:04:03,686 INFO] origin sent: 7
[2020-07-21 19:04:03,728 INFO] origin sent: 7
[2020-07-21 19:04:03,768 INFO] origin sent: 7
[2020-07-21 19:04:03,807 INFO] origin sent: 7
[2020-07-21 19:04:03,845 INFO] origin sent: 7
[2020-07-21 19:04:03,884 INFO] origin sent: 7
[2020-07-21 19:04:03,925 INFO] origin sent: 7
[2020-07-21 19:04:03,966 INFO] origin sent: 7
[2020-07-21 19:04:04,005 INFO] origin sent: 7
[2020-07-21 19:04:04,045 INFO] origin sent: 7
[2020-07-21 19:04:04,085 INFO] origin sent: 7
[2020-07-21 19:04:04,124 INFO] origin sent: 7
[2020-07-21 19:04:04,161 INFO] origin sent: 7
[2020-07-21 19:04:04,200 INFO] origin sent: 7
[2020-07-21 19:04:04,238 INFO] origin sent: 8
[2020-07-21 19:04:04,277 INFO] origin sent: 7
[2020-07-21 19:04:04,319 INFO] origin sent: 7
[2020-07-21 19:04:42,842 INFO] Device ID 0
[2020-07-21 19:04:42,842 INFO] Device cuda
[2020-07-21 19:04:42,869 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:04:45,063 INFO] * number of parameters: 113297921
[2020-07-21 19:04:45,070 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:04:50,619 INFO] Writing summaries.
[2020-07-21 19:04:50,619 INFO] Processing summaries. Saving system files to ./temp/tmpfosltxvc\system and model files to ./temp/tmpfosltxvc\model.
[2020-07-21 19:04:50,619 INFO] Processing files in ./temp/rouge-tmp-2020-07-21-19-04-50/candidate/.
[2020-07-21 19:04:51,048 INFO] Saved processed files to ./temp/tmpfosltxvc\system.
[2020-07-21 19:04:51,049 INFO] Processing files in ./temp/rouge-tmp-2020-07-21-19-04-50/reference/.
[2020-07-21 19:04:51,460 INFO] Saved processed files to ./temp/tmpfosltxvc\model.
[2020-07-21 19:04:51,466 INFO] Written ROUGE configuration to ./temp/tmp0xjk1qw9\rouge_conf.xml
[2020-07-21 19:04:51,466 INFO] Running ROUGE with command C:\Users\VY\Desktop\Project\pyrouge\evaluation\ROUGE-RELEASE-1.5.5\ROUGE-1.5.5.pl -e C:\Users\VY\Desktop\Project\pyrouge\evaluation\ROUGE-RELEASE-1.5.5\data -c 95 -m -r 1000 -n 2 -a ./temp/tmp0xjk1qw9\rouge_conf.xml
[2020-07-21 19:05:06,641 INFO] Device ID 0
[2020-07-21 19:05:06,641 INFO] Device cuda
[2020-07-21 19:05:06,664 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:05:08,897 INFO] * number of parameters: 113297921
[2020-07-21 19:05:08,905 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:05:30,715 INFO] Device ID 0
[2020-07-21 19:05:30,715 INFO] Device cuda
[2020-07-21 19:05:30,743 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:05:33,006 INFO] * number of parameters: 113297921
[2020-07-21 19:05:33,013 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:08:28,384 INFO] Device ID 0
[2020-07-21 19:08:28,384 INFO] Device cuda
[2020-07-21 19:08:28,409 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:08:30,663 INFO] * number of parameters: 113297921
[2020-07-21 19:08:30,670 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:09:26,703 INFO] Device ID 0
[2020-07-21 19:09:26,703 INFO] Device cuda
[2020-07-21 19:09:26,727 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:09:28,924 INFO] * number of parameters: 113297921
[2020-07-21 19:09:28,932 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:10:13,478 INFO] Device ID 0
[2020-07-21 19:10:13,479 INFO] Device cuda
[2020-07-21 19:10:13,507 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:10:15,752 INFO] * number of parameters: 113297921
[2020-07-21 19:10:15,760 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:21:38,778 INFO] Device ID 0
[2020-07-21 19:21:38,778 INFO] Device cuda
[2020-07-21 19:21:38,805 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:21:41,025 INFO] * number of parameters: 113297921
[2020-07-21 19:21:41,033 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:21:51,182 INFO] Device ID 0
[2020-07-21 19:21:51,182 INFO] Device cuda
[2020-07-21 19:21:51,204 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:21:53,457 INFO] * number of parameters: 113297921
[2020-07-21 19:21:53,465 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:23:15,266 INFO] Device ID 0
[2020-07-21 19:23:15,266 INFO] Device cuda
[2020-07-21 19:23:15,289 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:23:17,533 INFO] * number of parameters: 113297921
[2020-07-21 19:23:17,541 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:27:41,222 INFO] Device ID 0
[2020-07-21 19:27:41,222 INFO] Device cuda
[2020-07-21 19:27:41,246 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:27:43,496 INFO] * number of parameters: 113297921
[2020-07-21 19:27:43,504 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:28:19,291 INFO] Device ID 0
[2020-07-21 19:28:19,291 INFO] Device cuda
[2020-07-21 19:28:19,320 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:28:21,579 INFO] * number of parameters: 113297921
[2020-07-21 19:28:21,587 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:28:27,204 INFO] Device ID 0
[2020-07-21 19:28:27,204 INFO] Device cuda
[2020-07-21 19:28:27,227 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:28:29,501 INFO] * number of parameters: 113297921
[2020-07-21 19:28:29,508 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:29:21,925 INFO] Device ID 0
[2020-07-21 19:29:21,925 INFO] Device cuda
[2020-07-21 19:29:21,951 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:29:24,213 INFO] * number of parameters: 113297921
[2020-07-21 19:29:24,220 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:29:54,978 INFO] Device ID 0
[2020-07-21 19:29:54,978 INFO] Device cuda
[2020-07-21 19:29:55,006 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:29:57,240 INFO] * number of parameters: 113297921
[2020-07-21 19:29:57,248 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:38:12,349 INFO] Device ID 0
[2020-07-21 19:38:12,349 INFO] Device cuda
[2020-07-21 19:38:12,371 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:38:14,533 INFO] * number of parameters: 113297921
[2020-07-21 19:38:14,540 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:38:39,696 INFO] Device ID 0
[2020-07-21 19:38:39,696 INFO] Device cuda
[2020-07-21 19:38:39,720 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:38:41,920 INFO] * number of parameters: 113297921
[2020-07-21 19:38:41,927 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:38:59,060 INFO] Device ID 0
[2020-07-21 19:38:59,060 INFO] Device cuda
[2020-07-21 19:38:59,083 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:39:01,299 INFO] * number of parameters: 113297921
[2020-07-21 19:39:01,307 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:39:17,916 INFO] Device ID 0
[2020-07-21 19:39:17,916 INFO] Device cuda
[2020-07-21 19:39:17,942 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:39:20,211 INFO] * number of parameters: 113297921
[2020-07-21 19:39:20,218 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:41:00,539 INFO] Device ID 0
[2020-07-21 19:41:00,539 INFO] Device cuda
[2020-07-21 19:41:00,558 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:41:02,961 INFO] * number of parameters: 113297921
[2020-07-21 19:41:02,968 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:41:09,534 INFO] Validation xent: 0.307077 at step 50000
[2020-07-21 19:41:41,515 INFO] Device ID 0
[2020-07-21 19:41:41,515 INFO] Device cuda
[2020-07-21 19:41:41,540 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:41:43,734 INFO] * number of parameters: 113297921
[2020-07-21 19:41:43,741 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:42:07,530 INFO] Device ID 0
[2020-07-21 19:42:07,530 INFO] Device cuda
[2020-07-21 19:42:07,555 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:42:09,820 INFO] * number of parameters: 113297921
[2020-07-21 19:42:09,827 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:42:28,364 INFO] Device ID 0
[2020-07-21 19:42:28,364 INFO] Device cuda
[2020-07-21 19:42:28,387 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:42:30,610 INFO] * number of parameters: 113297921
[2020-07-21 19:42:30,617 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:44:21,517 INFO] Device ID 0
[2020-07-21 19:44:21,517 INFO] Device cuda
[2020-07-21 19:44:21,539 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:44:23,757 INFO] * number of parameters: 113297921
[2020-07-21 19:44:23,765 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:46:08,266 INFO] Device ID 0
[2020-07-21 19:46:08,266 INFO] Device cuda
[2020-07-21 19:46:08,289 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-21 19:46:10,558 INFO] * number of parameters: 113297921
[2020-07-21 19:46:10,565 INFO] Loading test dataset from ./data/oov_data\vy_text.test.0.bert.pt, number of examples: 887
[2020-07-21 19:46:17,060 INFO] Validation xent: 0.307077 at step 50000
[2020-07-22 15:56:46,526 INFO] Device ID 0
[2020-07-22 15:56:46,526 INFO] Device cuda
[2020-07-22 15:56:46,540 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 16:32:43,901 INFO] Device ID 0
[2020-07-22 16:32:43,901 INFO] Device cuda
[2020-07-22 16:32:43,913 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 16:32:43,913 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 16:32:46,299 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 16:32:46,308 INFO] * number of parameters: 113297921
[2020-07-22 16:32:46,308 INFO] Start training...
[2020-07-22 22:25:19,052 INFO] Device ID 0
[2020-07-22 22:25:19,052 INFO] Device cuda
[2020-07-22 22:25:19,065 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:25:19,065 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:25:20,976 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:25:20,981 INFO] * number of parameters: 113297921
[2020-07-22 22:25:20,981 INFO] Start training...
[2020-07-22 22:25:45,273 INFO] Device ID 0
[2020-07-22 22:25:45,273 INFO] Device cuda
[2020-07-22 22:25:45,286 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:25:45,286 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:25:47,192 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:25:47,199 INFO] * number of parameters: 113297921
[2020-07-22 22:25:47,199 INFO] Start training...
[2020-07-22 22:25:47,200 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 22:27:08,643 INFO] Device ID 0
[2020-07-22 22:27:08,643 INFO] Device cuda
[2020-07-22 22:27:08,655 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:27:08,655 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:27:10,563 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:27:10,569 INFO] * number of parameters: 113297921
[2020-07-22 22:27:10,569 INFO] Start training...
[2020-07-22 22:27:10,569 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 22:28:59,283 INFO] Device ID 0
[2020-07-22 22:28:59,284 INFO] Device cuda
[2020-07-22 22:28:59,296 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:28:59,296 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:29:01,248 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:29:01,258 INFO] * number of parameters: 113297921
[2020-07-22 22:29:01,258 INFO] Start training...
[2020-07-22 22:29:01,258 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 22:30:54,305 INFO] Device ID 0
[2020-07-22 22:30:54,305 INFO] Device cuda
[2020-07-22 22:30:54,317 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:30:54,318 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:30:56,248 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:30:56,257 INFO] * number of parameters: 113297921
[2020-07-22 22:30:56,257 INFO] Start training...
[2020-07-22 22:30:56,258 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 22:32:08,572 INFO] Device ID 0
[2020-07-22 22:32:08,572 INFO] Device cuda
[2020-07-22 22:32:08,585 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:32:08,585 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:32:10,502 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:32:10,509 INFO] * number of parameters: 113297921
[2020-07-22 22:32:10,510 INFO] Start training...
[2020-07-22 22:32:10,510 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 22:32:23,184 INFO] Device ID 0
[2020-07-22 22:32:23,184 INFO] Device cuda
[2020-07-22 22:32:23,198 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:32:23,198 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:32:25,104 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:32:25,112 INFO] * number of parameters: 113297921
[2020-07-22 22:32:25,113 INFO] Start training...
[2020-07-22 22:33:30,852 INFO] Device ID 0
[2020-07-22 22:33:30,852 INFO] Device cuda
[2020-07-22 22:33:30,864 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 22:33:30,865 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 22:33:32,800 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 22:33:32,811 INFO] * number of parameters: 113297921
[2020-07-22 22:33:32,811 INFO] Start training...
[2020-07-22 23:46:39,946 INFO] Device ID 0
[2020-07-22 23:46:39,946 INFO] Device cuda
[2020-07-22 23:46:39,959 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 23:46:39,959 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 23:46:41,921 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 23:46:41,926 INFO] * number of parameters: 113297921
[2020-07-22 23:46:41,927 INFO] Start training...
[2020-07-22 23:46:41,927 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 23:46:41,977 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 5
[2020-07-22 23:48:35,389 INFO] Device ID 0
[2020-07-22 23:48:35,390 INFO] Device cuda
[2020-07-22 23:48:35,402 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 23:48:35,402 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 23:48:37,323 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 23:48:37,333 INFO] * number of parameters: 113297921
[2020-07-22 23:48:37,333 INFO] Start training...
[2020-07-22 23:48:37,333 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 10
[2020-07-22 23:59:05,430 INFO] Device ID 0
[2020-07-22 23:59:05,430 INFO] Device cuda
[2020-07-22 23:59:05,443 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 23:59:05,443 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 23:59:22,954 INFO] Device ID 0
[2020-07-22 23:59:22,954 INFO] Device cuda
[2020-07-22 23:59:22,967 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-22 23:59:22,967 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-22 23:59:24,885 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-22 23:59:24,890 INFO] * number of parameters: 113297921
[2020-07-22 23:59:24,891 INFO] Start training...
[2020-07-22 23:59:24,908 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 2000
[2020-07-23 00:15:05,799 INFO] Device ID 0
[2020-07-23 00:15:05,799 INFO] Device cuda
[2020-07-23 00:15:05,812 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:15:05,812 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:15:07,753 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:15:07,760 INFO] * number of parameters: 113297921
[2020-07-23 00:15:07,761 INFO] Start training...
[2020-07-23 00:15:07,778 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 2000
[2020-07-23 00:20:14,793 INFO] Device ID 0
[2020-07-23 00:20:14,793 INFO] Device cuda
[2020-07-23 00:20:14,805 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:20:14,805 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:20:16,767 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:20:16,775 INFO] * number of parameters: 113297921
[2020-07-23 00:20:16,775 INFO] Start training...
[2020-07-23 00:20:16,901 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:22:13,296 INFO] Device ID 0
[2020-07-23 00:22:13,296 INFO] Device cuda
[2020-07-23 00:22:13,309 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:22:13,309 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:22:15,286 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:22:15,293 INFO] * number of parameters: 113297921
[2020-07-23 00:22:15,294 INFO] Start training...
[2020-07-23 00:22:15,421 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:27:15,313 INFO] Device ID 0
[2020-07-23 00:27:15,313 INFO] Device cuda
[2020-07-23 00:27:15,325 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:27:15,326 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:27:17,271 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:27:17,277 INFO] * number of parameters: 113297921
[2020-07-23 00:27:17,278 INFO] Start training...
[2020-07-23 00:27:17,411 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:30:11,886 INFO] Device ID 0
[2020-07-23 00:30:11,886 INFO] Device cuda
[2020-07-23 00:30:11,898 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:30:11,898 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:30:13,818 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:30:13,825 INFO] * number of parameters: 113297921
[2020-07-23 00:30:13,826 INFO] Start training...
[2020-07-23 00:30:13,960 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:30:30,564 INFO] Device ID 0
[2020-07-23 00:30:30,564 INFO] Device cuda
[2020-07-23 00:30:30,577 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:30:30,577 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:30:32,487 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:30:32,497 INFO] * number of parameters: 113297921
[2020-07-23 00:30:32,498 INFO] Start training...
[2020-07-23 00:30:32,623 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:30:46,958 INFO] Device ID 0
[2020-07-23 00:30:46,958 INFO] Device cuda
[2020-07-23 00:30:46,970 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:30:46,971 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:30:48,914 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:30:48,922 INFO] * number of parameters: 113297921
[2020-07-23 00:30:48,923 INFO] Start training...
[2020-07-23 00:30:49,048 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:31:33,088 INFO] Device ID 0
[2020-07-23 00:31:33,088 INFO] Device cuda
[2020-07-23 00:31:33,101 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:31:33,101 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:31:35,028 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:31:35,038 INFO] * number of parameters: 113297921
[2020-07-23 00:31:35,038 INFO] Start training...
[2020-07-23 00:31:35,164 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:32:11,208 INFO] Device ID 0
[2020-07-23 00:32:11,208 INFO] Device cuda
[2020-07-23 00:32:11,224 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:32:11,225 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:32:13,144 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:32:13,151 INFO] * number of parameters: 113297921
[2020-07-23 00:32:13,152 INFO] Start training...
[2020-07-23 00:32:13,279 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:34:33,390 INFO] Device ID 0
[2020-07-23 00:34:33,390 INFO] Device cuda
[2020-07-23 00:34:33,403 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:34:33,403 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:34:35,311 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:34:35,317 INFO] * number of parameters: 113297921
[2020-07-23 00:34:35,318 INFO] Start training...
[2020-07-23 00:34:35,442 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:39:08,598 INFO] Device ID 0
[2020-07-23 00:39:08,598 INFO] Device cuda
[2020-07-23 00:39:08,611 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:39:08,611 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:39:10,590 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:39:10,595 INFO] * number of parameters: 113297921
[2020-07-23 00:39:10,596 INFO] Start training...
[2020-07-23 00:39:10,722 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:43:29,040 INFO] Device ID 0
[2020-07-23 00:43:29,041 INFO] Device cuda
[2020-07-23 00:43:29,059 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:43:29,060 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:43:30,995 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:43:31,003 INFO] * number of parameters: 113297921
[2020-07-23 00:43:31,003 INFO] Start training...
[2020-07-23 00:43:31,130 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:44:08,533 INFO] Device ID 0
[2020-07-23 00:44:08,533 INFO] Device cuda
[2020-07-23 00:44:08,546 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:44:08,546 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:44:10,492 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:44:10,499 INFO] * number of parameters: 113297921
[2020-07-23 00:44:10,499 INFO] Start training...
[2020-07-23 00:44:10,625 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:44:21,524 INFO] Device ID 0
[2020-07-23 00:44:21,524 INFO] Device cuda
[2020-07-23 00:44:21,537 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:44:21,537 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:44:23,475 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:44:23,484 INFO] * number of parameters: 113297921
[2020-07-23 00:44:23,485 INFO] Start training...
[2020-07-23 00:44:23,610 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:46:34,661 INFO] Device ID 0
[2020-07-23 00:46:34,661 INFO] Device cuda
[2020-07-23 00:46:34,674 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:46:34,674 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:46:36,605 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:46:36,612 INFO] * number of parameters: 113297921
[2020-07-23 00:46:36,613 INFO] Start training...
[2020-07-23 00:46:36,737 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:46:56,937 INFO] Device ID 0
[2020-07-23 00:46:56,937 INFO] Device cuda
[2020-07-23 00:46:56,950 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:46:56,951 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:46:58,892 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:46:58,902 INFO] * number of parameters: 113297921
[2020-07-23 00:46:58,903 INFO] Start training...
[2020-07-23 00:46:59,032 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:47:51,537 INFO] Device ID 0
[2020-07-23 00:47:51,537 INFO] Device cuda
[2020-07-23 00:47:51,549 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:47:51,549 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:47:53,487 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:47:53,494 INFO] * number of parameters: 113297921
[2020-07-23 00:47:53,495 INFO] Start training...
[2020-07-23 00:47:53,620 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:48:16,893 INFO] Device ID 0
[2020-07-23 00:48:16,893 INFO] Device cuda
[2020-07-23 00:48:16,905 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:48:16,906 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:48:18,841 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:48:18,850 INFO] * number of parameters: 113297921
[2020-07-23 00:48:18,850 INFO] Start training...
[2020-07-23 00:48:18,979 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:49:04,933 INFO] Device ID 0
[2020-07-23 00:49:04,933 INFO] Device cuda
[2020-07-23 00:49:04,945 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:49:04,946 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:49:06,897 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:49:06,907 INFO] * number of parameters: 113297921
[2020-07-23 00:49:06,908 INFO] Start training...
[2020-07-23 00:49:07,036 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 00:49:59,736 INFO] Device ID 0
[2020-07-23 00:49:59,736 INFO] Device cuda
[2020-07-23 00:49:59,748 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 00:49:59,749 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 00:50:01,674 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 00:50:01,683 INFO] * number of parameters: 113297921
[2020-07-23 00:50:01,684 INFO] Start training...
[2020-07-23 00:50:01,807 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.1.bert.pt, number of examples: 10000
[2020-07-23 15:44:54,167 INFO] Device ID 0
[2020-07-23 15:44:54,167 INFO] Device cuda
[2020-07-23 15:44:54,193 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 15:44:54,194 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 15:44:56,765 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 15:44:56,776 INFO] * number of parameters: 113297921
[2020-07-23 15:44:56,776 INFO] Start training...
[2020-07-23 15:44:56,797 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 17:46:45,697 INFO] Device ID 0
[2020-07-23 17:46:45,698 INFO] Device cuda
[2020-07-23 17:46:45,711 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 17:46:45,711 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 17:46:47,653 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 17:46:47,663 INFO] * number of parameters: 113297921
[2020-07-23 17:46:47,664 INFO] Start training...
[2020-07-23 17:46:47,684 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 17:47:02,836 INFO] Device ID 0
[2020-07-23 17:47:02,837 INFO] Device cuda
[2020-07-23 17:47:02,850 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 17:47:02,851 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 17:47:04,806 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 17:47:04,814 INFO] * number of parameters: 113297921
[2020-07-23 17:47:04,814 INFO] Start training...
[2020-07-23 17:47:04,835 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 17:52:58,316 INFO] Device ID 0
[2020-07-23 17:52:58,316 INFO] Device cuda
[2020-07-23 17:52:58,329 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 17:52:58,329 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 17:53:00,278 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 17:53:00,289 INFO] * number of parameters: 113297921
[2020-07-23 17:53:00,289 INFO] Start training...
[2020-07-23 17:53:00,309 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 17:59:27,973 INFO] Device ID 0
[2020-07-23 17:59:27,973 INFO] Device cuda
[2020-07-23 17:59:27,986 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 17:59:27,986 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 17:59:29,930 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 17:59:29,941 INFO] * number of parameters: 113297921
[2020-07-23 17:59:29,941 INFO] Start training...
[2020-07-23 17:59:29,961 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:00:14,497 INFO] Device ID 0
[2020-07-23 18:00:14,497 INFO] Device cuda
[2020-07-23 18:00:14,510 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:00:14,511 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:00:16,447 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:00:16,458 INFO] * number of parameters: 113297921
[2020-07-23 18:00:16,458 INFO] Start training...
[2020-07-23 18:00:16,477 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:02:01,089 INFO] Device ID 0
[2020-07-23 18:02:01,089 INFO] Device cuda
[2020-07-23 18:02:01,101 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:02:01,102 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:02:03,028 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:02:03,035 INFO] * number of parameters: 113297921
[2020-07-23 18:02:03,035 INFO] Start training...
[2020-07-23 18:02:03,056 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:02:20,338 INFO] Device ID 0
[2020-07-23 18:02:20,338 INFO] Device cuda
[2020-07-23 18:02:20,353 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:02:20,353 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:02:22,394 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:02:22,400 INFO] * number of parameters: 113297921
[2020-07-23 18:02:22,400 INFO] Start training...
[2020-07-23 18:02:22,422 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:02:48,491 INFO] Device ID 0
[2020-07-23 18:02:48,491 INFO] Device cuda
[2020-07-23 18:02:48,504 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:02:48,504 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:02:50,435 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:02:50,441 INFO] * number of parameters: 113297921
[2020-07-23 18:02:50,441 INFO] Start training...
[2020-07-23 18:02:50,460 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:03:02,519 INFO] Device ID 0
[2020-07-23 18:03:02,520 INFO] Device cuda
[2020-07-23 18:03:02,533 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:03:02,533 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:03:04,508 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:03:04,519 INFO] * number of parameters: 113297921
[2020-07-23 18:03:04,519 INFO] Start training...
[2020-07-23 18:03:04,539 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:03:18,056 INFO] Device ID 0
[2020-07-23 18:03:18,056 INFO] Device cuda
[2020-07-23 18:03:18,069 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:03:18,069 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:03:20,042 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:03:20,053 INFO] * number of parameters: 113297921
[2020-07-23 18:03:20,053 INFO] Start training...
[2020-07-23 18:03:20,074 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:03:39,448 INFO] Device ID 0
[2020-07-23 18:03:39,448 INFO] Device cuda
[2020-07-23 18:03:39,462 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:03:39,462 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:03:41,432 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:03:41,440 INFO] * number of parameters: 113297921
[2020-07-23 18:03:41,440 INFO] Start training...
[2020-07-23 18:03:41,461 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:04:03,528 INFO] Device ID 0
[2020-07-23 18:04:03,528 INFO] Device cuda
[2020-07-23 18:04:03,541 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:04:03,541 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:04:05,465 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:04:05,475 INFO] * number of parameters: 113297921
[2020-07-23 18:04:05,475 INFO] Start training...
[2020-07-23 18:04:05,496 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:07:02,237 INFO] Device ID 0
[2020-07-23 18:07:02,238 INFO] Device cuda
[2020-07-23 18:07:02,251 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:07:02,251 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:07:04,189 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:07:04,200 INFO] * number of parameters: 113297921
[2020-07-23 18:07:04,200 INFO] Start training...
[2020-07-23 18:07:04,219 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:10:27,720 INFO] Device ID 0
[2020-07-23 18:10:27,720 INFO] Device cuda
[2020-07-23 18:10:27,733 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:10:27,734 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:10:29,719 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:10:29,725 INFO] * number of parameters: 113297921
[2020-07-23 18:10:29,725 INFO] Start training...
[2020-07-23 18:10:29,746 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:11:52,247 INFO] Device ID 0
[2020-07-23 18:11:52,248 INFO] Device cuda
[2020-07-23 18:11:52,261 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:11:52,262 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:11:54,206 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:11:54,214 INFO] * number of parameters: 113297921
[2020-07-23 18:11:54,214 INFO] Start training...
[2020-07-23 18:11:54,215 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:11:56,437 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:11:58,514 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:00,347 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:02,453 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:04,243 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:06,419 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:08,261 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:09,728 INFO] Step 50/50000; xent: 2.57; lr: 0.0000001;  96 docs/s;     16 sec
[2020-07-23 18:12:10,412 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:12,224 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:14,330 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:16,178 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:18,290 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:12:20,118 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 97
[2020-07-23 18:13:12,747 INFO] Device ID 0
[2020-07-23 18:13:12,747 INFO] Device cuda
[2020-07-23 18:13:12,761 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:13:12,761 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:13:14,752 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:13:14,758 INFO] * number of parameters: 113297921
[2020-07-23 18:13:14,758 INFO] Start training...
[2020-07-23 18:13:14,890 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 9924
[2020-07-23 18:13:30,261 INFO] Step 50/50000; xent: 2.48; lr: 0.0000001;  98 docs/s;     15 sec
[2020-07-23 18:13:45,280 INFO] Step 100/50000; xent: 2.40; lr: 0.0000003;  99 docs/s;     30 sec
[2020-07-23 18:14:00,433 INFO] Step 150/50000; xent: 2.44; lr: 0.0000004;  98 docs/s;     46 sec
[2020-07-23 18:14:15,542 INFO] Step 200/50000; xent: 2.36; lr: 0.0000006; 100 docs/s;     61 sec
[2020-07-23 18:14:30,644 INFO] Step 250/50000; xent: 2.38; lr: 0.0000007;  98 docs/s;     76 sec
[2020-07-23 18:14:45,828 INFO] Step 300/50000; xent: 2.33; lr: 0.0000008;  98 docs/s;     91 sec
[2020-07-23 18:15:00,820 INFO] Step 350/50000; xent: 2.36; lr: 0.0000010;  98 docs/s;    106 sec
[2020-07-23 18:15:16,075 INFO] Step 400/50000; xent: 2.32; lr: 0.0000011;  99 docs/s;    121 sec
[2020-07-23 18:15:31,274 INFO] Step 450/50000; xent: 2.34; lr: 0.0000013;  98 docs/s;    136 sec
[2020-07-23 18:15:46,493 INFO] Step 500/50000; xent: 2.29; lr: 0.0000014;  99 docs/s;    152 sec
[2020-07-23 18:16:01,700 INFO] Step 550/50000; xent: 2.38; lr: 0.0000015; 100 docs/s;    167 sec
[2020-07-23 18:16:16,937 INFO] Step 600/50000; xent: 2.31; lr: 0.0000017;  98 docs/s;    182 sec
[2020-07-23 18:16:32,321 INFO] Step 650/50000; xent: 2.31; lr: 0.0000018;  98 docs/s;    197 sec
[2020-07-23 18:16:36,490 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.0.bert.pt, number of examples: 9924
[2020-07-23 18:16:47,731 INFO] Step 700/50000; xent: 2.30; lr: 0.0000020;  96 docs/s;    213 sec
[2020-07-23 18:17:02,863 INFO] Step 750/50000; xent: 2.29; lr: 0.0000021;  98 docs/s;    228 sec
[2020-07-23 18:17:18,279 INFO] Step 800/50000; xent: 2.31; lr: 0.0000022;  99 docs/s;    243 sec
[2020-07-23 18:17:33,712 INFO] Step 850/50000; xent: 2.30; lr: 0.0000024;  98 docs/s;    259 sec
[2020-07-23 18:17:49,094 INFO] Step 900/50000; xent: 2.31; lr: 0.0000025;  99 docs/s;    274 sec
[2020-07-23 18:18:21,693 INFO] Device ID 0
[2020-07-23 18:18:21,693 INFO] Device cuda
[2020-07-23 18:18:21,707 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-23 18:18:21,707 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-23 18:18:23,749 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-23 18:18:23,758 INFO] * number of parameters: 113297921
[2020-07-23 18:18:23,758 INFO] Start training...
[2020-07-23 18:18:23,777 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-23 18:18:39,372 INFO] Step 50/50000; xent: 2.24; lr: 0.0000001; 101 docs/s;     16 sec
[2020-07-23 18:18:54,856 INFO] Step 100/50000; xent: 2.08; lr: 0.0000003; 101 docs/s;     31 sec
[2020-07-23 18:19:03,272 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.849.bert.pt, number of examples: 1995
[2020-07-23 18:19:10,288 INFO] Step 150/50000; xent: 2.20; lr: 0.0000004; 102 docs/s;     47 sec
[2020-07-23 18:19:25,614 INFO] Step 200/50000; xent: 2.20; lr: 0.0000006; 104 docs/s;     62 sec
[2020-07-23 18:19:41,189 INFO] Step 250/50000; xent: 2.14; lr: 0.0000007; 103 docs/s;     77 sec
[2020-07-23 18:19:41,846 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.678.bert.pt, number of examples: 1996
[2020-07-23 18:19:56,685 INFO] Step 300/50000; xent: 2.12; lr: 0.0000008;  99 docs/s;     93 sec
[2020-07-23 18:20:11,933 INFO] Step 350/50000; xent: 2.11; lr: 0.0000010;  99 docs/s;    108 sec
[2020-07-23 18:20:22,027 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.320.bert.pt, number of examples: 2001
[2020-07-23 18:20:27,181 INFO] Step 400/50000; xent: 2.10; lr: 0.0000011; 101 docs/s;    123 sec
[2020-07-23 18:20:42,295 INFO] Step 450/50000; xent: 2.06; lr: 0.0000013; 102 docs/s;    139 sec
[2020-07-23 18:20:57,784 INFO] Step 500/50000; xent: 2.07; lr: 0.0000014; 101 docs/s;    154 sec
[2020-07-23 18:21:01,477 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.983.bert.pt, number of examples: 2000
[2020-07-23 18:21:13,129 INFO] Step 550/50000; xent: 2.18; lr: 0.0000015; 100 docs/s;    169 sec
[2020-07-23 18:21:28,526 INFO] Step 600/50000; xent: 2.17; lr: 0.0000017; 100 docs/s;    185 sec
[2020-07-23 18:21:41,946 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.206.bert.pt, number of examples: 1997
[2020-07-23 18:21:44,435 INFO] Step 650/50000; xent: 2.17; lr: 0.0000018;  96 docs/s;    201 sec
[2020-07-23 18:21:59,879 INFO] Step 700/50000; xent: 2.16; lr: 0.0000020; 102 docs/s;    216 sec
[2020-07-23 18:22:15,086 INFO] Step 750/50000; xent: 2.22; lr: 0.0000021; 102 docs/s;    231 sec
[2020-07-23 18:22:21,233 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.412.bert.pt, number of examples: 1992
[2020-07-23 18:22:30,405 INFO] Step 800/50000; xent: 2.16; lr: 0.0000022; 102 docs/s;    247 sec
[2020-07-23 18:22:45,755 INFO] Step 850/50000; xent: 2.13; lr: 0.0000024; 100 docs/s;    262 sec
[2020-07-23 18:23:00,509 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.314.bert.pt, number of examples: 1995
[2020-07-23 18:23:01,123 INFO] Step 900/50000; xent: 2.15; lr: 0.0000025; 102 docs/s;    277 sec
[2020-07-23 18:23:16,536 INFO] Step 950/50000; xent: 2.12; lr: 0.0000027; 102 docs/s;    293 sec
[2020-07-23 18:23:32,282 INFO] Step 1000/50000; xent: 2.11; lr: 0.0000028; 101 docs/s;    309 sec
[2020-07-23 18:23:39,862 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.982.bert.pt, number of examples: 1993
[2020-07-23 18:23:47,592 INFO] Step 1050/50000; xent: 2.11; lr: 0.0000029; 102 docs/s;    324 sec
[2020-07-23 18:24:02,776 INFO] Step 1100/50000; xent: 2.12; lr: 0.0000031; 102 docs/s;    339 sec
[2020-07-23 18:24:18,191 INFO] Step 1150/50000; xent: 2.21; lr: 0.0000032; 101 docs/s;    354 sec
[2020-07-23 18:24:19,175 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.346.bert.pt, number of examples: 1994
[2020-07-23 18:24:33,691 INFO] Step 1200/50000; xent: 2.06; lr: 0.0000034; 100 docs/s;    370 sec
[2020-07-23 18:24:49,088 INFO] Step 1250/50000; xent: 2.12; lr: 0.0000035; 100 docs/s;    385 sec
[2020-07-23 18:24:58,876 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.325.bert.pt, number of examples: 1994
[2020-07-23 18:25:04,379 INFO] Step 1300/50000; xent: 2.07; lr: 0.0000036; 102 docs/s;    401 sec
[2020-07-23 18:25:19,590 INFO] Step 1350/50000; xent: 2.04; lr: 0.0000038; 104 docs/s;    416 sec
[2020-07-23 18:25:35,113 INFO] Step 1400/50000; xent: 2.04; lr: 0.0000039; 102 docs/s;    431 sec
[2020-07-23 18:25:37,704 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.732.bert.pt, number of examples: 1985
[2020-07-23 18:25:50,713 INFO] Step 1450/50000; xent: 2.10; lr: 0.0000041;  99 docs/s;    447 sec
[2020-07-23 18:26:05,964 INFO] Step 1500/50000; xent: 2.08; lr: 0.0000042; 103 docs/s;    462 sec
[2020-07-23 18:26:17,236 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.871.bert.pt, number of examples: 1999
[2020-07-23 18:26:21,615 INFO] Step 1550/50000; xent: 2.07; lr: 0.0000043; 100 docs/s;    478 sec
[2020-07-23 18:26:37,228 INFO] Step 1600/50000; xent: 1.96; lr: 0.0000045; 102 docs/s;    493 sec
[2020-07-23 18:26:52,761 INFO] Step 1650/50000; xent: 1.95; lr: 0.0000046; 104 docs/s;    509 sec
[2020-07-23 18:26:55,870 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.860.bert.pt, number of examples: 2000
[2020-07-23 18:27:08,121 INFO] Step 1700/50000; xent: 2.04; lr: 0.0000048; 103 docs/s;    524 sec
[2020-07-23 18:27:23,572 INFO] Step 1750/50000; xent: 1.95; lr: 0.0000049; 103 docs/s;    540 sec
[2020-07-23 18:27:34,788 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.427.bert.pt, number of examples: 1988
[2020-07-23 18:27:39,056 INFO] Step 1800/50000; xent: 1.98; lr: 0.0000050; 102 docs/s;    555 sec
[2020-07-23 18:27:54,438 INFO] Step 1850/50000; xent: 2.09; lr: 0.0000052;  97 docs/s;    571 sec
[2020-07-23 18:28:09,945 INFO] Step 1900/50000; xent: 2.09; lr: 0.0000053;  99 docs/s;    586 sec
[2020-07-23 18:28:15,181 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.173.bert.pt, number of examples: 1998
[2020-07-23 18:28:25,231 INFO] Step 1950/50000; xent: 2.10; lr: 0.0000055; 100 docs/s;    601 sec
[2020-07-23 18:28:40,906 INFO] Step 2000/50000; xent: 2.06; lr: 0.0000056;  99 docs/s;    617 sec
[2020-07-23 18:28:55,400 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.707.bert.pt, number of examples: 1999
[2020-07-23 18:28:56,328 INFO] Step 2050/50000; xent: 2.04; lr: 0.0000057;  99 docs/s;    633 sec
[2020-07-23 18:29:11,793 INFO] Step 2100/50000; xent: 2.17; lr: 0.0000059; 101 docs/s;    648 sec
[2020-07-23 18:29:27,060 INFO] Step 2150/50000; xent: 2.14; lr: 0.0000060; 103 docs/s;    663 sec
[2020-07-23 18:29:34,439 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.647.bert.pt, number of examples: 1998
[2020-07-23 18:29:42,446 INFO] Step 2200/50000; xent: 2.08; lr: 0.0000061; 102 docs/s;    679 sec
[2020-07-23 18:29:57,868 INFO] Step 2250/50000; xent: 2.00; lr: 0.0000063; 101 docs/s;    694 sec
[2020-07-23 18:30:13,169 INFO] Step 2300/50000; xent: 2.07; lr: 0.0000064; 100 docs/s;    709 sec
[2020-07-23 18:30:14,127 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.171.bert.pt, number of examples: 2000
[2020-07-23 18:30:28,599 INFO] Step 2350/50000; xent: 2.02; lr: 0.0000066; 101 docs/s;    725 sec
[2020-07-23 18:30:44,027 INFO] Step 2400/50000; xent: 2.03; lr: 0.0000067; 102 docs/s;    740 sec
[2020-07-23 18:30:53,268 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.690.bert.pt, number of examples: 1992
[2020-07-23 18:30:59,356 INFO] Step 2450/50000; xent: 1.99; lr: 0.0000068; 100 docs/s;    756 sec
[2020-07-23 18:31:14,776 INFO] Step 2500/50000; xent: 1.97; lr: 0.0000070;  99 docs/s;    771 sec
[2020-07-23 18:31:30,005 INFO] Step 2550/50000; xent: 1.98; lr: 0.0000071; 100 docs/s;    786 sec
[2020-07-23 18:31:33,397 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.68.bert.pt, number of examples: 1996
[2020-07-23 18:31:45,557 INFO] Step 2600/50000; xent: 2.07; lr: 0.0000073; 100 docs/s;    802 sec
[2020-07-23 18:32:01,017 INFO] Step 2650/50000; xent: 2.06; lr: 0.0000074; 102 docs/s;    817 sec
[2020-07-23 18:32:13,080 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.339.bert.pt, number of examples: 1998
[2020-07-23 18:32:16,432 INFO] Step 2700/50000; xent: 2.00; lr: 0.0000075; 100 docs/s;    833 sec
[2020-07-23 18:32:31,950 INFO] Step 2750/50000; xent: 2.07; lr: 0.0000077;  99 docs/s;    848 sec
[2020-07-23 18:32:47,360 INFO] Step 2800/50000; xent: 2.03; lr: 0.0000078;  99 docs/s;    864 sec
[2020-07-23 18:32:53,497 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.646.bert.pt, number of examples: 1993
[2020-07-23 18:33:02,683 INFO] Step 2850/50000; xent: 2.17; lr: 0.0000080;  98 docs/s;    879 sec
[2020-07-23 18:33:18,006 INFO] Step 2900/50000; xent: 2.05; lr: 0.0000081;  99 docs/s;    894 sec
[2020-07-23 18:33:33,187 INFO] Step 2950/50000; xent: 2.15; lr: 0.0000082;  97 docs/s;    909 sec
[2020-07-23 18:33:34,137 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.47.bert.pt, number of examples: 1995
[2020-07-23 18:33:48,538 INFO] Step 3000/50000; xent: 2.05; lr: 0.0000084; 102 docs/s;    925 sec
[2020-07-23 18:34:03,785 INFO] Step 3050/50000; xent: 2.04; lr: 0.0000085; 103 docs/s;    940 sec
[2020-07-23 18:34:13,234 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.616.bert.pt, number of examples: 1998
[2020-07-23 18:34:18,930 INFO] Step 3100/50000; xent: 2.07; lr: 0.0000087; 102 docs/s;    955 sec
[2020-07-23 18:34:34,307 INFO] Step 3150/50000; xent: 2.16; lr: 0.0000088;  99 docs/s;    971 sec
[2020-07-23 18:34:49,782 INFO] Step 3200/50000; xent: 2.20; lr: 0.0000089; 100 docs/s;    986 sec
[2020-07-23 18:34:53,107 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.989.bert.pt, number of examples: 1999
[2020-07-23 18:35:04,981 INFO] Step 3250/50000; xent: 2.04; lr: 0.0000091; 104 docs/s;   1001 sec
[2020-07-23 18:35:20,178 INFO] Step 3300/50000; xent: 2.05; lr: 0.0000092; 102 docs/s;   1016 sec
[2020-07-23 18:35:31,461 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.130.bert.pt, number of examples: 1996
[2020-07-23 18:35:35,384 INFO] Step 3350/50000; xent: 1.96; lr: 0.0000094; 104 docs/s;   1032 sec
[2020-07-23 18:35:50,604 INFO] Step 3400/50000; xent: 2.00; lr: 0.0000095; 103 docs/s;   1047 sec
[2020-07-23 18:36:05,805 INFO] Step 3450/50000; xent: 1.93; lr: 0.0000096; 104 docs/s;   1062 sec
[2020-07-23 18:36:10,328 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.66.bert.pt, number of examples: 2001
[2020-07-23 18:36:20,946 INFO] Step 3500/50000; xent: 1.93; lr: 0.0000098; 105 docs/s;   1077 sec
[2020-07-23 18:36:36,060 INFO] Step 3550/50000; xent: 1.98; lr: 0.0000099; 103 docs/s;   1092 sec
[2020-07-23 18:36:48,749 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.865.bert.pt, number of examples: 1996
[2020-07-23 18:36:51,173 INFO] Step 3600/50000; xent: 2.02; lr: 0.0000101; 104 docs/s;   1107 sec
[2020-07-23 18:37:06,283 INFO] Step 3650/50000; xent: 2.00; lr: 0.0000102; 102 docs/s;   1123 sec
[2020-07-23 18:37:21,458 INFO] Step 3700/50000; xent: 1.95; lr: 0.0000103; 103 docs/s;   1138 sec
[2020-07-23 18:37:27,546 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.884.bert.pt, number of examples: 1995
[2020-07-23 18:37:36,704 INFO] Step 3750/50000; xent: 1.84; lr: 0.0000105; 103 docs/s;   1153 sec
[2020-07-23 18:37:51,900 INFO] Step 3800/50000; xent: 1.77; lr: 0.0000106; 104 docs/s;   1168 sec
[2020-07-23 18:38:06,171 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.42.bert.pt, number of examples: 1998
[2020-07-23 18:38:07,086 INFO] Step 3850/50000; xent: 1.70; lr: 0.0000108; 103 docs/s;   1183 sec
[2020-07-23 18:38:22,344 INFO] Step 3900/50000; xent: 1.69; lr: 0.0000109; 101 docs/s;   1199 sec
[2020-07-23 18:38:37,579 INFO] Step 3950/50000; xent: 1.65; lr: 0.0000110; 101 docs/s;   1214 sec
[2020-07-23 18:38:45,754 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.129.bert.pt, number of examples: 1992
[2020-07-23 18:38:52,672 INFO] Step 4000/50000; xent: 1.66; lr: 0.0000112; 102 docs/s;   1229 sec
[2020-07-23 18:39:07,847 INFO] Step 4050/50000; xent: 1.62; lr: 0.0000113; 105 docs/s;   1244 sec
[2020-07-23 18:39:23,054 INFO] Step 4100/50000; xent: 1.61; lr: 0.0000115; 103 docs/s;   1259 sec
[2020-07-23 18:39:24,027 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.94.bert.pt, number of examples: 1998
[2020-07-23 18:39:38,376 INFO] Step 4150/50000; xent: 1.60; lr: 0.0000116; 102 docs/s;   1275 sec
[2020-07-23 18:39:53,539 INFO] Step 4200/50000; xent: 1.67; lr: 0.0000117; 103 docs/s;   1290 sec
[2020-07-23 18:40:03,219 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.198.bert.pt, number of examples: 1998
[2020-07-23 18:40:09,095 INFO] Step 4250/50000; xent: 1.62; lr: 0.0000119; 100 docs/s;   1305 sec
[2020-07-23 18:40:24,466 INFO] Step 4300/50000; xent: 1.71; lr: 0.0000120; 101 docs/s;   1321 sec
[2020-07-23 18:40:39,670 INFO] Step 4350/50000; xent: 1.73; lr: 0.0000122; 102 docs/s;   1336 sec
[2020-07-23 18:40:42,746 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.775.bert.pt, number of examples: 2001
[2020-07-23 18:40:54,979 INFO] Step 4400/50000; xent: 1.79; lr: 0.0000123; 102 docs/s;   1351 sec
[2020-07-23 18:41:10,157 INFO] Step 4450/50000; xent: 1.86; lr: 0.0000124; 101 docs/s;   1366 sec
[2020-07-23 18:41:22,035 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.903.bert.pt, number of examples: 1996
[2020-07-23 18:41:25,328 INFO] Step 4500/50000; xent: 1.82; lr: 0.0000126; 101 docs/s;   1382 sec
[2020-07-23 18:41:40,557 INFO] Step 4550/50000; xent: 1.77; lr: 0.0000127; 101 docs/s;   1397 sec
[2020-07-23 18:41:55,767 INFO] Step 4600/50000; xent: 1.74; lr: 0.0000129; 102 docs/s;   1412 sec
[2020-07-23 18:42:01,604 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.504.bert.pt, number of examples: 1982
[2020-07-23 18:42:11,106 INFO] Step 4650/50000; xent: 1.73; lr: 0.0000130;  98 docs/s;   1427 sec
[2020-07-23 18:42:26,267 INFO] Step 4700/50000; xent: 1.42; lr: 0.0000131;  99 docs/s;   1442 sec
[2020-07-23 18:42:41,450 INFO] Step 4750/50000; xent: 1.48; lr: 0.0000133;  96 docs/s;   1458 sec
[2020-07-23 18:42:42,407 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.803.bert.pt, number of examples: 1999
[2020-07-23 18:42:56,650 INFO] Step 4800/50000; xent: 1.65; lr: 0.0000134; 102 docs/s;   1473 sec
[2020-07-23 18:43:11,802 INFO] Step 4850/50000; xent: 1.62; lr: 0.0000136; 102 docs/s;   1488 sec
[2020-07-23 18:43:21,590 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.127.bert.pt, number of examples: 1998
[2020-07-23 18:43:27,177 INFO] Step 4900/50000; xent: 1.62; lr: 0.0000137; 101 docs/s;   1503 sec
[2020-07-23 18:43:42,318 INFO] Step 4950/50000; xent: 1.53; lr: 0.0000138; 102 docs/s;   1519 sec
[2020-07-23 18:43:57,351 INFO] Step 5000/50000; xent: 1.53; lr: 0.0000140; 102 docs/s;   1534 sec
[2020-07-23 18:43:57,352 INFO] Saving checkpoint ./models/models_check_points/model_step_5000.pt
[2020-07-23 18:44:01,533 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.457.bert.pt, number of examples: 1996
[2020-07-23 18:44:13,415 INFO] Step 5050/50000; xent: 1.58; lr: 0.0000141;  99 docs/s;   1550 sec
[2020-07-23 18:44:28,626 INFO] Step 5100/50000; xent: 1.55; lr: 0.0000143; 105 docs/s;   1565 sec
[2020-07-23 18:44:39,376 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.835.bert.pt, number of examples: 1990
[2020-07-23 18:44:43,918 INFO] Step 5150/50000; xent: 1.58; lr: 0.0000144; 106 docs/s;   1580 sec
[2020-07-23 18:44:59,270 INFO] Step 5200/50000; xent: 1.69; lr: 0.0000145; 101 docs/s;   1595 sec
[2020-07-23 18:45:14,724 INFO] Step 5250/50000; xent: 1.72; lr: 0.0000147; 100 docs/s;   1611 sec
[2020-07-23 18:45:18,838 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.240.bert.pt, number of examples: 1997
[2020-07-23 18:45:30,314 INFO] Step 5300/50000; xent: 1.69; lr: 0.0000148;  98 docs/s;   1627 sec
[2020-07-23 18:45:46,041 INFO] Step 5350/50000; xent: 1.68; lr: 0.0000150;  97 docs/s;   1642 sec
[2020-07-23 18:46:00,169 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.461.bert.pt, number of examples: 1994
[2020-07-23 18:46:01,700 INFO] Step 5400/50000; xent: 1.63; lr: 0.0000151;  97 docs/s;   1658 sec
[2020-07-23 18:46:17,518 INFO] Step 5450/50000; xent: 1.64; lr: 0.0000152; 101 docs/s;   1674 sec
[2020-07-23 18:46:33,310 INFO] Step 5500/50000; xent: 1.63; lr: 0.0000154; 101 docs/s;   1690 sec
[2020-07-23 18:46:39,694 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.729.bert.pt, number of examples: 1995
[2020-07-23 18:46:48,924 INFO] Step 5550/50000; xent: 1.75; lr: 0.0000155;  99 docs/s;   1705 sec
[2020-07-23 18:47:04,451 INFO] Step 5600/50000; xent: 1.80; lr: 0.0000157; 100 docs/s;   1721 sec
[2020-07-23 18:47:19,668 INFO] Step 5650/50000; xent: 1.85; lr: 0.0000158; 101 docs/s;   1736 sec
[2020-07-23 18:47:19,722 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.820.bert.pt, number of examples: 2001
[2020-07-23 18:47:34,914 INFO] Step 5700/50000; xent: 1.70; lr: 0.0000159; 101 docs/s;   1751 sec
[2020-07-23 18:47:50,174 INFO] Step 5750/50000; xent: 1.63; lr: 0.0000161; 103 docs/s;   1766 sec
[2020-07-23 18:47:59,052 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.738.bert.pt, number of examples: 1990
[2020-07-23 18:48:05,451 INFO] Step 5800/50000; xent: 1.55; lr: 0.0000162; 102 docs/s;   1782 sec
[2020-07-23 18:48:20,573 INFO] Step 5850/50000; xent: 1.46; lr: 0.0000164; 104 docs/s;   1797 sec
[2020-07-23 18:48:35,702 INFO] Step 5900/50000; xent: 1.45; lr: 0.0000165; 103 docs/s;   1812 sec
[2020-07-23 18:48:37,812 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.277.bert.pt, number of examples: 1998
[2020-07-23 18:48:50,914 INFO] Step 5950/50000; xent: 1.48; lr: 0.0000166; 102 docs/s;   1827 sec
[2020-07-23 18:49:06,131 INFO] Step 6000/50000; xent: 1.49; lr: 0.0000168; 103 docs/s;   1842 sec
[2020-07-23 18:49:16,526 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.977.bert.pt, number of examples: 1997
[2020-07-23 18:49:21,430 INFO] Step 6050/50000; xent: 1.55; lr: 0.0000169; 103 docs/s;   1858 sec
[2020-07-23 18:49:36,658 INFO] Step 6100/50000; xent: 1.59; lr: 0.0000171; 104 docs/s;   1873 sec
[2020-07-23 18:49:51,899 INFO] Step 6150/50000; xent: 1.63; lr: 0.0000172; 103 docs/s;   1888 sec
[2020-07-23 18:49:55,312 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.943.bert.pt, number of examples: 1991
[2020-07-23 18:50:07,250 INFO] Step 6200/50000; xent: 1.58; lr: 0.0000173; 101 docs/s;   1903 sec
[2020-07-23 18:50:22,520 INFO] Step 6250/50000; xent: 1.66; lr: 0.0000175; 102 docs/s;   1919 sec
[2020-07-23 18:50:34,724 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.769.bert.pt, number of examples: 1996
[2020-07-23 18:50:37,769 INFO] Step 6300/50000; xent: 1.62; lr: 0.0000176; 102 docs/s;   1934 sec
[2020-07-23 18:50:53,235 INFO] Step 6350/50000; xent: 1.78; lr: 0.0000177; 101 docs/s;   1949 sec
[2020-07-23 18:51:08,979 INFO] Step 6400/50000; xent: 1.76; lr: 0.0000179;  99 docs/s;   1965 sec
[2020-07-23 18:51:14,514 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.777.bert.pt, number of examples: 1997
[2020-07-23 18:51:24,335 INFO] Step 6450/50000; xent: 1.79; lr: 0.0000180; 102 docs/s;   1981 sec
[2020-07-23 18:51:39,717 INFO] Step 6500/50000; xent: 1.73; lr: 0.0000182; 102 docs/s;   1996 sec
[2020-07-23 18:51:53,589 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.966.bert.pt, number of examples: 1998
[2020-07-23 18:51:55,142 INFO] Step 6550/50000; xent: 1.79; lr: 0.0000183; 102 docs/s;   2011 sec
[2020-07-23 18:52:10,687 INFO] Step 6600/50000; xent: 1.46; lr: 0.0000184;  99 docs/s;   2027 sec
[2020-07-23 18:52:26,712 INFO] Step 6650/50000; xent: 1.44; lr: 0.0000186;  97 docs/s;   2043 sec
[2020-07-23 18:52:34,055 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.895.bert.pt, number of examples: 1994
[2020-07-23 18:52:42,645 INFO] Step 6700/50000; xent: 1.47; lr: 0.0000187; 100 docs/s;   2059 sec
[2020-07-23 18:52:58,770 INFO] Step 6750/50000; xent: 1.56; lr: 0.0000189;  96 docs/s;   2075 sec
[2020-07-23 18:53:14,971 INFO] Step 6800/50000; xent: 1.51; lr: 0.0000190;  97 docs/s;   2091 sec
[2020-07-23 18:53:15,031 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.673.bert.pt, number of examples: 1994
[2020-07-23 18:53:31,728 INFO] Step 6850/50000; xent: 1.58; lr: 0.0000191;  91 docs/s;   2108 sec
[2020-07-23 18:53:47,976 INFO] Step 6900/50000; xent: 1.58; lr: 0.0000193;  92 docs/s;   2124 sec
[2020-07-23 18:53:58,508 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.937.bert.pt, number of examples: 1995
[2020-07-23 18:54:04,444 INFO] Step 6950/50000; xent: 1.57; lr: 0.0000194;  93 docs/s;   2141 sec
[2020-07-23 18:54:20,754 INFO] Step 7000/50000; xent: 1.58; lr: 0.0000196;  96 docs/s;   2157 sec
[2020-07-23 18:54:37,154 INFO] Step 7050/50000; xent: 1.60; lr: 0.0000197;  94 docs/s;   2173 sec
[2020-07-23 18:54:40,406 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.914.bert.pt, number of examples: 1991
[2020-07-23 18:54:53,669 INFO] Step 7100/50000; xent: 1.72; lr: 0.0000198;  93 docs/s;   2190 sec
[2020-07-23 18:55:10,364 INFO] Step 7150/50000; xent: 1.76; lr: 0.0000200;  92 docs/s;   2207 sec
[2020-07-23 18:55:23,415 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.844.bert.pt, number of examples: 1992
[2020-07-23 18:55:26,664 INFO] Step 7200/50000; xent: 1.74; lr: 0.0000201;  96 docs/s;   2223 sec
[2020-07-23 18:55:42,944 INFO] Step 7250/50000; xent: 1.77; lr: 0.0000203;  99 docs/s;   2239 sec
[2020-07-23 18:55:59,298 INFO] Step 7300/50000; xent: 1.71; lr: 0.0000204;  97 docs/s;   2256 sec
[2020-07-23 18:56:04,108 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.429.bert.pt, number of examples: 1975
[2020-07-23 18:56:15,385 INFO] Step 7350/50000; xent: 1.68; lr: 0.0000205;  95 docs/s;   2272 sec
[2020-07-23 18:56:31,492 INFO] Step 7400/50000; xent: 1.68; lr: 0.0000207;  95 docs/s;   2288 sec
[2020-07-23 18:56:45,694 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.5.bert.pt, number of examples: 1997
[2020-07-23 18:56:47,606 INFO] Step 7450/50000; xent: 1.63; lr: 0.0000208;  95 docs/s;   2304 sec
[2020-07-23 18:57:03,712 INFO] Step 7500/50000; xent: 1.57; lr: 0.0000210;  97 docs/s;   2320 sec
[2020-07-23 18:57:20,083 INFO] Step 7550/50000; xent: 1.68; lr: 0.0000211;  91 docs/s;   2336 sec
[2020-07-23 18:57:27,984 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.973.bert.pt, number of examples: 1992
[2020-07-23 18:57:36,363 INFO] Step 7600/50000; xent: 1.62; lr: 0.0000212;  96 docs/s;   2353 sec
[2020-07-23 18:57:52,787 INFO] Step 7650/50000; xent: 1.53; lr: 0.0000214;  96 docs/s;   2369 sec
[2020-07-23 18:58:09,262 INFO] Step 7700/50000; xent: 1.60; lr: 0.0000215;  95 docs/s;   2385 sec
[2020-07-23 18:58:09,655 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.963.bert.pt, number of examples: 1997
[2020-07-23 18:58:25,594 INFO] Step 7750/50000; xent: 1.54; lr: 0.0000217;  96 docs/s;   2402 sec
[2020-07-23 18:58:41,990 INFO] Step 7800/50000; xent: 1.49; lr: 0.0000218;  96 docs/s;   2418 sec
[2020-07-23 18:58:51,025 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.667.bert.pt, number of examples: 1996
[2020-07-23 18:58:58,057 INFO] Step 7850/50000; xent: 1.54; lr: 0.0000219;  95 docs/s;   2434 sec
[2020-07-23 18:59:14,296 INFO] Step 7900/50000; xent: 1.75; lr: 0.0000221;  94 docs/s;   2451 sec
[2020-07-23 18:59:30,672 INFO] Step 7950/50000; xent: 1.68; lr: 0.0000222;  91 docs/s;   2467 sec
[2020-07-23 18:59:34,282 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.300.bert.pt, number of examples: 1994
[2020-07-23 18:59:47,010 INFO] Step 8000/50000; xent: 1.65; lr: 0.0000224;  95 docs/s;   2483 sec
[2020-07-23 19:00:03,490 INFO] Step 8050/50000; xent: 1.57; lr: 0.0000223;  95 docs/s;   2500 sec
[2020-07-23 19:00:16,146 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.286.bert.pt, number of examples: 1989
[2020-07-23 19:00:20,078 INFO] Step 8100/50000; xent: 1.60; lr: 0.0000222;  95 docs/s;   2516 sec
[2020-07-23 19:00:36,455 INFO] Step 8150/50000; xent: 1.63; lr: 0.0000222;  96 docs/s;   2533 sec
[2020-07-23 19:00:52,634 INFO] Step 8200/50000; xent: 1.60; lr: 0.0000221;  97 docs/s;   2549 sec
[2020-07-23 19:00:57,461 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.333.bert.pt, number of examples: 1996
[2020-07-23 19:01:08,645 INFO] Step 8250/50000; xent: 1.64; lr: 0.0000220;  96 docs/s;   2565 sec
[2020-07-23 19:01:24,726 INFO] Step 8300/50000; xent: 1.59; lr: 0.0000220;  97 docs/s;   2581 sec
[2020-07-23 19:01:38,834 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.812.bert.pt, number of examples: 1998
[2020-07-23 19:01:40,705 INFO] Step 8350/50000; xent: 1.61; lr: 0.0000219;  96 docs/s;   2597 sec
[2020-07-23 19:01:57,039 INFO] Step 8400/50000; xent: 1.55; lr: 0.0000218;  95 docs/s;   2613 sec
[2020-07-23 19:02:10,267 INFO] Device ID 0
[2020-07-23 19:02:10,267 INFO] Device cuda
[2020-07-23 19:02:10,282 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-23 19:02:13,182 INFO] Step 8450/50000; xent: 1.47; lr: 0.0000218;  96 docs/s;   2629 sec
[2020-07-23 19:02:18,953 INFO] Device ID 0
[2020-07-23 19:02:18,953 INFO] Device cuda
[2020-07-23 19:02:18,967 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:02:21,154 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.600.bert.pt, number of examples: 2000
[2020-07-23 19:02:29,572 INFO] Step 8500/50000; xent: 1.56; lr: 0.0000217;  94 docs/s;   2646 sec
[2020-07-23 19:02:45,807 INFO] Step 8550/50000; xent: 1.54; lr: 0.0000216;  94 docs/s;   2662 sec
[2020-07-23 19:03:02,032 INFO] Step 8600/50000; xent: 1.60; lr: 0.0000216;  93 docs/s;   2678 sec
[2020-07-23 19:03:03,767 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.990.bert.pt, number of examples: 1436
[2020-07-23 19:03:18,763 INFO] Step 8650/50000; xent: 1.64; lr: 0.0000215;  93 docs/s;   2695 sec
[2020-07-23 19:03:34,242 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.493.bert.pt, number of examples: 2001
[2020-07-23 19:03:35,183 INFO] Step 8700/50000; xent: 1.67; lr: 0.0000214;  95 docs/s;   2711 sec
[2020-07-23 19:03:51,536 INFO] Step 8750/50000; xent: 1.57; lr: 0.0000214;  94 docs/s;   2728 sec
[2020-07-23 19:04:07,575 INFO] Step 8800/50000; xent: 1.53; lr: 0.0000213;  97 docs/s;   2744 sec
[2020-07-23 19:04:15,864 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.567.bert.pt, number of examples: 1995
[2020-07-23 19:04:23,468 INFO] Step 8850/50000; xent: 1.56; lr: 0.0000213; 100 docs/s;   2760 sec
[2020-07-23 19:04:39,433 INFO] Step 8900/50000; xent: 1.58; lr: 0.0000212;  98 docs/s;   2776 sec
[2020-07-23 19:04:55,450 INFO] Step 8950/50000; xent: 1.69; lr: 0.0000211;  97 docs/s;   2792 sec
[2020-07-23 19:04:56,464 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.408.bert.pt, number of examples: 1995
[2020-07-23 19:05:11,482 INFO] Step 9000/50000; xent: 1.67; lr: 0.0000211;  98 docs/s;   2808 sec
[2020-07-23 19:05:27,508 INFO] Step 9050/50000; xent: 1.63; lr: 0.0000210;  98 docs/s;   2824 sec
[2020-07-23 19:05:37,334 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.272.bert.pt, number of examples: 1998
[2020-07-23 19:05:43,778 INFO] Step 9100/50000; xent: 1.68; lr: 0.0000210;  97 docs/s;   2840 sec
[2020-07-23 19:05:59,912 INFO] Step 9150/50000; xent: 1.67; lr: 0.0000209;  97 docs/s;   2856 sec
[2020-07-23 19:06:15,782 INFO] Step 9200/50000; xent: 1.69; lr: 0.0000209;  97 docs/s;   2872 sec
[2020-07-23 19:06:18,468 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.120.bert.pt, number of examples: 1999
[2020-07-23 19:06:32,058 INFO] Step 9250/50000; xent: 1.64; lr: 0.0000208;  97 docs/s;   2888 sec
[2020-07-23 19:06:48,018 INFO] Step 9300/50000; xent: 1.54; lr: 0.0000207;  98 docs/s;   2904 sec
[2020-07-23 19:06:59,250 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.629.bert.pt, number of examples: 1999
[2020-07-23 19:07:04,088 INFO] Step 9350/50000; xent: 1.70; lr: 0.0000207;  98 docs/s;   2920 sec
[2020-07-23 19:07:20,416 INFO] Step 9400/50000; xent: 1.66; lr: 0.0000206;  97 docs/s;   2937 sec
[2020-07-23 19:07:36,523 INFO] Step 9450/50000; xent: 1.66; lr: 0.0000206;  98 docs/s;   2953 sec
[2020-07-23 19:07:40,365 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.316.bert.pt, number of examples: 1995
[2020-07-23 19:07:52,377 INFO] Step 9500/50000; xent: 1.58; lr: 0.0000205;  99 docs/s;   2969 sec
[2020-07-23 19:08:08,335 INFO] Step 9550/50000; xent: 1.56; lr: 0.0000205;  99 docs/s;   2985 sec
[2020-07-23 19:08:20,579 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.915.bert.pt, number of examples: 2000
[2020-07-23 19:08:24,428 INFO] Step 9600/50000; xent: 1.61; lr: 0.0000204;  98 docs/s;   3001 sec
[2020-07-23 19:08:40,235 INFO] Step 9650/50000; xent: 1.87; lr: 0.0000204;  96 docs/s;   3016 sec
[2020-07-23 19:08:56,198 INFO] Step 9700/50000; xent: 1.77; lr: 0.0000203;  96 docs/s;   3032 sec
[2020-07-23 19:09:02,265 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.734.bert.pt, number of examples: 1976
[2020-07-23 19:09:12,121 INFO] Step 9750/50000; xent: 1.71; lr: 0.0000203;  96 docs/s;   3048 sec
[2020-07-23 19:09:15,838 INFO] Device ID 0
[2020-07-23 19:09:15,838 INFO] Device cuda
[2020-07-23 19:09:15,852 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:09:28,290 INFO] Step 9800/50000; xent: 1.67; lr: 0.0000202;  96 docs/s;   3065 sec
[2020-07-23 19:09:42,838 INFO] Device ID 0
[2020-07-23 19:09:42,838 INFO] Device cuda
[2020-07-23 19:09:42,852 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:09:43,189 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.164.bert.pt, number of examples: 1997
[2020-07-23 19:09:44,511 INFO] Step 9850/50000; xent: 1.64; lr: 0.0000202;  96 docs/s;   3081 sec
[2020-07-23 19:10:00,574 INFO] Device ID 0
[2020-07-23 19:10:00,575 INFO] Device cuda
[2020-07-23 19:10:00,589 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:10:00,803 INFO] Step 9900/50000; xent: 1.59; lr: 0.0000201;  98 docs/s;   3097 sec
[2020-07-23 19:10:16,861 INFO] Step 9950/50000; xent: 1.56; lr: 0.0000201;  98 docs/s;   3113 sec
[2020-07-23 19:10:23,998 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.451.bert.pt, number of examples: 1993
[2020-07-23 19:10:33,172 INFO] Step 10000/50000; xent: 1.50; lr: 0.0000200;  98 docs/s;   3129 sec
[2020-07-23 19:10:33,174 INFO] Saving checkpoint ./models/models_check_points/model_step_10000.pt
[2020-07-23 19:10:50,008 INFO] Step 10050/50000; xent: 1.47; lr: 0.0000200;  96 docs/s;   3146 sec
[2020-07-23 19:11:04,866 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.853.bert.pt, number of examples: 1989
[2020-07-23 19:11:06,189 INFO] Step 10100/50000; xent: 1.50; lr: 0.0000199; 100 docs/s;   3162 sec
[2020-07-23 19:11:22,248 INFO] Step 10150/50000; xent: 1.65; lr: 0.0000199;  97 docs/s;   3178 sec
[2020-07-23 19:11:38,445 INFO] Step 10200/50000; xent: 1.57; lr: 0.0000198;  99 docs/s;   3195 sec
[2020-07-23 19:11:45,522 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.11.bert.pt, number of examples: 1997
[2020-07-23 19:11:54,544 INFO] Step 10250/50000; xent: 1.67; lr: 0.0000198;  97 docs/s;   3211 sec
[2020-07-23 19:12:10,739 INFO] Step 10300/50000; xent: 1.80; lr: 0.0000197;  95 docs/s;   3227 sec
[2020-07-23 19:12:26,890 INFO] Step 10350/50000; xent: 1.71; lr: 0.0000197;  95 docs/s;   3243 sec
[2020-07-23 19:12:27,585 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.237.bert.pt, number of examples: 1994
[2020-07-23 19:12:43,019 INFO] Step 10400/50000; xent: 1.66; lr: 0.0000196;  96 docs/s;   3259 sec
[2020-07-23 19:12:59,173 INFO] Step 10450/50000; xent: 1.65; lr: 0.0000196;  96 docs/s;   3275 sec
[2020-07-23 19:13:08,809 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.383.bert.pt, number of examples: 1996
[2020-07-23 19:13:09,831 INFO] Device ID 0
[2020-07-23 19:13:09,831 INFO] Device cuda
[2020-07-23 19:13:09,845 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:13:15,524 INFO] Step 10500/50000; xent: 1.62; lr: 0.0000195;  96 docs/s;   3292 sec
[2020-07-23 19:13:31,753 INFO] Step 10550/50000; xent: 1.56; lr: 0.0000195;  96 docs/s;   3308 sec
[2020-07-23 19:13:48,137 INFO] Step 10600/50000; xent: 1.52; lr: 0.0000194;  95 docs/s;   3324 sec
[2020-07-23 19:13:50,901 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.666.bert.pt, number of examples: 1994
[2020-07-23 19:14:04,653 INFO] Step 10650/50000; xent: 1.62; lr: 0.0000194;  92 docs/s;   3341 sec
[2020-07-23 19:14:21,440 INFO] Step 10700/50000; xent: 1.65; lr: 0.0000193;  89 docs/s;   3358 sec
[2020-07-23 19:14:34,772 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.153.bert.pt, number of examples: 1998
[2020-07-23 19:14:38,188 INFO] Step 10750/50000; xent: 1.67; lr: 0.0000193;  91 docs/s;   3374 sec
[2020-07-23 19:14:54,490 INFO] Step 10800/50000; xent: 1.56; lr: 0.0000192;  98 docs/s;   3391 sec
[2020-07-23 19:15:10,882 INFO] Step 10850/50000; xent: 1.60; lr: 0.0000192;  95 docs/s;   3407 sec
[2020-07-23 19:15:16,508 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.380.bert.pt, number of examples: 1999
[2020-07-23 19:15:27,121 INFO] Step 10900/50000; xent: 1.53; lr: 0.0000192;  97 docs/s;   3423 sec
[2020-07-23 19:15:43,077 INFO] Step 10950/50000; xent: 1.63; lr: 0.0000191;  97 docs/s;   3439 sec
[2020-07-23 19:15:57,531 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.411.bert.pt, number of examples: 1994
[2020-07-23 19:15:59,238 INFO] Step 11000/50000; xent: 1.58; lr: 0.0000191;  97 docs/s;   3455 sec
[2020-07-23 19:16:15,314 INFO] Step 11050/50000; xent: 1.66; lr: 0.0000190;  97 docs/s;   3472 sec
[2020-07-23 19:16:31,649 INFO] Step 11100/50000; xent: 1.60; lr: 0.0000190;  95 docs/s;   3488 sec
[2020-07-23 19:16:39,230 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.161.bert.pt, number of examples: 1997
[2020-07-23 19:16:48,086 INFO] Step 11150/50000; xent: 1.58; lr: 0.0000189;  95 docs/s;   3504 sec
[2020-07-23 19:17:04,415 INFO] Step 11200/50000; xent: 1.57; lr: 0.0000189;  97 docs/s;   3521 sec
[2020-07-23 19:17:20,922 INFO] Step 11250/50000; xent: 1.58; lr: 0.0000189;  94 docs/s;   3537 sec
[2020-07-23 19:17:20,981 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.579.bert.pt, number of examples: 2000
[2020-07-23 19:17:21,043 INFO] Device ID 0
[2020-07-23 19:17:21,043 INFO] Device cuda
[2020-07-23 19:17:21,057 INFO] Loading checkpoint from ./models/models_check_points/model_step_5000.pt
[2020-07-23 19:17:23,807 INFO] Loading test dataset from ./data/bert_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 19:17:23,811 INFO] * number of parameters: 113297921
[2020-07-23 19:17:37,696 INFO] Step 11300/50000; xent: 1.69; lr: 0.0000188;  93 docs/s;   3554 sec
[2020-07-23 19:17:54,174 INFO] Step 11350/50000; xent: 1.68; lr: 0.0000188;  94 docs/s;   3570 sec
[2020-07-23 19:18:00,529 INFO] Device ID 0
[2020-07-23 19:18:00,529 INFO] Device cuda
[2020-07-23 19:18:00,544 INFO] Loading checkpoint from ./models/models_check_points/model_step_10000.pt
[2020-07-23 19:18:03,226 INFO] Loading test dataset from ./data/bert_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 19:18:03,229 INFO] * number of parameters: 113297921
[2020-07-23 19:18:04,090 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.578.bert.pt, number of examples: 1995
[2020-07-23 19:18:10,466 INFO] Step 11400/50000; xent: 1.73; lr: 0.0000187;  94 docs/s;   3587 sec
[2020-07-23 19:18:26,802 INFO] Step 11450/50000; xent: 1.68; lr: 0.0000187;  95 docs/s;   3603 sec
[2020-07-23 19:18:35,699 INFO] Device ID 0
[2020-07-23 19:18:35,699 INFO] Device cuda
[2020-07-23 19:18:35,715 INFO] Loading checkpoint from ./models/models_check_points/model_step_10000.pt
[2020-07-23 19:18:38,406 INFO] Loading test dataset from ./data/bert_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 19:18:38,411 INFO] * number of parameters: 113297921
[2020-07-23 19:18:43,379 INFO] Step 11500/50000; xent: 1.73; lr: 0.0000187;  95 docs/s;   3620 sec
[2020-07-23 19:18:45,780 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.548.bert.pt, number of examples: 1997
[2020-07-23 19:19:00,169 INFO] Step 11550/50000; xent: 1.61; lr: 0.0000186;  94 docs/s;   3636 sec
[2020-07-23 19:19:11,481 INFO] Device ID 0
[2020-07-23 19:19:11,481 INFO] Device cuda
[2020-07-23 19:19:11,496 INFO] Loading checkpoint from ./models/models_check_points/model_step_10000.pt
[2020-07-23 19:19:14,187 INFO] Loading test dataset from ./data/bert_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 19:19:14,191 INFO] * number of parameters: 113297921
[2020-07-23 19:19:18,844 INFO] Step 11600/50000; xent: 1.54; lr: 0.0000186;  84 docs/s;   3655 sec
[2020-07-23 19:19:37,718 INFO] Loading test dataset from ./data/bert_data\chinese_summary.test.1.bert.pt, number of examples: 1999
[2020-07-23 19:19:41,354 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.584.bert.pt, number of examples: 1996
[2020-07-23 19:19:51,029 INFO] Step 11650/50000; xent: 1.59; lr: 0.0000185;  48 docs/s;   3687 sec
[2020-07-23 19:20:07,827 INFO] Step 11700/50000; xent: 1.60; lr: 0.0000185;  90 docs/s;   3704 sec
[2020-07-23 19:20:23,845 INFO] Step 11750/50000; xent: 1.61; lr: 0.0000185;  97 docs/s;   3720 sec
[2020-07-23 19:20:28,244 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.191.bert.pt, number of examples: 1989
[2020-07-23 19:20:39,565 INFO] Step 11800/50000; xent: 1.68; lr: 0.0000184;  99 docs/s;   3736 sec
[2020-07-23 19:20:43,708 INFO] Device ID 0
[2020-07-23 19:20:43,708 INFO] Device cuda
[2020-07-23 19:20:43,723 INFO] Loading checkpoint from ./models/models_check_points/model_step_10000.pt
[2020-07-23 19:20:46,427 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 19:20:46,430 INFO] * number of parameters: 113297921
[2020-07-23 19:21:04,149 INFO] Step 11850/50000; xent: 1.65; lr: 0.0000184;  63 docs/s;   3760 sec
[2020-07-23 19:21:09,119 INFO] Validation xent: 3.26277 at step 10000
[2020-07-23 19:21:20,128 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.684.bert.pt, number of examples: 1992
[2020-07-23 19:21:22,727 INFO] Step 11900/50000; xent: 1.63; lr: 0.0000183;  84 docs/s;   3779 sec
[2020-07-23 19:21:38,943 INFO] Step 11950/50000; xent: 1.53; lr: 0.0000183;  96 docs/s;   3795 sec
[2020-07-23 19:21:55,367 INFO] Step 12000/50000; xent: 1.57; lr: 0.0000183;  93 docs/s;   3812 sec
[2020-07-23 19:22:02,308 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.391.bert.pt, number of examples: 1996
[2020-07-23 19:22:11,727 INFO] Step 12050/50000; xent: 1.42; lr: 0.0000182;  96 docs/s;   3828 sec
[2020-07-23 19:22:28,056 INFO] Step 12100/50000; xent: 1.37; lr: 0.0000182;  99 docs/s;   3844 sec
[2020-07-23 19:22:42,828 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.188.bert.pt, number of examples: 1974
[2020-07-23 19:22:44,456 INFO] Step 12150/50000; xent: 1.40; lr: 0.0000181;  98 docs/s;   3861 sec
[2020-07-23 19:23:00,616 INFO] Step 12200/50000; xent: 1.59; lr: 0.0000181;  96 docs/s;   3877 sec
[2020-07-23 19:23:16,783 INFO] Step 12250/50000; xent: 1.53; lr: 0.0000181;  96 docs/s;   3893 sec
[2020-07-23 19:23:23,989 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.194.bert.pt, number of examples: 1998
[2020-07-23 19:23:33,164 INFO] Step 12300/50000; xent: 1.53; lr: 0.0000180;  94 docs/s;   3909 sec
[2020-07-23 19:23:49,690 INFO] Step 12350/50000; xent: 1.56; lr: 0.0000180;  94 docs/s;   3926 sec
[2020-07-23 19:24:06,063 INFO] Step 12400/50000; xent: 1.63; lr: 0.0000180;  95 docs/s;   3942 sec
[2020-07-23 19:24:06,430 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.576.bert.pt, number of examples: 1997
[2020-07-23 19:24:22,169 INFO] Step 12450/50000; xent: 1.57; lr: 0.0000179;  96 docs/s;   3958 sec
[2020-07-23 19:24:38,276 INFO] Step 12500/50000; xent: 1.55; lr: 0.0000179;  98 docs/s;   3974 sec
[2020-07-23 19:24:47,432 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.928.bert.pt, number of examples: 1993
[2020-07-23 19:24:53,882 INFO] Step 12550/50000; xent: 1.62; lr: 0.0000179;  98 docs/s;   3990 sec
[2020-07-23 19:25:09,761 INFO] Step 12600/50000; xent: 1.54; lr: 0.0000178;  94 docs/s;   4006 sec
[2020-07-23 19:25:25,804 INFO] Step 12650/50000; xent: 1.55; lr: 0.0000178;  94 docs/s;   4022 sec
[2020-07-23 19:25:29,711 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.117.bert.pt, number of examples: 1998
[2020-07-23 19:25:41,974 INFO] Step 12700/50000; xent: 1.52; lr: 0.0000177;  98 docs/s;   4038 sec
[2020-07-23 19:25:57,878 INFO] Step 12750/50000; xent: 1.53; lr: 0.0000177;  98 docs/s;   4054 sec
[2020-07-23 19:26:10,382 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.454.bert.pt, number of examples: 1995
[2020-07-23 19:26:13,926 INFO] Step 12800/50000; xent: 1.54; lr: 0.0000177;  97 docs/s;   4070 sec
[2020-07-23 19:26:29,833 INFO] Step 12850/50000; xent: 1.47; lr: 0.0000176; 100 docs/s;   4086 sec
[2020-07-23 19:26:45,841 INFO] Step 12900/50000; xent: 1.46; lr: 0.0000176; 101 docs/s;   4102 sec
[2020-07-23 19:26:50,393 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.37.bert.pt, number of examples: 1996
[2020-07-23 19:27:01,889 INFO] Step 12950/50000; xent: 1.55; lr: 0.0000176; 100 docs/s;   4118 sec
[2020-07-23 19:27:17,848 INFO] Step 13000/50000; xent: 1.69; lr: 0.0000175;  98 docs/s;   4134 sec
[2020-07-23 19:27:31,101 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.9.bert.pt, number of examples: 1994
[2020-07-23 19:27:33,989 INFO] Step 13050/50000; xent: 1.57; lr: 0.0000175;  97 docs/s;   4150 sec
[2020-07-23 19:27:49,971 INFO] Step 13100/50000; xent: 1.66; lr: 0.0000175;  97 docs/s;   4166 sec
[2020-07-23 19:28:06,221 INFO] Step 13150/50000; xent: 1.61; lr: 0.0000174;  96 docs/s;   4182 sec
[2020-07-23 19:28:12,371 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.534.bert.pt, number of examples: 1997
[2020-07-23 19:28:22,315 INFO] Step 13200/50000; xent: 1.57; lr: 0.0000174;  98 docs/s;   4199 sec
[2020-07-23 19:28:38,280 INFO] Step 13250/50000; xent: 1.55; lr: 0.0000174;  98 docs/s;   4215 sec
[2020-07-23 19:28:53,043 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.238.bert.pt, number of examples: 1997
[2020-07-23 19:28:54,267 INFO] Step 13300/50000; xent: 1.47; lr: 0.0000173;  99 docs/s;   4230 sec
[2020-07-23 19:29:10,232 INFO] Step 13350/50000; xent: 1.63; lr: 0.0000173;  96 docs/s;   4246 sec
[2020-07-23 19:29:26,150 INFO] Step 13400/50000; xent: 1.62; lr: 0.0000173;  96 docs/s;   4262 sec
[2020-07-23 19:29:34,742 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.265.bert.pt, number of examples: 1988
[2020-07-23 19:29:42,177 INFO] Step 13450/50000; xent: 1.65; lr: 0.0000172;  96 docs/s;   4278 sec
[2020-07-23 19:29:58,077 INFO] Step 13500/50000; xent: 1.60; lr: 0.0000172; 100 docs/s;   4294 sec
[2020-07-23 19:30:14,146 INFO] Step 13550/50000; xent: 1.47; lr: 0.0000172; 100 docs/s;   4310 sec
[2020-07-23 19:30:14,833 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.909.bert.pt, number of examples: 1998
[2020-07-23 19:30:30,134 INFO] Step 13600/50000; xent: 1.67; lr: 0.0000171;  97 docs/s;   4326 sec
[2020-07-23 19:30:45,770 INFO] Step 13650/50000; xent: 1.79; lr: 0.0000171;  98 docs/s;   4342 sec
[2020-07-23 19:30:55,759 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.111.bert.pt, number of examples: 1989
[2020-07-23 19:31:01,330 INFO] Step 13700/50000; xent: 1.63; lr: 0.0000171;  99 docs/s;   4358 sec
[2020-07-23 19:31:17,338 INFO] Step 13750/50000; xent: 1.40; lr: 0.0000171; 101 docs/s;   4374 sec
[2020-07-23 19:31:33,524 INFO] Step 13800/50000; xent: 1.38; lr: 0.0000170; 101 docs/s;   4390 sec
[2020-07-23 19:31:35,158 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.663.bert.pt, number of examples: 2000
[2020-07-23 19:31:49,655 INFO] Step 13850/50000; xent: 1.64; lr: 0.0000170;  93 docs/s;   4406 sec
[2020-07-23 19:32:05,697 INFO] Step 13900/50000; xent: 1.69; lr: 0.0000170;  94 docs/s;   4422 sec
[2020-07-23 19:32:18,178 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.716.bert.pt, number of examples: 1998
[2020-07-23 19:32:21,650 INFO] Step 13950/50000; xent: 1.69; lr: 0.0000169;  92 docs/s;   4438 sec
[2020-07-23 19:32:37,618 INFO] Step 14000/50000; xent: 1.72; lr: 0.0000169;  93 docs/s;   4454 sec
[2020-07-23 19:32:53,756 INFO] Step 14050/50000; xent: 1.68; lr: 0.0000169;  95 docs/s;   4470 sec
[2020-07-23 19:33:00,545 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.810.bert.pt, number of examples: 1994
[2020-07-23 19:33:09,743 INFO] Step 14100/50000; xent: 1.57; lr: 0.0000168;  96 docs/s;   4486 sec
[2020-07-23 19:33:25,724 INFO] Step 14150/50000; xent: 1.64; lr: 0.0000168;  96 docs/s;   4502 sec
[2020-07-23 19:33:41,690 INFO] Step 14200/50000; xent: 1.54; lr: 0.0000168;  96 docs/s;   4518 sec
[2020-07-23 19:33:42,047 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.721.bert.pt, number of examples: 2000
[2020-07-23 19:33:57,673 INFO] Step 14250/50000; xent: 1.59; lr: 0.0000168;  95 docs/s;   4534 sec
[2020-07-23 19:34:13,737 INFO] Step 14300/50000; xent: 1.59; lr: 0.0000167;  96 docs/s;   4550 sec
[2020-07-23 19:34:23,756 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.851.bert.pt, number of examples: 1996
[2020-07-23 19:34:29,860 INFO] Step 14350/50000; xent: 1.48; lr: 0.0000167;  97 docs/s;   4566 sec
[2020-07-23 19:34:45,882 INFO] Step 14400/50000; xent: 1.47; lr: 0.0000167;  98 docs/s;   4582 sec
[2020-07-23 19:35:01,982 INFO] Step 14450/50000; xent: 1.42; lr: 0.0000166;  99 docs/s;   4598 sec
[2020-07-23 19:35:04,235 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.18.bert.pt, number of examples: 1998
[2020-07-23 19:35:18,004 INFO] Step 14500/50000; xent: 1.49; lr: 0.0000166;  96 docs/s;   4614 sec
[2020-07-23 19:35:34,065 INFO] Step 14550/50000; xent: 1.48; lr: 0.0000166;  97 docs/s;   4630 sec
[2020-07-23 19:35:45,791 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.222.bert.pt, number of examples: 1999
[2020-07-23 19:35:50,255 INFO] Step 14600/50000; xent: 1.50; lr: 0.0000166;  97 docs/s;   4646 sec
[2020-07-23 19:36:06,305 INFO] Step 14650/50000; xent: 1.55; lr: 0.0000165;  99 docs/s;   4663 sec
[2020-07-23 19:36:22,326 INFO] Step 14700/50000; xent: 1.55; lr: 0.0000165;  98 docs/s;   4679 sec
[2020-07-23 19:36:26,221 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.801.bert.pt, number of examples: 1992
[2020-07-23 19:36:38,507 INFO] Step 14750/50000; xent: 1.60; lr: 0.0000165;  98 docs/s;   4695 sec
[2020-07-23 19:36:54,600 INFO] Step 14800/50000; xent: 1.60; lr: 0.0000164;  98 docs/s;   4711 sec
[2020-07-23 19:37:07,165 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.349.bert.pt, number of examples: 1996
[2020-07-23 19:37:10,745 INFO] Step 14850/50000; xent: 1.57; lr: 0.0000164;  96 docs/s;   4727 sec
[2020-07-23 19:37:27,142 INFO] Step 14900/50000; xent: 1.66; lr: 0.0000164;  94 docs/s;   4743 sec
[2020-07-23 19:37:43,464 INFO] Step 14950/50000; xent: 1.58; lr: 0.0000164;  95 docs/s;   4760 sec
[2020-07-23 19:37:49,313 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.965.bert.pt, number of examples: 2001
[2020-07-23 19:37:59,705 INFO] Step 15000/50000; xent: 1.50; lr: 0.0000163;  96 docs/s;   4776 sec
[2020-07-23 19:37:59,707 INFO] Saving checkpoint ./models/models_check_points/model_step_15000.pt
[2020-07-23 19:38:16,769 INFO] Step 15050/50000; xent: 1.41; lr: 0.0000163;  92 docs/s;   4793 sec
[2020-07-23 19:38:31,437 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.98.bert.pt, number of examples: 1993
[2020-07-23 19:38:33,042 INFO] Step 15100/50000; xent: 1.48; lr: 0.0000163;  96 docs/s;   4809 sec
[2020-07-23 19:38:49,208 INFO] Step 15150/50000; xent: 1.61; lr: 0.0000162;  97 docs/s;   4825 sec
[2020-07-23 19:39:05,213 INFO] Step 15200/50000; xent: 1.68; lr: 0.0000162;  97 docs/s;   4841 sec
[2020-07-23 19:39:12,588 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.536.bert.pt, number of examples: 1994
[2020-07-23 19:39:21,229 INFO] Step 15250/50000; xent: 1.53; lr: 0.0000162;  96 docs/s;   4857 sec
[2020-07-23 19:39:37,233 INFO] Step 15300/50000; xent: 1.53; lr: 0.0000162;  98 docs/s;   4873 sec
[2020-07-23 19:39:53,215 INFO] Step 15350/50000; xent: 1.41; lr: 0.0000161;  98 docs/s;   4889 sec
[2020-07-23 19:39:53,272 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.508.bert.pt, number of examples: 1991
[2020-07-23 19:40:09,398 INFO] Step 15400/50000; xent: 1.39; lr: 0.0000161;  95 docs/s;   4906 sec
[2020-07-23 19:40:25,247 INFO] Step 15450/50000; xent: 1.34; lr: 0.0000161;  97 docs/s;   4921 sec
[2020-07-23 19:40:34,864 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.20.bert.pt, number of examples: 1996
[2020-07-23 19:40:41,214 INFO] Step 15500/50000; xent: 1.49; lr: 0.0000161;  96 docs/s;   4937 sec
[2020-07-23 19:40:57,129 INFO] Step 15550/50000; xent: 1.62; lr: 0.0000160;  98 docs/s;   4953 sec
[2020-07-23 19:41:13,032 INFO] Step 15600/50000; xent: 1.58; lr: 0.0000160;  97 docs/s;   4969 sec
[2020-07-23 19:41:15,895 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.520.bert.pt, number of examples: 1998
[2020-07-23 19:41:29,117 INFO] Step 15650/50000; xent: 1.49; lr: 0.0000160;  98 docs/s;   4985 sec
[2020-07-23 19:41:45,123 INFO] Step 15700/50000; xent: 1.50; lr: 0.0000160;  99 docs/s;   5001 sec
[2020-07-23 19:41:56,128 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.821.bert.pt, number of examples: 1987
[2020-07-23 19:42:01,341 INFO] Step 15750/50000; xent: 1.50; lr: 0.0000159;  96 docs/s;   5018 sec
[2020-07-23 19:42:17,597 INFO] Step 15800/50000; xent: 1.64; lr: 0.0000159;  92 docs/s;   5034 sec
[2020-07-23 19:42:33,540 INFO] Step 15850/50000; xent: 1.60; lr: 0.0000159;  94 docs/s;   5050 sec
[2020-07-23 19:42:38,961 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.744.bert.pt, number of examples: 1972
[2020-07-23 19:42:49,578 INFO] Step 15900/50000; xent: 1.54; lr: 0.0000159;  96 docs/s;   5066 sec
[2020-07-23 19:43:05,485 INFO] Step 15950/50000; xent: 1.46; lr: 0.0000158;  97 docs/s;   5082 sec
[2020-07-23 19:43:19,960 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.443.bert.pt, number of examples: 1995
[2020-07-23 19:43:21,553 INFO] Step 16000/50000; xent: 1.41; lr: 0.0000158;  97 docs/s;   5098 sec
[2020-07-23 19:43:37,446 INFO] Step 16050/50000; xent: 1.61; lr: 0.0000158;  97 docs/s;   5114 sec
[2020-07-23 19:43:53,268 INFO] Step 16100/50000; xent: 1.53; lr: 0.0000158;  97 docs/s;   5129 sec
[2020-07-23 19:44:01,401 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.413.bert.pt, number of examples: 1989
[2020-07-23 19:44:09,359 INFO] Step 16150/50000; xent: 1.66; lr: 0.0000157;  95 docs/s;   5146 sec
[2020-07-23 19:44:25,221 INFO] Step 16200/50000; xent: 1.67; lr: 0.0000157;  97 docs/s;   5161 sec
[2020-07-23 19:44:41,145 INFO] Step 16250/50000; xent: 1.69; lr: 0.0000157;  97 docs/s;   5177 sec
[2020-07-23 19:44:42,444 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.233.bert.pt, number of examples: 1994
[2020-07-23 19:44:57,040 INFO] Step 16300/50000; xent: 1.59; lr: 0.0000157;  98 docs/s;   5193 sec
[2020-07-23 19:45:12,829 INFO] Step 16350/50000; xent: 1.59; lr: 0.0000156;  98 docs/s;   5209 sec
[2020-07-23 19:45:23,050 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.890.bert.pt, number of examples: 1997
[2020-07-23 19:45:28,756 INFO] Step 16400/50000; xent: 1.58; lr: 0.0000156;  99 docs/s;   5225 sec
[2020-07-23 19:45:44,516 INFO] Step 16450/50000; xent: 1.50; lr: 0.0000156; 103 docs/s;   5241 sec
[2020-07-23 19:46:00,359 INFO] Step 16500/50000; xent: 1.50; lr: 0.0000156; 102 docs/s;   5257 sec
[2020-07-23 19:46:02,269 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.893.bert.pt, number of examples: 1997
[2020-07-23 19:46:16,168 INFO] Step 16550/50000; xent: 1.50; lr: 0.0000155; 102 docs/s;   5272 sec
[2020-07-23 19:46:32,011 INFO] Step 16600/50000; xent: 1.53; lr: 0.0000155; 100 docs/s;   5288 sec
[2020-07-23 19:46:41,534 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.515.bert.pt, number of examples: 2000
[2020-07-23 19:46:47,853 INFO] Step 16650/50000; xent: 1.41; lr: 0.0000155; 103 docs/s;   5304 sec
[2020-07-23 19:47:03,618 INFO] Step 16700/50000; xent: 1.46; lr: 0.0000155; 101 docs/s;   5320 sec
[2020-07-23 19:47:19,461 INFO] Step 16750/50000; xent: 1.41; lr: 0.0000155; 101 docs/s;   5336 sec
[2020-07-23 19:47:21,118 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.148.bert.pt, number of examples: 1998
[2020-07-23 19:47:35,344 INFO] Step 16800/50000; xent: 1.47; lr: 0.0000154; 101 docs/s;   5352 sec
[2020-07-23 19:47:51,129 INFO] Step 16850/50000; xent: 1.48; lr: 0.0000154; 101 docs/s;   5367 sec
[2020-07-23 19:48:00,859 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.885.bert.pt, number of examples: 1992
[2020-07-23 19:48:06,830 INFO] Step 16900/50000; xent: 1.51; lr: 0.0000154; 100 docs/s;   5383 sec
[2020-07-23 19:48:22,576 INFO] Step 16950/50000; xent: 1.48; lr: 0.0000154; 101 docs/s;   5399 sec
[2020-07-23 19:48:38,405 INFO] Step 17000/50000; xent: 1.39; lr: 0.0000153; 101 docs/s;   5415 sec
[2020-07-23 19:48:40,344 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.570.bert.pt, number of examples: 2000
[2020-07-23 19:48:54,308 INFO] Step 17050/50000; xent: 1.53; lr: 0.0000153; 100 docs/s;   5431 sec
[2020-07-23 19:49:10,057 INFO] Step 17100/50000; xent: 1.57; lr: 0.0000153;  99 docs/s;   5446 sec
[2020-07-23 19:49:20,581 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.372.bert.pt, number of examples: 1997
[2020-07-23 19:49:25,975 INFO] Step 17150/50000; xent: 1.55; lr: 0.0000153;  98 docs/s;   5462 sec
[2020-07-23 19:49:41,792 INFO] Step 17200/50000; xent: 1.52; lr: 0.0000152;  99 docs/s;   5478 sec
[2020-07-23 19:49:57,528 INFO] Step 17250/50000; xent: 1.60; lr: 0.0000152;  98 docs/s;   5494 sec
[2020-07-23 19:50:01,341 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.48.bert.pt, number of examples: 1997
[2020-07-23 19:50:13,330 INFO] Step 17300/50000; xent: 1.58; lr: 0.0000152;  99 docs/s;   5510 sec
[2020-07-23 19:50:29,158 INFO] Step 17350/50000; xent: 1.52; lr: 0.0000152; 100 docs/s;   5525 sec
[2020-07-23 19:50:41,515 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.879.bert.pt, number of examples: 1996
[2020-07-23 19:50:44,938 INFO] Step 17400/50000; xent: 1.55; lr: 0.0000152;  98 docs/s;   5541 sec
[2020-07-23 19:51:00,779 INFO] Step 17450/50000; xent: 1.49; lr: 0.0000151; 100 docs/s;   5557 sec
[2020-07-23 19:51:16,601 INFO] Step 17500/50000; xent: 1.47; lr: 0.0000151; 101 docs/s;   5573 sec
[2020-07-23 19:51:21,372 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.342.bert.pt, number of examples: 1994
[2020-07-23 19:51:32,357 INFO] Step 17550/50000; xent: 1.54; lr: 0.0000151;  99 docs/s;   5589 sec
[2020-07-23 19:51:48,114 INFO] Step 17600/50000; xent: 1.57; lr: 0.0000151;  98 docs/s;   5604 sec
[2020-07-23 19:52:02,040 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.741.bert.pt, number of examples: 1951
[2020-07-23 19:52:03,957 INFO] Step 17650/50000; xent: 1.63; lr: 0.0000151;  99 docs/s;   5620 sec
[2020-07-23 19:52:19,773 INFO] Step 17700/50000; xent: 1.60; lr: 0.0000150;  99 docs/s;   5636 sec
[2020-07-23 19:52:35,650 INFO] Step 17750/50000; xent: 1.66; lr: 0.0000150;  98 docs/s;   5652 sec
[2020-07-23 19:52:41,653 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.524.bert.pt, number of examples: 1984
[2020-07-23 19:52:51,438 INFO] Step 17800/50000; xent: 1.63; lr: 0.0000150;  97 docs/s;   5668 sec
[2020-07-23 19:53:07,329 INFO] Step 17850/50000; xent: 1.66; lr: 0.0000150;  98 docs/s;   5684 sec
[2020-07-23 19:53:22,217 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.403.bert.pt, number of examples: 1996
[2020-07-23 19:53:23,169 INFO] Step 17900/50000; xent: 1.58; lr: 0.0000149;  97 docs/s;   5699 sec
[2020-07-23 19:53:38,923 INFO] Step 17950/50000; xent: 1.64; lr: 0.0000149; 100 docs/s;   5715 sec
[2020-07-23 19:53:54,676 INFO] Step 18000/50000; xent: 1.63; lr: 0.0000149; 101 docs/s;   5731 sec
[2020-07-23 19:54:02,255 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.35.bert.pt, number of examples: 1990
[2020-07-23 19:54:10,449 INFO] Step 18050/50000; xent: 1.61; lr: 0.0000149; 100 docs/s;   5747 sec
[2020-07-23 19:54:26,146 INFO] Step 18100/50000; xent: 1.56; lr: 0.0000149;  99 docs/s;   5762 sec
[2020-07-23 19:54:41,891 INFO] Step 18150/50000; xent: 1.60; lr: 0.0000148; 100 docs/s;   5778 sec
[2020-07-23 19:54:41,943 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.787.bert.pt, number of examples: 1992
[2020-07-23 19:54:57,749 INFO] Step 18200/50000; xent: 1.82; lr: 0.0000148;  97 docs/s;   5794 sec
[2020-07-23 19:55:13,582 INFO] Step 18250/50000; xent: 1.72; lr: 0.0000148;  97 docs/s;   5810 sec
[2020-07-23 19:55:23,131 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.841.bert.pt, number of examples: 1998
[2020-07-23 19:55:29,423 INFO] Step 18300/50000; xent: 1.66; lr: 0.0000148;  99 docs/s;   5826 sec
[2020-07-23 19:55:45,371 INFO] Step 18350/50000; xent: 1.58; lr: 0.0000148; 101 docs/s;   5842 sec
[2020-07-23 19:56:01,182 INFO] Step 18400/50000; xent: 1.55; lr: 0.0000147; 100 docs/s;   5857 sec
[2020-07-23 19:56:02,799 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.507.bert.pt, number of examples: 1999
[2020-07-23 19:56:16,898 INFO] Step 18450/50000; xent: 1.39; lr: 0.0000147;  95 docs/s;   5873 sec
[2020-07-23 19:56:32,787 INFO] Step 18500/50000; xent: 1.38; lr: 0.0000147;  95 docs/s;   5889 sec
[2020-07-23 19:56:45,210 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.163.bert.pt, number of examples: 1998
[2020-07-23 19:56:48,692 INFO] Step 18550/50000; xent: 1.36; lr: 0.0000147;  95 docs/s;   5905 sec
[2020-07-23 19:57:04,525 INFO] Step 18600/50000; xent: 1.55; lr: 0.0000147; 101 docs/s;   5921 sec
[2020-07-23 19:57:20,413 INFO] Step 18650/50000; xent: 1.50; lr: 0.0000146; 101 docs/s;   5937 sec
[2020-07-23 19:57:24,826 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.144.bert.pt, number of examples: 1997
[2020-07-23 19:57:36,177 INFO] Step 18700/50000; xent: 1.53; lr: 0.0000146;  95 docs/s;   5952 sec
[2020-07-23 19:57:51,961 INFO] Step 18750/50000; xent: 1.47; lr: 0.0000146;  95 docs/s;   5968 sec
[2020-07-23 19:58:07,363 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.633.bert.pt, number of examples: 1996
[2020-07-23 19:58:07,669 INFO] Step 18800/50000; xent: 1.40; lr: 0.0000146;  95 docs/s;   5984 sec
[2020-07-23 19:58:23,449 INFO] Step 18850/50000; xent: 1.60; lr: 0.0000146; 100 docs/s;   6000 sec
[2020-07-23 19:58:39,117 INFO] Step 18900/50000; xent: 1.56; lr: 0.0000145;  99 docs/s;   6015 sec
[2020-07-23 19:58:47,016 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.595.bert.pt, number of examples: 2001
[2020-07-23 19:58:54,886 INFO] Step 18950/50000; xent: 1.60; lr: 0.0000145; 100 docs/s;   6031 sec
[2020-07-23 19:59:10,703 INFO] Step 19000/50000; xent: 1.53; lr: 0.0000145;  99 docs/s;   6047 sec
[2020-07-23 19:59:26,605 INFO] Step 19050/50000; xent: 1.53; lr: 0.0000145;  96 docs/s;   6063 sec
[2020-07-23 19:59:28,203 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.473.bert.pt, number of examples: 1998
[2020-07-23 19:59:42,566 INFO] Step 19100/50000; xent: 1.55; lr: 0.0000145; 100 docs/s;   6079 sec
[2020-07-23 19:59:58,287 INFO] Step 19150/50000; xent: 1.60; lr: 0.0000145; 102 docs/s;   6095 sec
[2020-07-23 20:00:07,599 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.881.bert.pt, number of examples: 1991
[2020-07-23 20:00:13,737 INFO] Step 19200/50000; xent: 1.55; lr: 0.0000144; 101 docs/s;   6110 sec
[2020-07-23 20:00:29,170 INFO] Step 19250/50000; xent: 1.53; lr: 0.0000144; 103 docs/s;   6125 sec
[2020-07-23 20:00:44,533 INFO] Step 19300/50000; xent: 1.52; lr: 0.0000144; 103 docs/s;   6141 sec
[2020-07-23 20:00:46,438 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.155.bert.pt, number of examples: 1997
[2020-07-23 20:01:00,097 INFO] Step 19350/50000; xent: 1.50; lr: 0.0000144; 102 docs/s;   6156 sec
[2020-07-23 20:01:15,534 INFO] Step 19400/50000; xent: 1.52; lr: 0.0000144; 102 docs/s;   6172 sec
[2020-07-23 20:01:25,726 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.561.bert.pt, number of examples: 1994
[2020-07-23 20:01:31,040 INFO] Step 19450/50000; xent: 1.50; lr: 0.0000143; 100 docs/s;   6187 sec
[2020-07-23 20:01:46,573 INFO] Step 19500/50000; xent: 1.51; lr: 0.0000143;  99 docs/s;   6203 sec
[2020-07-23 20:02:02,035 INFO] Step 19550/50000; xent: 1.51; lr: 0.0000143;  98 docs/s;   6218 sec
[2020-07-23 20:02:06,097 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.866.bert.pt, number of examples: 1997
[2020-07-23 20:02:17,545 INFO] Step 19600/50000; xent: 1.54; lr: 0.0000143; 101 docs/s;   6234 sec
[2020-07-23 20:02:32,955 INFO] Step 19650/50000; xent: 1.52; lr: 0.0000143; 102 docs/s;   6249 sec
[2020-07-23 20:02:45,302 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.395.bert.pt, number of examples: 1989
[2020-07-23 20:02:48,390 INFO] Step 19700/50000; xent: 1.55; lr: 0.0000142; 102 docs/s;   6265 sec
[2020-07-23 20:03:03,804 INFO] Step 19750/50000; xent: 1.41; lr: 0.0000142; 103 docs/s;   6280 sec
[2020-07-23 20:03:19,257 INFO] Step 19800/50000; xent: 1.41; lr: 0.0000142; 104 docs/s;   6295 sec
[2020-07-23 20:03:23,915 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.357.bert.pt, number of examples: 2000
[2020-07-23 20:03:34,747 INFO] Step 19850/50000; xent: 1.54; lr: 0.0000142; 103 docs/s;   6311 sec
[2020-07-23 20:03:50,376 INFO] Step 19900/50000; xent: 1.60; lr: 0.0000142; 101 docs/s;   6327 sec
[2020-07-23 20:04:03,353 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.607.bert.pt, number of examples: 2001
[2020-07-23 20:04:05,823 INFO] Step 19950/50000; xent: 1.58; lr: 0.0000142; 100 docs/s;   6342 sec
[2020-07-23 20:04:21,344 INFO] Step 20000/50000; xent: 1.45; lr: 0.0000141; 100 docs/s;   6358 sec
[2020-07-23 20:04:21,346 INFO] Saving checkpoint ./models/models_check_points/model_step_20000.pt
[2020-07-23 20:04:37,765 INFO] Step 20050/50000; xent: 1.58; lr: 0.0000141;  94 docs/s;   6374 sec
[2020-07-23 20:04:44,396 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.168.bert.pt, number of examples: 1998
[2020-07-23 20:04:53,206 INFO] Step 20100/50000; xent: 1.49; lr: 0.0000141; 100 docs/s;   6389 sec
[2020-07-23 20:05:08,737 INFO] Step 20150/50000; xent: 1.48; lr: 0.0000141; 102 docs/s;   6405 sec
[2020-07-23 20:05:23,871 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.614.bert.pt, number of examples: 1996
[2020-07-23 20:05:24,176 INFO] Step 20200/50000; xent: 1.47; lr: 0.0000141; 102 docs/s;   6420 sec
[2020-07-23 20:05:39,727 INFO] Step 20250/50000; xent: 1.76; lr: 0.0000141; 101 docs/s;   6436 sec
[2020-07-23 20:05:55,289 INFO] Step 20300/50000; xent: 1.73; lr: 0.0000140; 100 docs/s;   6452 sec
[2020-07-23 20:06:03,698 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.500.bert.pt, number of examples: 1978
[2020-07-23 20:06:10,693 INFO] Step 20350/50000; xent: 1.61; lr: 0.0000140; 101 docs/s;   6467 sec
[2020-07-23 20:06:26,114 INFO] Step 20400/50000; xent: 1.50; lr: 0.0000140; 101 docs/s;   6482 sec
[2020-07-23 20:06:41,597 INFO] Step 20450/50000; xent: 1.44; lr: 0.0000140; 100 docs/s;   6498 sec
[2020-07-23 20:06:42,894 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.572.bert.pt, number of examples: 1998
[2020-07-23 20:06:57,204 INFO] Step 20500/50000; xent: 1.45; lr: 0.0000140; 101 docs/s;   6513 sec
[2020-07-23 20:07:12,777 INFO] Step 20550/50000; xent: 1.50; lr: 0.0000140; 101 docs/s;   6529 sec
[2020-07-23 20:07:22,621 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.731.bert.pt, number of examples: 1990
[2020-07-23 20:07:28,601 INFO] Step 20600/50000; xent: 1.56; lr: 0.0000139; 100 docs/s;   6545 sec
[2020-07-23 20:07:44,548 INFO] Step 20650/50000; xent: 1.65; lr: 0.0000139;  98 docs/s;   6561 sec
[2020-07-23 20:08:00,251 INFO] Step 20700/50000; xent: 1.63; lr: 0.0000139; 100 docs/s;   6576 sec
[2020-07-23 20:08:02,769 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.626.bert.pt, number of examples: 1993
[2020-07-23 20:08:15,992 INFO] Step 20750/50000; xent: 1.76; lr: 0.0000139;  99 docs/s;   6592 sec
[2020-07-23 20:08:31,671 INFO] Step 20800/50000; xent: 1.70; lr: 0.0000139;  99 docs/s;   6608 sec
[2020-07-23 20:08:42,952 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.236.bert.pt, number of examples: 1997
[2020-07-23 20:08:47,296 INFO] Step 20850/50000; xent: 1.73; lr: 0.0000139;  98 docs/s;   6624 sec
[2020-07-23 20:09:02,842 INFO] Step 20900/50000; xent: 1.54; lr: 0.0000138; 100 docs/s;   6639 sec
[2020-07-23 20:09:18,422 INFO] Step 20950/50000; xent: 1.58; lr: 0.0000138; 101 docs/s;   6655 sec
[2020-07-23 20:09:22,740 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.425.bert.pt, number of examples: 1992
[2020-07-23 20:09:33,896 INFO] Step 21000/50000; xent: 1.56; lr: 0.0000138;  98 docs/s;   6670 sec
[2020-07-23 20:09:49,659 INFO] Step 21050/50000; xent: 1.46; lr: 0.0000138;  95 docs/s;   6686 sec
[2020-07-23 20:10:04,284 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.347.bert.pt, number of examples: 1989
[2020-07-23 20:10:05,239 INFO] Step 21100/50000; xent: 1.58; lr: 0.0000138;  96 docs/s;   6701 sec
[2020-07-23 20:10:20,814 INFO] Step 21150/50000; xent: 1.71; lr: 0.0000138;  98 docs/s;   6717 sec
[2020-07-23 20:10:36,231 INFO] Step 21200/50000; xent: 1.64; lr: 0.0000137;  98 docs/s;   6732 sec
[2020-07-23 20:10:45,001 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.786.bert.pt, number of examples: 1998
[2020-07-23 20:10:51,816 INFO] Step 21250/50000; xent: 1.63; lr: 0.0000137;  99 docs/s;   6748 sec
[2020-07-23 20:11:07,434 INFO] Step 21300/50000; xent: 1.59; lr: 0.0000137;  99 docs/s;   6764 sec
[2020-07-23 20:11:22,962 INFO] Step 21350/50000; xent: 1.62; lr: 0.0000137; 101 docs/s;   6779 sec
[2020-07-23 20:11:24,873 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.166.bert.pt, number of examples: 1996
[2020-07-23 20:11:38,825 INFO] Step 21400/50000; xent: 1.54; lr: 0.0000137; 101 docs/s;   6795 sec
[2020-07-23 20:11:54,388 INFO] Step 21450/50000; xent: 1.53; lr: 0.0000137; 101 docs/s;   6811 sec
[2020-07-23 20:12:04,232 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.574.bert.pt, number of examples: 1998
[2020-07-23 20:12:10,261 INFO] Step 21500/50000; xent: 1.45; lr: 0.0000136; 101 docs/s;   6826 sec
[2020-07-23 20:12:26,039 INFO] Step 21550/50000; xent: 1.46; lr: 0.0000136;  99 docs/s;   6842 sec
[2020-07-23 20:12:41,892 INFO] Step 21600/50000; xent: 1.45; lr: 0.0000136;  98 docs/s;   6858 sec
[2020-07-23 20:12:45,039 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.655.bert.pt, number of examples: 1999
[2020-07-23 20:12:57,832 INFO] Step 21650/50000; xent: 1.64; lr: 0.0000136;  94 docs/s;   6874 sec
[2020-07-23 20:13:13,511 INFO] Step 21700/50000; xent: 1.68; lr: 0.0000136;  95 docs/s;   6890 sec
[2020-07-23 20:13:27,348 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.970.bert.pt, number of examples: 1999
[2020-07-23 20:13:29,205 INFO] Step 21750/50000; xent: 1.67; lr: 0.0000136;  96 docs/s;   6905 sec
[2020-07-23 20:13:44,799 INFO] Step 21800/50000; xent: 1.48; lr: 0.0000135;  99 docs/s;   6921 sec
[2020-07-23 20:14:00,445 INFO] Step 21850/50000; xent: 1.38; lr: 0.0000135;  99 docs/s;   6937 sec
[2020-07-23 20:14:07,634 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.282.bert.pt, number of examples: 1998
[2020-07-23 20:14:16,092 INFO] Step 21900/50000; xent: 1.47; lr: 0.0000135;  98 docs/s;   6952 sec
[2020-07-23 20:14:31,661 INFO] Step 21950/50000; xent: 1.47; lr: 0.0000135;  99 docs/s;   6968 sec
[2020-07-23 20:14:47,304 INFO] Step 22000/50000; xent: 1.56; lr: 0.0000135;  99 docs/s;   6984 sec
[2020-07-23 20:14:47,966 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.414.bert.pt, number of examples: 1993
[2020-07-23 20:15:02,906 INFO] Step 22050/50000; xent: 1.58; lr: 0.0000135;  99 docs/s;   6999 sec
[2020-07-23 20:15:18,718 INFO] Step 22100/50000; xent: 1.67; lr: 0.0000135;  98 docs/s;   7015 sec
[2020-07-23 20:15:28,748 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.101.bert.pt, number of examples: 1998
[2020-07-23 20:15:34,397 INFO] Step 22150/50000; xent: 1.58; lr: 0.0000134;  99 docs/s;   7031 sec
[2020-07-23 20:15:50,037 INFO] Step 22200/50000; xent: 1.48; lr: 0.0000134; 102 docs/s;   7046 sec
[2020-07-23 20:16:05,535 INFO] Step 22250/50000; xent: 1.50; lr: 0.0000134; 102 docs/s;   7062 sec
[2020-07-23 20:16:08,097 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.568.bert.pt, number of examples: 1999
[2020-07-23 20:16:21,160 INFO] Step 22300/50000; xent: 1.49; lr: 0.0000134; 100 docs/s;   7077 sec
[2020-07-23 20:16:36,812 INFO] Step 22350/50000; xent: 1.50; lr: 0.0000134;  99 docs/s;   7093 sec
[2020-07-23 20:16:48,285 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.654.bert.pt, number of examples: 1995
[2020-07-23 20:16:52,407 INFO] Step 22400/50000; xent: 1.60; lr: 0.0000134;  97 docs/s;   7109 sec
[2020-07-23 20:17:08,064 INFO] Step 22450/50000; xent: 1.65; lr: 0.0000133;  96 docs/s;   7124 sec
[2020-07-23 20:17:23,697 INFO] Step 22500/50000; xent: 1.61; lr: 0.0000133;  95 docs/s;   7140 sec
[2020-07-23 20:17:29,931 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.859.bert.pt, number of examples: 1996
[2020-07-23 20:17:39,271 INFO] Step 22550/50000; xent: 1.48; lr: 0.0000133;  99 docs/s;   7155 sec
[2020-07-23 20:17:54,874 INFO] Step 22600/50000; xent: 1.45; lr: 0.0000133; 101 docs/s;   7171 sec
[2020-07-23 20:18:09,643 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.739.bert.pt, number of examples: 1994
[2020-07-23 20:18:10,534 INFO] Step 22650/50000; xent: 1.44; lr: 0.0000133; 101 docs/s;   7187 sec
[2020-07-23 20:18:26,067 INFO] Step 22700/50000; xent: 1.26; lr: 0.0000133; 103 docs/s;   7202 sec
[2020-07-23 20:18:41,598 INFO] Step 22750/50000; xent: 1.32; lr: 0.0000133; 103 docs/s;   7218 sec
[2020-07-23 20:18:48,198 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.24.bert.pt, number of examples: 1998
[2020-07-23 20:18:57,246 INFO] Step 22800/50000; xent: 1.44; lr: 0.0000132; 101 docs/s;   7233 sec
[2020-07-23 20:19:12,854 INFO] Step 22850/50000; xent: 1.46; lr: 0.0000132; 102 docs/s;   7249 sec
[2020-07-23 20:19:27,899 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.296.bert.pt, number of examples: 1997
[2020-07-23 20:19:28,529 INFO] Step 22900/50000; xent: 1.50; lr: 0.0000132; 101 docs/s;   7265 sec
[2020-07-23 20:19:44,059 INFO] Step 22950/50000; xent: 1.64; lr: 0.0000132;  99 docs/s;   7280 sec
[2020-07-23 20:19:59,542 INFO] Step 23000/50000; xent: 1.59; lr: 0.0000132;  99 docs/s;   7296 sec
[2020-07-23 20:20:07,992 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.701.bert.pt, number of examples: 2001
[2020-07-23 20:20:15,116 INFO] Step 23050/50000; xent: 1.60; lr: 0.0000132; 100 docs/s;   7311 sec
[2020-07-23 20:20:30,658 INFO] Step 23100/50000; xent: 1.61; lr: 0.0000132; 102 docs/s;   7327 sec
[2020-07-23 20:20:46,258 INFO] Step 23150/50000; xent: 1.62; lr: 0.0000131; 101 docs/s;   7342 sec
[2020-07-23 20:20:47,521 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.268.bert.pt, number of examples: 1995
[2020-07-23 20:21:01,898 INFO] Step 23200/50000; xent: 1.50; lr: 0.0000131; 101 docs/s;   7358 sec
[2020-07-23 20:21:17,505 INFO] Step 23250/50000; xent: 1.54; lr: 0.0000131; 101 docs/s;   7374 sec
[2020-07-23 20:21:27,105 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.956.bert.pt, number of examples: 1998
[2020-07-23 20:21:33,017 INFO] Step 23300/50000; xent: 1.46; lr: 0.0000131; 100 docs/s;   7389 sec
[2020-07-23 20:21:48,671 INFO] Step 23350/50000; xent: 1.40; lr: 0.0000131; 100 docs/s;   7405 sec
[2020-07-23 20:22:04,214 INFO] Step 23400/50000; xent: 1.40; lr: 0.0000131; 100 docs/s;   7420 sec
[2020-07-23 20:22:07,327 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.906.bert.pt, number of examples: 1992
[2020-07-23 20:22:19,767 INFO] Step 23450/50000; xent: 1.61; lr: 0.0000131;  98 docs/s;   7436 sec
[2020-07-23 20:22:35,348 INFO] Step 23500/50000; xent: 1.68; lr: 0.0000130;  98 docs/s;   7452 sec
[2020-07-23 20:22:47,903 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.571.bert.pt, number of examples: 1995
[2020-07-23 20:22:51,021 INFO] Step 23550/50000; xent: 1.63; lr: 0.0000130;  99 docs/s;   7467 sec
[2020-07-23 20:23:06,625 INFO] Step 23600/50000; xent: 1.44; lr: 0.0000130; 101 docs/s;   7483 sec
[2020-07-23 20:23:22,285 INFO] Step 23650/50000; xent: 1.52; lr: 0.0000130; 100 docs/s;   7499 sec
[2020-07-23 20:23:27,511 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.858.bert.pt, number of examples: 1997
[2020-07-23 20:23:37,803 INFO] Step 23700/50000; xent: 1.49; lr: 0.0000130; 101 docs/s;   7514 sec
[2020-07-23 20:23:53,378 INFO] Step 23750/50000; xent: 1.48; lr: 0.0000130; 101 docs/s;   7530 sec
[2020-07-23 20:24:06,876 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.33.bert.pt, number of examples: 1994
[2020-07-23 20:24:08,994 INFO] Step 23800/50000; xent: 1.51; lr: 0.0000130; 101 docs/s;   7545 sec
[2020-07-23 20:24:24,721 INFO] Step 23850/50000; xent: 1.56; lr: 0.0000130; 101 docs/s;   7561 sec
[2020-07-23 20:24:40,191 INFO] Step 23900/50000; xent: 1.55; lr: 0.0000129; 101 docs/s;   7576 sec
[2020-07-23 20:24:46,757 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.718.bert.pt, number of examples: 1998
[2020-07-23 20:24:55,691 INFO] Step 23950/50000; xent: 1.58; lr: 0.0000129;  99 docs/s;   7592 sec
[2020-07-23 20:25:11,399 INFO] Step 24000/50000; xent: 1.67; lr: 0.0000129; 100 docs/s;   7608 sec
[2020-07-23 20:25:26,914 INFO] Step 24050/50000; xent: 1.62; lr: 0.0000129;  99 docs/s;   7623 sec
[2020-07-23 20:25:26,970 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.559.bert.pt, number of examples: 1996
[2020-07-23 20:25:42,458 INFO] Step 24100/50000; xent: 1.43; lr: 0.0000129;  96 docs/s;   7639 sec
[2020-07-23 20:25:57,963 INFO] Step 24150/50000; xent: 1.49; lr: 0.0000129;  98 docs/s;   7654 sec
[2020-07-23 20:26:08,543 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.196.bert.pt, number of examples: 1998
[2020-07-23 20:26:13,526 INFO] Step 24200/50000; xent: 1.57; lr: 0.0000129;  97 docs/s;   7670 sec
[2020-07-23 20:26:29,331 INFO] Step 24250/50000; xent: 1.63; lr: 0.0000128;  98 docs/s;   7686 sec
[2020-07-23 20:26:45,186 INFO] Step 24300/50000; xent: 1.69; lr: 0.0000128;  98 docs/s;   7701 sec
[2020-07-23 20:26:49,141 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.358.bert.pt, number of examples: 1996
[2020-07-23 20:27:00,399 INFO] Step 24350/50000; xent: 1.58; lr: 0.0000128; 102 docs/s;   7717 sec
[2020-07-23 20:27:15,609 INFO] Step 24400/50000; xent: 1.57; lr: 0.0000128; 103 docs/s;   7732 sec
[2020-07-23 20:27:27,858 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.406.bert.pt, number of examples: 1998
[2020-07-23 20:27:30,894 INFO] Step 24450/50000; xent: 1.57; lr: 0.0000128; 102 docs/s;   7747 sec
[2020-07-23 20:27:46,029 INFO] Step 24500/50000; xent: 1.70; lr: 0.0000128; 103 docs/s;   7762 sec
[2020-07-23 20:28:01,484 INFO] Step 24550/50000; xent: 1.65; lr: 0.0000128; 101 docs/s;   7778 sec
[2020-07-23 20:28:07,459 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.105.bert.pt, number of examples: 1996
[2020-07-23 20:28:17,125 INFO] Step 24600/50000; xent: 1.51; lr: 0.0000128; 100 docs/s;   7793 sec
[2020-07-23 20:28:32,751 INFO] Step 24650/50000; xent: 1.50; lr: 0.0000127; 102 docs/s;   7809 sec
[2020-07-23 20:28:47,104 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.26.bert.pt, number of examples: 1998
[2020-07-23 20:28:48,341 INFO] Step 24700/50000; xent: 1.40; lr: 0.0000127; 100 docs/s;   7825 sec
[2020-07-23 20:29:03,772 INFO] Step 24750/50000; xent: 1.57; lr: 0.0000127; 102 docs/s;   7840 sec
[2020-07-23 20:29:19,419 INFO] Step 24800/50000; xent: 1.53; lr: 0.0000127; 103 docs/s;   7856 sec
[2020-07-23 20:29:26,300 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.843.bert.pt, number of examples: 1988
[2020-07-23 20:29:34,935 INFO] Step 24850/50000; xent: 1.71; lr: 0.0000127; 102 docs/s;   7871 sec
[2020-07-23 20:29:50,514 INFO] Step 24900/50000; xent: 1.73; lr: 0.0000127; 102 docs/s;   7887 sec
[2020-07-23 20:30:05,260 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.313.bert.pt, number of examples: 1998
[2020-07-23 20:30:06,190 INFO] Step 24950/50000; xent: 1.69; lr: 0.0000127; 102 docs/s;   7902 sec
[2020-07-23 20:30:21,771 INFO] Step 25000/50000; xent: 1.51; lr: 0.0000126; 102 docs/s;   7918 sec
[2020-07-23 20:30:21,773 INFO] Saving checkpoint ./models/models_check_points/model_step_25000.pt
[2020-07-23 20:30:38,055 INFO] Step 25050/50000; xent: 1.52; lr: 0.0000126;  96 docs/s;   7934 sec
[2020-07-23 20:30:45,271 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.251.bert.pt, number of examples: 2000
[2020-07-23 20:30:53,710 INFO] Step 25100/50000; xent: 1.49; lr: 0.0000126; 100 docs/s;   7950 sec
[2020-07-23 20:31:09,455 INFO] Step 25150/50000; xent: 1.48; lr: 0.0000126;  99 docs/s;   7966 sec
[2020-07-23 20:31:25,799 INFO] Step 25200/50000; xent: 1.43; lr: 0.0000126;  96 docs/s;   7982 sec
[2020-07-23 20:31:26,192 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.267.bert.pt, number of examples: 1997
[2020-07-23 20:31:42,131 INFO] Step 25250/50000; xent: 1.55; lr: 0.0000126;  97 docs/s;   7998 sec
[2020-07-23 20:31:58,425 INFO] Step 25300/50000; xent: 1.57; lr: 0.0000126;  97 docs/s;   8015 sec
[2020-07-23 20:32:07,460 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.553.bert.pt, number of examples: 2000
[2020-07-23 20:32:14,862 INFO] Step 25350/50000; xent: 1.49; lr: 0.0000126;  97 docs/s;   8031 sec
[2020-07-23 20:32:30,345 INFO] Step 25400/50000; xent: 1.52; lr: 0.0000125; 103 docs/s;   8047 sec
[2020-07-23 20:32:45,885 INFO] Step 25450/50000; xent: 1.45; lr: 0.0000125; 103 docs/s;   8062 sec
[2020-07-23 20:32:46,828 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.671.bert.pt, number of examples: 1955
[2020-07-23 20:33:01,415 INFO] Step 25500/50000; xent: 1.62; lr: 0.0000125;  97 docs/s;   8078 sec
[2020-07-23 20:33:16,990 INFO] Step 25550/50000; xent: 1.51; lr: 0.0000125;  98 docs/s;   8093 sec
[2020-07-23 20:33:26,659 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.736.bert.pt, number of examples: 1974
[2020-07-23 20:33:32,552 INFO] Step 25600/50000; xent: 1.60; lr: 0.0000125;  99 docs/s;   8109 sec
[2020-07-23 20:33:48,068 INFO] Step 25650/50000; xent: 1.60; lr: 0.0000125; 100 docs/s;   8124 sec
[2020-07-23 20:34:03,672 INFO] Step 25700/50000; xent: 1.55; lr: 0.0000125; 100 docs/s;   8140 sec
[2020-07-23 20:34:06,234 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.12.bert.pt, number of examples: 1992
[2020-07-23 20:34:19,333 INFO] Step 25750/50000; xent: 1.65; lr: 0.0000125;  98 docs/s;   8156 sec
[2020-07-23 20:34:35,174 INFO] Step 25800/50000; xent: 1.71; lr: 0.0000125;  98 docs/s;   8171 sec
[2020-07-23 20:34:46,965 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.735.bert.pt, number of examples: 1975
[2020-07-23 20:34:50,858 INFO] Step 25850/50000; xent: 1.73; lr: 0.0000124;  96 docs/s;   8187 sec
[2020-07-23 20:35:06,764 INFO] Step 25900/50000; xent: 1.57; lr: 0.0000124;  96 docs/s;   8203 sec
[2020-07-23 20:35:22,428 INFO] Step 25950/50000; xent: 1.61; lr: 0.0000124;  97 docs/s;   8219 sec
[2020-07-23 20:35:28,224 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.702.bert.pt, number of examples: 1997
[2020-07-23 20:35:38,313 INFO] Step 26000/50000; xent: 1.65; lr: 0.0000124;  98 docs/s;   8235 sec
[2020-07-23 20:35:54,067 INFO] Step 26050/50000; xent: 1.62; lr: 0.0000124;  99 docs/s;   8250 sec
[2020-07-23 20:36:08,082 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.932.bert.pt, number of examples: 1996
[2020-07-23 20:36:10,003 INFO] Step 26100/50000; xent: 1.60; lr: 0.0000124;  99 docs/s;   8266 sec
[2020-07-23 20:36:25,753 INFO] Step 26150/50000; xent: 1.54; lr: 0.0000124;  95 docs/s;   8282 sec
[2020-07-23 20:36:41,449 INFO] Step 26200/50000; xent: 1.43; lr: 0.0000124;  96 docs/s;   8298 sec
[2020-07-23 20:36:50,038 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.704.bert.pt, number of examples: 2000
[2020-07-23 20:36:57,249 INFO] Step 26250/50000; xent: 1.55; lr: 0.0000123;  96 docs/s;   8313 sec
[2020-07-23 20:37:13,090 INFO] Step 26300/50000; xent: 1.64; lr: 0.0000123;  99 docs/s;   8329 sec
[2020-07-23 20:37:28,856 INFO] Step 26350/50000; xent: 1.54; lr: 0.0000123;  99 docs/s;   8345 sec
[2020-07-23 20:37:30,485 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.662.bert.pt, number of examples: 2000
[2020-07-23 20:37:44,700 INFO] Step 26400/50000; xent: 1.56; lr: 0.0000123;  96 docs/s;   8361 sec
[2020-07-23 20:38:00,466 INFO] Step 26450/50000; xent: 1.56; lr: 0.0000123;  97 docs/s;   8377 sec
[2020-07-23 20:38:12,387 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.81.bert.pt, number of examples: 1995
[2020-07-23 20:38:16,200 INFO] Step 26500/50000; xent: 1.64; lr: 0.0000123;  96 docs/s;   8392 sec
[2020-07-23 20:38:32,053 INFO] Step 26550/50000; xent: 1.53; lr: 0.0000123;  99 docs/s;   8408 sec
[2020-07-23 20:38:47,938 INFO] Step 26600/50000; xent: 1.59; lr: 0.0000123;  98 docs/s;   8424 sec
[2020-07-23 20:38:52,992 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.872.bert.pt, number of examples: 1998
[2020-07-23 20:39:03,734 INFO] Step 26650/50000; xent: 1.50; lr: 0.0000123;  99 docs/s;   8440 sec
[2020-07-23 20:39:19,350 INFO] Step 26700/50000; xent: 1.47; lr: 0.0000122; 101 docs/s;   8456 sec
[2020-07-23 20:39:32,468 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.410.bert.pt, number of examples: 1996
[2020-07-23 20:39:34,910 INFO] Step 26750/50000; xent: 1.53; lr: 0.0000122; 102 docs/s;   8471 sec
[2020-07-23 20:39:50,264 INFO] Step 26800/50000; xent: 1.53; lr: 0.0000122; 102 docs/s;   8486 sec
[2020-07-23 20:40:05,428 INFO] Step 26850/50000; xent: 1.61; lr: 0.0000122; 103 docs/s;   8502 sec
[2020-07-23 20:40:11,383 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.141.bert.pt, number of examples: 1986
[2020-07-23 20:40:20,423 INFO] Step 26900/50000; xent: 1.59; lr: 0.0000122; 102 docs/s;   8517 sec
[2020-07-23 20:40:35,552 INFO] Step 26950/50000; xent: 1.64; lr: 0.0000122; 103 docs/s;   8532 sec
[2020-07-23 20:40:50,422 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.459.bert.pt, number of examples: 1999
[2020-07-23 20:40:50,717 INFO] Step 27000/50000; xent: 1.63; lr: 0.0000122; 102 docs/s;   8547 sec
[2020-07-23 20:41:05,723 INFO] Step 27050/50000; xent: 1.46; lr: 0.0000122; 106 docs/s;   8562 sec
[2020-07-23 20:41:20,717 INFO] Step 27100/50000; xent: 1.40; lr: 0.0000121; 105 docs/s;   8577 sec
[2020-07-23 20:41:28,468 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.557.bert.pt, number of examples: 1993
[2020-07-23 20:41:35,693 INFO] Step 27150/50000; xent: 1.47; lr: 0.0000121; 102 docs/s;   8592 sec
[2020-07-23 20:41:50,674 INFO] Step 27200/50000; xent: 1.44; lr: 0.0000121; 101 docs/s;   8607 sec
[2020-07-23 20:42:05,769 INFO] Step 27250/50000; xent: 1.46; lr: 0.0000121; 101 docs/s;   8622 sec
[2020-07-23 20:42:07,952 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.817.bert.pt, number of examples: 1989
[2020-07-23 20:42:20,883 INFO] Step 27300/50000; xent: 1.45; lr: 0.0000121; 104 docs/s;   8637 sec
[2020-07-23 20:42:35,952 INFO] Step 27350/50000; xent: 1.46; lr: 0.0000121; 105 docs/s;   8652 sec
[2020-07-23 20:42:45,858 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.256.bert.pt, number of examples: 2000
[2020-07-23 20:42:51,006 INFO] Step 27400/50000; xent: 1.50; lr: 0.0000121; 104 docs/s;   8667 sec
[2020-07-23 20:43:06,021 INFO] Step 27450/50000; xent: 1.57; lr: 0.0000121; 103 docs/s;   8682 sec
[2020-07-23 20:43:21,110 INFO] Step 27500/50000; xent: 1.54; lr: 0.0000121; 103 docs/s;   8697 sec
[2020-07-23 20:43:24,726 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.187.bert.pt, number of examples: 1992
[2020-07-23 20:43:36,141 INFO] Step 27550/50000; xent: 1.48; lr: 0.0000120; 104 docs/s;   8712 sec
[2020-07-23 20:43:51,285 INFO] Step 27600/50000; xent: 1.50; lr: 0.0000120; 104 docs/s;   8728 sec
[2020-07-23 20:44:03,035 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.911.bert.pt, number of examples: 1996
[2020-07-23 20:44:06,338 INFO] Step 27650/50000; xent: 1.52; lr: 0.0000120; 104 docs/s;   8743 sec
[2020-07-23 20:44:21,604 INFO] Step 27700/50000; xent: 1.70; lr: 0.0000120; 101 docs/s;   8758 sec
[2020-07-23 20:44:36,681 INFO] Step 27750/50000; xent: 1.67; lr: 0.0000120; 101 docs/s;   8773 sec
[2020-07-23 20:44:42,537 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.476.bert.pt, number of examples: 1997
[2020-07-23 20:44:51,995 INFO] Step 27800/50000; xent: 1.59; lr: 0.0000120; 102 docs/s;   8788 sec
[2020-07-23 20:45:07,272 INFO] Step 27850/50000; xent: 1.58; lr: 0.0000120; 102 docs/s;   8803 sec
[2020-07-23 20:45:21,846 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.470.bert.pt, number of examples: 1996
[2020-07-23 20:45:22,456 INFO] Step 27900/50000; xent: 1.60; lr: 0.0000120; 101 docs/s;   8819 sec
[2020-07-23 20:45:37,714 INFO] Step 27950/50000; xent: 1.51; lr: 0.0000120; 103 docs/s;   8834 sec
[2020-07-23 20:45:52,907 INFO] Step 28000/50000; xent: 1.53; lr: 0.0000120; 103 docs/s;   8849 sec
[2020-07-23 20:46:00,777 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.922.bert.pt, number of examples: 1999
[2020-07-23 20:46:08,137 INFO] Step 28050/50000; xent: 1.60; lr: 0.0000119; 102 docs/s;   8864 sec
[2020-07-23 20:46:23,390 INFO] Step 28100/50000; xent: 1.67; lr: 0.0000119; 101 docs/s;   8880 sec
[2020-07-23 20:46:38,606 INFO] Step 28150/50000; xent: 1.67; lr: 0.0000119; 102 docs/s;   8895 sec
[2020-07-23 20:46:39,890 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.530.bert.pt, number of examples: 1996
[2020-07-23 20:46:53,790 INFO] Step 28200/50000; xent: 1.51; lr: 0.0000119; 105 docs/s;   8910 sec
[2020-07-23 20:47:09,067 INFO] Step 28250/50000; xent: 1.42; lr: 0.0000119; 105 docs/s;   8925 sec
[2020-07-23 20:47:17,901 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.103.bert.pt, number of examples: 1993
[2020-07-23 20:47:24,290 INFO] Step 28300/50000; xent: 1.45; lr: 0.0000119; 103 docs/s;   8941 sec
[2020-07-23 20:47:39,604 INFO] Step 28350/50000; xent: 1.55; lr: 0.0000119; 103 docs/s;   8956 sec
[2020-07-23 20:47:54,900 INFO] Step 28400/50000; xent: 1.51; lr: 0.0000119; 104 docs/s;   8971 sec
[2020-07-23 20:47:56,719 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.829.bert.pt, number of examples: 1994
[2020-07-23 20:48:10,034 INFO] Step 28450/50000; xent: 1.55; lr: 0.0000119; 102 docs/s;   8986 sec
[2020-07-23 20:48:25,304 INFO] Step 28500/50000; xent: 1.53; lr: 0.0000118; 103 docs/s;   9002 sec
[2020-07-23 20:48:35,677 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.323.bert.pt, number of examples: 1994
[2020-07-23 20:48:40,545 INFO] Step 28550/50000; xent: 1.50; lr: 0.0000118; 103 docs/s;   9017 sec
[2020-07-23 20:48:55,779 INFO] Step 28600/50000; xent: 1.56; lr: 0.0000118; 104 docs/s;   9032 sec
[2020-07-23 20:49:10,966 INFO] Step 28650/50000; xent: 1.56; lr: 0.0000118; 104 docs/s;   9047 sec
[2020-07-23 20:49:14,033 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.17.bert.pt, number of examples: 1998
[2020-07-23 20:49:26,339 INFO] Step 28700/50000; xent: 1.48; lr: 0.0000118; 102 docs/s;   9063 sec
[2020-07-23 20:49:41,515 INFO] Step 28750/50000; xent: 1.50; lr: 0.0000118; 101 docs/s;   9078 sec
[2020-07-23 20:49:53,427 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.58.bert.pt, number of examples: 2001
[2020-07-23 20:49:56,737 INFO] Step 28800/50000; xent: 1.56; lr: 0.0000118; 100 docs/s;   9093 sec
[2020-07-23 20:50:12,071 INFO] Step 28850/50000; xent: 1.50; lr: 0.0000118; 103 docs/s;   9108 sec
[2020-07-23 20:50:27,399 INFO] Step 28900/50000; xent: 1.46; lr: 0.0000118; 103 docs/s;   9124 sec
[2020-07-23 20:50:32,653 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.373.bert.pt, number of examples: 1991
[2020-07-23 20:50:42,802 INFO] Step 28950/50000; xent: 1.49; lr: 0.0000118; 101 docs/s;   9139 sec
[2020-07-23 20:50:58,046 INFO] Step 29000/50000; xent: 1.56; lr: 0.0000117; 100 docs/s;   9154 sec
[2020-07-23 20:51:12,444 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.594.bert.pt, number of examples: 1999
[2020-07-23 20:51:13,321 INFO] Step 29050/50000; xent: 1.53; lr: 0.0000117; 100 docs/s;   9170 sec
[2020-07-23 20:51:28,612 INFO] Step 29100/50000; xent: 1.52; lr: 0.0000117; 102 docs/s;   9185 sec
[2020-07-23 20:51:43,926 INFO] Step 29150/50000; xent: 1.52; lr: 0.0000117; 101 docs/s;   9200 sec
[2020-07-23 20:51:51,582 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.460.bert.pt, number of examples: 1998
[2020-07-23 20:51:59,214 INFO] Step 29200/50000; xent: 1.53; lr: 0.0000117; 102 docs/s;   9215 sec
[2020-07-23 20:52:14,469 INFO] Step 29250/50000; xent: 1.50; lr: 0.0000117; 104 docs/s;   9231 sec
[2020-07-23 20:52:29,749 INFO] Step 29300/50000; xent: 1.47; lr: 0.0000117; 104 docs/s;   9246 sec
[2020-07-23 20:52:30,112 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.216.bert.pt, number of examples: 2000
[2020-07-23 20:52:45,112 INFO] Step 29350/50000; xent: 1.55; lr: 0.0000117; 100 docs/s;   9261 sec
[2020-07-23 20:53:00,314 INFO] Step 29400/50000; xent: 1.60; lr: 0.0000117; 101 docs/s;   9277 sec
[2020-07-23 20:53:09,864 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.899.bert.pt, number of examples: 2000
[2020-07-23 20:53:15,644 INFO] Step 29450/50000; xent: 1.54; lr: 0.0000117; 102 docs/s;   9292 sec
[2020-07-23 20:53:30,807 INFO] Step 29500/50000; xent: 1.40; lr: 0.0000116; 102 docs/s;   9307 sec
[2020-07-23 20:53:46,122 INFO] Step 29550/50000; xent: 1.29; lr: 0.0000116; 103 docs/s;   9322 sec
[2020-07-23 20:53:48,932 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.958.bert.pt, number of examples: 1999
[2020-07-23 20:54:01,499 INFO] Step 29600/50000; xent: 1.39; lr: 0.0000116; 103 docs/s;   9338 sec
[2020-07-23 20:54:16,787 INFO] Step 29650/50000; xent: 1.39; lr: 0.0000116; 103 docs/s;   9353 sec
[2020-07-23 20:54:27,584 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.219.bert.pt, number of examples: 1998
[2020-07-23 20:54:32,189 INFO] Step 29700/50000; xent: 1.48; lr: 0.0000116; 102 docs/s;   9368 sec
[2020-07-23 20:54:47,539 INFO] Step 29750/50000; xent: 1.54; lr: 0.0000116; 101 docs/s;   9384 sec
[2020-07-23 20:55:02,927 INFO] Step 29800/50000; xent: 1.52; lr: 0.0000116; 101 docs/s;   9399 sec
[2020-07-23 20:55:07,196 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.368.bert.pt, number of examples: 1995
[2020-07-23 20:55:18,280 INFO] Step 29850/50000; xent: 1.51; lr: 0.0000116; 103 docs/s;   9415 sec
[2020-07-23 20:55:33,616 INFO] Step 29900/50000; xent: 1.62; lr: 0.0000116; 103 docs/s;   9430 sec
[2020-07-23 20:55:45,782 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.770.bert.pt, number of examples: 1993
[2020-07-23 20:55:48,858 INFO] Step 29950/50000; xent: 1.53; lr: 0.0000116; 102 docs/s;   9445 sec
[2020-07-23 20:56:04,051 INFO] Step 30000/50000; xent: 1.61; lr: 0.0000115; 101 docs/s;   9460 sec
[2020-07-23 20:56:04,053 INFO] Saving checkpoint ./models/models_check_points/model_step_30000.pt
[2020-07-23 20:56:20,138 INFO] Step 30050/50000; xent: 1.62; lr: 0.0000115;  98 docs/s;   9476 sec
[2020-07-23 20:56:25,672 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.842.bert.pt, number of examples: 1983
[2020-07-23 20:56:35,442 INFO] Step 30100/50000; xent: 1.72; lr: 0.0000115; 104 docs/s;   9492 sec
[2020-07-23 20:56:50,806 INFO] Step 30150/50000; xent: 1.64; lr: 0.0000115; 104 docs/s;   9507 sec
[2020-07-23 20:57:03,659 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.407.bert.pt, number of examples: 1997
[2020-07-23 20:57:06,116 INFO] Step 30200/50000; xent: 1.65; lr: 0.0000115; 104 docs/s;   9522 sec
[2020-07-23 20:57:21,447 INFO] Step 30250/50000; xent: 1.66; lr: 0.0000115; 103 docs/s;   9538 sec
[2020-07-23 20:57:36,881 INFO] Step 30300/50000; xent: 1.62; lr: 0.0000115; 105 docs/s;   9553 sec
[2020-07-23 20:57:42,417 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.632.bert.pt, number of examples: 1990
[2020-07-23 20:57:52,161 INFO] Step 30350/50000; xent: 1.62; lr: 0.0000115; 102 docs/s;   9568 sec
[2020-07-23 20:58:07,375 INFO] Step 30400/50000; xent: 1.60; lr: 0.0000115; 103 docs/s;   9584 sec
[2020-07-23 20:58:21,139 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.642.bert.pt, number of examples: 1997
[2020-07-23 20:58:22,665 INFO] Step 30450/50000; xent: 1.64; lr: 0.0000115; 102 docs/s;   9599 sec
[2020-07-23 20:58:37,963 INFO] Step 30500/50000; xent: 1.51; lr: 0.0000115; 101 docs/s;   9614 sec
[2020-07-23 20:58:53,161 INFO] Step 30550/50000; xent: 1.64; lr: 0.0000114; 101 docs/s;   9629 sec
[2020-07-23 20:59:00,525 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.864.bert.pt, number of examples: 1970
[2020-07-23 20:59:08,470 INFO] Step 30600/50000; xent: 1.60; lr: 0.0000114; 102 docs/s;   9645 sec
[2020-07-23 20:59:23,661 INFO] Step 30650/50000; xent: 1.49; lr: 0.0000114; 102 docs/s;   9660 sec
[2020-07-23 20:59:38,906 INFO] Step 30700/50000; xent: 1.56; lr: 0.0000114; 101 docs/s;   9675 sec
[2020-07-23 20:59:39,261 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.421.bert.pt, number of examples: 1989
[2020-07-23 20:59:54,297 INFO] Step 30750/50000; xent: 1.43; lr: 0.0000114; 103 docs/s;   9691 sec
[2020-07-23 21:00:09,592 INFO] Step 30800/50000; xent: 1.40; lr: 0.0000114; 103 docs/s;   9706 sec
[2020-07-23 21:00:17,936 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.472.bert.pt, number of examples: 1998
[2020-07-23 21:00:24,887 INFO] Step 30850/50000; xent: 1.45; lr: 0.0000114; 102 docs/s;   9721 sec
[2020-07-23 21:00:40,178 INFO] Step 30900/50000; xent: 1.51; lr: 0.0000114; 102 docs/s;   9736 sec
[2020-07-23 21:00:55,428 INFO] Step 30950/50000; xent: 1.49; lr: 0.0000114; 101 docs/s;   9752 sec
[2020-07-23 21:00:57,345 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.283.bert.pt, number of examples: 1999
[2020-07-23 21:01:10,768 INFO] Step 31000/50000; xent: 1.58; lr: 0.0000114; 100 docs/s;   9767 sec
[2020-07-23 21:01:26,182 INFO] Step 31050/50000; xent: 1.58; lr: 0.0000114; 101 docs/s;   9782 sec
[2020-07-23 21:01:37,174 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.480.bert.pt, number of examples: 1998
[2020-07-23 21:01:41,478 INFO] Step 31100/50000; xent: 1.50; lr: 0.0000113; 101 docs/s;   9798 sec
[2020-07-23 21:01:56,845 INFO] Step 31150/50000; xent: 1.22; lr: 0.0000113; 103 docs/s;   9813 sec
[2020-07-23 21:02:12,190 INFO] Step 31200/50000; xent: 1.21; lr: 0.0000113; 102 docs/s;   9828 sec
[2020-07-23 21:02:15,949 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.782.bert.pt, number of examples: 1996
[2020-07-23 21:02:27,543 INFO] Step 31250/50000; xent: 1.55; lr: 0.0000113; 103 docs/s;   9844 sec
[2020-07-23 21:02:42,853 INFO] Step 31300/50000; xent: 1.65; lr: 0.0000113; 103 docs/s;   9859 sec
[2020-07-23 21:02:55,066 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.260.bert.pt, number of examples: 1996
[2020-07-23 21:02:58,094 INFO] Step 31350/50000; xent: 1.60; lr: 0.0000113; 102 docs/s;   9874 sec
[2020-07-23 21:03:13,346 INFO] Step 31400/50000; xent: 1.49; lr: 0.0000113; 102 docs/s;   9890 sec
[2020-07-23 21:03:28,619 INFO] Step 31450/50000; xent: 1.50; lr: 0.0000113; 103 docs/s;   9905 sec
[2020-07-23 21:03:33,846 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.938.bert.pt, number of examples: 1997
[2020-07-23 21:03:44,067 INFO] Step 31500/50000; xent: 1.48; lr: 0.0000113; 101 docs/s;   9920 sec
[2020-07-23 21:03:59,405 INFO] Step 31550/50000; xent: 1.43; lr: 0.0000113; 101 docs/s;   9936 sec
[2020-07-23 21:04:13,288 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.162.bert.pt, number of examples: 2001
[2020-07-23 21:04:14,814 INFO] Step 31600/50000; xent: 1.47; lr: 0.0000113; 102 docs/s;   9951 sec
[2020-07-23 21:04:30,125 INFO] Step 31650/50000; xent: 1.44; lr: 0.0000112; 105 docs/s;   9966 sec
[2020-07-23 21:04:45,357 INFO] Step 31700/50000; xent: 1.41; lr: 0.0000112; 105 docs/s;   9982 sec
[2020-07-23 21:04:51,595 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.22.bert.pt, number of examples: 1999
[2020-07-23 21:05:00,786 INFO] Step 31750/50000; xent: 1.46; lr: 0.0000112; 104 docs/s;   9997 sec
[2020-07-23 21:05:16,099 INFO] Step 31800/50000; xent: 1.55; lr: 0.0000112; 102 docs/s;  10012 sec
[2020-07-23 21:05:30,488 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.241.bert.pt, number of examples: 1996
[2020-07-23 21:05:31,409 INFO] Step 31850/50000; xent: 1.50; lr: 0.0000112; 102 docs/s;  10028 sec
[2020-07-23 21:05:46,614 INFO] Step 31900/50000; xent: 1.58; lr: 0.0000112; 100 docs/s;  10043 sec
[2020-07-23 21:06:01,929 INFO] Step 31950/50000; xent: 1.54; lr: 0.0000112; 100 docs/s;  10058 sec
[2020-07-23 21:06:10,299 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.467.bert.pt, number of examples: 1992
[2020-07-23 21:06:17,345 INFO] Step 32000/50000; xent: 1.46; lr: 0.0000112; 103 docs/s;  10074 sec
[2020-07-23 21:06:32,556 INFO] Step 32050/50000; xent: 1.50; lr: 0.0000112; 104 docs/s;  10089 sec
[2020-07-23 21:06:47,858 INFO] Step 32100/50000; xent: 1.40; lr: 0.0000112; 103 docs/s;  10104 sec
[2020-07-23 21:06:48,526 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.434.bert.pt, number of examples: 1993
[2020-07-23 21:07:03,176 INFO] Step 32150/50000; xent: 1.59; lr: 0.0000112; 101 docs/s;  10119 sec
[2020-07-23 21:07:18,374 INFO] Step 32200/50000; xent: 1.62; lr: 0.0000111; 101 docs/s;  10135 sec
[2020-07-23 21:07:27,897 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.807.bert.pt, number of examples: 1997
[2020-07-23 21:07:33,718 INFO] Step 32250/50000; xent: 1.57; lr: 0.0000111; 102 docs/s;  10150 sec
[2020-07-23 21:07:49,004 INFO] Step 32300/50000; xent: 1.57; lr: 0.0000111; 103 docs/s;  10165 sec
[2020-07-23 21:08:04,337 INFO] Step 32350/50000; xent: 1.56; lr: 0.0000111; 104 docs/s;  10181 sec
[2020-07-23 21:08:06,811 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.902.bert.pt, number of examples: 1997
[2020-07-23 21:08:19,781 INFO] Step 32400/50000; xent: 1.60; lr: 0.0000111; 100 docs/s;  10196 sec
[2020-07-23 21:08:35,009 INFO] Step 32450/50000; xent: 1.59; lr: 0.0000111; 102 docs/s;  10211 sec
[2020-07-23 21:08:46,370 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.952.bert.pt, number of examples: 1998
[2020-07-23 21:08:50,301 INFO] Step 32500/50000; xent: 1.56; lr: 0.0000111; 101 docs/s;  10227 sec
[2020-07-23 21:09:05,636 INFO] Step 32550/50000; xent: 1.52; lr: 0.0000111; 104 docs/s;  10242 sec
[2020-07-23 21:09:20,947 INFO] Step 32600/50000; xent: 1.58; lr: 0.0000111; 103 docs/s;  10257 sec
[2020-07-23 21:09:24,998 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.226.bert.pt, number of examples: 1995
[2020-07-23 21:09:36,384 INFO] Step 32650/50000; xent: 1.53; lr: 0.0000111; 101 docs/s;  10273 sec
[2020-07-23 21:09:51,698 INFO] Step 32700/50000; xent: 1.59; lr: 0.0000111; 101 docs/s;  10288 sec
[2020-07-23 21:10:04,228 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.131.bert.pt, number of examples: 1993
[2020-07-23 21:10:06,957 INFO] Step 32750/50000; xent: 1.62; lr: 0.0000111; 101 docs/s;  10303 sec
[2020-07-23 21:10:22,278 INFO] Step 32800/50000; xent: 1.57; lr: 0.0000110; 104 docs/s;  10318 sec
[2020-07-23 21:10:37,543 INFO] Step 32850/50000; xent: 1.46; lr: 0.0000110; 103 docs/s;  10334 sec
[2020-07-23 21:10:43,076 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.135.bert.pt, number of examples: 1996
[2020-07-23 21:10:52,815 INFO] Step 32900/50000; xent: 1.52; lr: 0.0000110; 103 docs/s;  10349 sec
[2020-07-23 21:11:08,132 INFO] Step 32950/50000; xent: 1.47; lr: 0.0000110; 103 docs/s;  10364 sec
[2020-07-23 21:11:21,911 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.863.bert.pt, number of examples: 1964
[2020-07-23 21:11:23,452 INFO] Step 33000/50000; xent: 1.48; lr: 0.0000110; 103 docs/s;  10380 sec
[2020-07-23 21:11:38,723 INFO] Step 33050/50000; xent: 1.58; lr: 0.0000110; 102 docs/s;  10395 sec
[2020-07-23 21:11:53,979 INFO] Step 33100/50000; xent: 1.46; lr: 0.0000110; 101 docs/s;  10410 sec
[2020-07-23 21:12:00,383 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.445.bert.pt, number of examples: 1994
[2020-07-23 21:12:09,298 INFO] Step 33150/50000; xent: 1.59; lr: 0.0000110; 102 docs/s;  10426 sec
[2020-07-23 21:12:24,597 INFO] Step 33200/50000; xent: 1.51; lr: 0.0000110; 100 docs/s;  10441 sec
[2020-07-23 21:12:39,935 INFO] Step 33250/50000; xent: 1.55; lr: 0.0000110;  99 docs/s;  10456 sec
[2020-07-23 21:12:40,298 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.217.bert.pt, number of examples: 1998
[2020-07-23 21:12:55,375 INFO] Step 33300/50000; xent: 1.56; lr: 0.0000110; 104 docs/s;  10472 sec
[2020-07-23 21:13:10,698 INFO] Step 33350/50000; xent: 1.56; lr: 0.0000110; 103 docs/s;  10487 sec
[2020-07-23 21:13:19,243 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.593.bert.pt, number of examples: 1998
[2020-07-23 21:13:26,004 INFO] Step 33400/50000; xent: 1.47; lr: 0.0000109; 102 docs/s;  10502 sec
[2020-07-23 21:13:41,213 INFO] Step 33450/50000; xent: 1.49; lr: 0.0000109; 101 docs/s;  10517 sec
[2020-07-23 21:13:56,527 INFO] Step 33500/50000; xent: 1.46; lr: 0.0000109; 101 docs/s;  10533 sec
[2020-07-23 21:13:58,710 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.971.bert.pt, number of examples: 1998
[2020-07-23 21:14:11,829 INFO] Step 33550/50000; xent: 1.56; lr: 0.0000109; 100 docs/s;  10548 sec
[2020-07-23 21:14:27,121 INFO] Step 33600/50000; xent: 1.46; lr: 0.0000109; 102 docs/s;  10563 sec
[2020-07-23 21:14:38,462 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.888.bert.pt, number of examples: 1981
[2020-07-23 21:14:42,480 INFO] Step 33650/50000; xent: 1.48; lr: 0.0000109; 101 docs/s;  10579 sec
[2020-07-23 21:14:57,919 INFO] Step 33700/50000; xent: 1.51; lr: 0.0000109; 101 docs/s;  10594 sec
[2020-07-23 21:15:13,113 INFO] Step 33750/50000; xent: 1.55; lr: 0.0000109; 101 docs/s;  10609 sec
[2020-07-23 21:15:17,702 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.785.bert.pt, number of examples: 1994
[2020-07-23 21:15:28,417 INFO] Step 33800/50000; xent: 1.43; lr: 0.0000109; 102 docs/s;  10625 sec
[2020-07-23 21:15:43,761 INFO] Step 33850/50000; xent: 1.42; lr: 0.0000109; 103 docs/s;  10640 sec
[2020-07-23 21:15:56,593 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.157.bert.pt, number of examples: 1998
[2020-07-23 21:15:59,026 INFO] Step 33900/50000; xent: 1.46; lr: 0.0000109; 102 docs/s;  10655 sec
[2020-07-23 21:16:14,291 INFO] Step 33950/50000; xent: 1.44; lr: 0.0000109; 104 docs/s;  10671 sec
[2020-07-23 21:16:29,709 INFO] Step 34000/50000; xent: 1.43; lr: 0.0000108; 104 docs/s;  10686 sec
[2020-07-23 21:16:34,990 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.462.bert.pt, number of examples: 1991
[2020-07-23 21:16:45,093 INFO] Step 34050/50000; xent: 1.47; lr: 0.0000108; 104 docs/s;  10701 sec
[2020-07-23 21:17:00,408 INFO] Step 34100/50000; xent: 1.44; lr: 0.0000108; 106 docs/s;  10717 sec
[2020-07-23 21:17:12,893 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.428.bert.pt, number of examples: 1990
[2020-07-23 21:17:15,667 INFO] Step 34150/50000; xent: 1.47; lr: 0.0000108; 104 docs/s;  10732 sec
[2020-07-23 21:17:30,979 INFO] Step 34200/50000; xent: 1.63; lr: 0.0000108;  99 docs/s;  10747 sec
[2020-07-23 21:17:46,306 INFO] Step 34250/50000; xent: 1.58; lr: 0.0000108; 100 docs/s;  10763 sec
[2020-07-23 21:17:53,094 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.80.bert.pt, number of examples: 1997
[2020-07-23 21:18:01,693 INFO] Step 34300/50000; xent: 1.56; lr: 0.0000108; 100 docs/s;  10778 sec
[2020-07-23 21:18:16,997 INFO] Step 34350/50000; xent: 1.49; lr: 0.0000108; 101 docs/s;  10793 sec
[2020-07-23 21:18:32,228 INFO] Step 34400/50000; xent: 1.47; lr: 0.0000108; 102 docs/s;  10808 sec
[2020-07-23 21:18:32,279 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.953.bert.pt, number of examples: 2000
[2020-07-23 21:18:47,517 INFO] Step 34450/50000; xent: 1.35; lr: 0.0000108; 104 docs/s;  10824 sec
[2020-07-23 21:19:02,735 INFO] Step 34500/50000; xent: 1.39; lr: 0.0000108; 103 docs/s;  10839 sec
[2020-07-23 21:19:10,963 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.950.bert.pt, number of examples: 1994
[2020-07-23 21:19:17,939 INFO] Step 34550/50000; xent: 1.33; lr: 0.0000108; 103 docs/s;  10854 sec
[2020-07-23 21:19:33,292 INFO] Step 34600/50000; xent: 1.47; lr: 0.0000108; 103 docs/s;  10870 sec
[2020-07-23 21:19:48,597 INFO] Step 34650/50000; xent: 1.46; lr: 0.0000107; 102 docs/s;  10885 sec
[2020-07-23 21:19:49,873 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.657.bert.pt, number of examples: 1997
[2020-07-23 21:20:04,001 INFO] Step 34700/50000; xent: 1.66; lr: 0.0000107;  99 docs/s;  10900 sec
[2020-07-23 21:20:19,319 INFO] Step 34750/50000; xent: 1.68; lr: 0.0000107;  99 docs/s;  10916 sec
[2020-07-23 21:20:30,375 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.253.bert.pt, number of examples: 1999
[2020-07-23 21:20:34,638 INFO] Step 34800/50000; xent: 1.55; lr: 0.0000107; 100 docs/s;  10931 sec
[2020-07-23 21:20:49,911 INFO] Step 34850/50000; xent: 1.50; lr: 0.0000107; 101 docs/s;  10946 sec
[2020-07-23 21:21:05,262 INFO] Step 34900/50000; xent: 1.43; lr: 0.0000107; 103 docs/s;  10961 sec
[2020-07-23 21:21:09,608 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.949.bert.pt, number of examples: 1998
[2020-07-23 21:21:20,552 INFO] Step 34950/50000; xent: 1.50; lr: 0.0000107; 103 docs/s;  10977 sec
[2020-07-23 21:21:35,829 INFO] Step 35000/50000; xent: 1.47; lr: 0.0000107; 104 docs/s;  10992 sec
[2020-07-23 21:21:35,831 INFO] Saving checkpoint ./models/models_check_points/model_step_35000.pt
[2020-07-23 21:21:48,820 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.396.bert.pt, number of examples: 1998
[2020-07-23 21:21:51,895 INFO] Step 35050/50000; xent: 1.47; lr: 0.0000107;  98 docs/s;  11008 sec
[2020-07-23 21:22:07,141 INFO] Step 35100/50000; xent: 1.48; lr: 0.0000107; 104 docs/s;  11023 sec
[2020-07-23 21:22:22,363 INFO] Step 35150/50000; xent: 1.46; lr: 0.0000107; 105 docs/s;  11039 sec
[2020-07-23 21:22:27,056 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.894.bert.pt, number of examples: 1999
[2020-07-23 21:22:37,902 INFO] Step 35200/50000; xent: 1.47; lr: 0.0000107; 104 docs/s;  11054 sec
[2020-07-23 21:22:53,169 INFO] Step 35250/50000; xent: 1.55; lr: 0.0000107; 105 docs/s;  11069 sec
[2020-07-23 21:23:05,628 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.944.bert.pt, number of examples: 1997
[2020-07-23 21:23:08,338 INFO] Step 35300/50000; xent: 1.48; lr: 0.0000106; 103 docs/s;  11085 sec
[2020-07-23 21:23:23,672 INFO] Step 35350/50000; xent: 1.57; lr: 0.0000106; 101 docs/s;  11100 sec
[2020-07-23 21:23:39,001 INFO] Step 35400/50000; xent: 1.53; lr: 0.0000106; 102 docs/s;  11115 sec
[2020-07-23 21:23:44,848 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.855.bert.pt, number of examples: 1991
[2020-07-23 21:23:54,319 INFO] Step 35450/50000; xent: 1.63; lr: 0.0000106; 102 docs/s;  11131 sec
[2020-07-23 21:24:09,599 INFO] Step 35500/50000; xent: 1.60; lr: 0.0000106; 103 docs/s;  11146 sec
[2020-07-23 21:24:23,679 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.526.bert.pt, number of examples: 1998
[2020-07-23 21:24:24,915 INFO] Step 35550/50000; xent: 1.67; lr: 0.0000106; 102 docs/s;  11161 sec
[2020-07-23 21:24:40,117 INFO] Step 35600/50000; xent: 1.49; lr: 0.0000106; 103 docs/s;  11176 sec
[2020-07-23 21:24:55,429 INFO] Step 35650/50000; xent: 1.43; lr: 0.0000106; 102 docs/s;  11192 sec
[2020-07-23 21:25:03,052 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.892.bert.pt, number of examples: 1997
[2020-07-23 21:25:10,706 INFO] Step 35700/50000; xent: 1.49; lr: 0.0000106; 103 docs/s;  11207 sec
[2020-07-23 21:25:25,976 INFO] Step 35750/50000; xent: 1.46; lr: 0.0000106; 106 docs/s;  11222 sec
[2020-07-23 21:25:40,894 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.76.bert.pt, number of examples: 2000
[2020-07-23 21:25:41,202 INFO] Step 35800/50000; xent: 1.50; lr: 0.0000106; 104 docs/s;  11237 sec
[2020-07-23 21:25:56,473 INFO] Step 35850/50000; xent: 1.56; lr: 0.0000106; 103 docs/s;  11253 sec
[2020-07-23 21:26:11,685 INFO] Step 35900/50000; xent: 1.56; lr: 0.0000106; 102 docs/s;  11268 sec
[2020-07-23 21:26:20,048 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.610.bert.pt, number of examples: 1994
[2020-07-23 21:26:27,115 INFO] Step 35950/50000; xent: 1.51; lr: 0.0000105; 102 docs/s;  11283 sec
[2020-07-23 21:26:42,367 INFO] Step 36000/50000; xent: 1.42; lr: 0.0000105; 105 docs/s;  11299 sec
[2020-07-23 21:26:57,626 INFO] Step 36050/50000; xent: 1.38; lr: 0.0000105; 103 docs/s;  11314 sec
[2020-07-23 21:26:58,608 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.668.bert.pt, number of examples: 1991
[2020-07-23 21:27:13,025 INFO] Step 36100/50000; xent: 1.54; lr: 0.0000105;  98 docs/s;  11329 sec
[2020-07-23 21:27:28,224 INFO] Step 36150/50000; xent: 1.56; lr: 0.0000105;  98 docs/s;  11344 sec
[2020-07-23 21:27:39,013 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.315.bert.pt, number of examples: 2001
[2020-07-23 21:27:43,568 INFO] Step 36200/50000; xent: 1.66; lr: 0.0000105;  99 docs/s;  11360 sec
[2020-07-23 21:27:58,851 INFO] Step 36250/50000; xent: 1.50; lr: 0.0000105; 103 docs/s;  11375 sec
[2020-07-23 21:28:14,142 INFO] Step 36300/50000; xent: 1.49; lr: 0.0000105; 104 docs/s;  11390 sec
[2020-07-23 21:28:17,890 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.612.bert.pt, number of examples: 1988
[2020-07-23 21:28:29,467 INFO] Step 36350/50000; xent: 1.64; lr: 0.0000105; 101 docs/s;  11406 sec
[2020-07-23 21:28:44,687 INFO] Step 36400/50000; xent: 1.64; lr: 0.0000105; 101 docs/s;  11421 sec
[2020-07-23 21:28:57,566 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.95.bert.pt, number of examples: 1998
[2020-07-23 21:29:00,038 INFO] Step 36450/50000; xent: 1.65; lr: 0.0000105; 100 docs/s;  11436 sec
[2020-07-23 21:29:15,290 INFO] Step 36500/50000; xent: 1.47; lr: 0.0000105; 101 docs/s;  11452 sec
[2020-07-23 21:29:30,531 INFO] Step 36550/50000; xent: 1.49; lr: 0.0000105; 101 docs/s;  11467 sec
[2020-07-23 21:29:37,026 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.53.bert.pt, number of examples: 2000
[2020-07-23 21:29:45,870 INFO] Step 36600/50000; xent: 1.54; lr: 0.0000105; 101 docs/s;  11482 sec
[2020-07-23 21:30:01,177 INFO] Step 36650/50000; xent: 1.48; lr: 0.0000104; 103 docs/s;  11497 sec
[2020-07-23 21:30:16,113 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.45.bert.pt, number of examples: 1987
[2020-07-23 21:30:16,405 INFO] Step 36700/50000; xent: 1.53; lr: 0.0000104; 102 docs/s;  11513 sec
[2020-07-23 21:30:31,763 INFO] Step 36750/50000; xent: 1.60; lr: 0.0000104; 101 docs/s;  11528 sec
[2020-07-23 21:30:47,082 INFO] Step 36800/50000; xent: 1.62; lr: 0.0000104; 101 docs/s;  11543 sec
[2020-07-23 21:30:55,639 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.369.bert.pt, number of examples: 2000
[2020-07-23 21:31:02,352 INFO] Step 36850/50000; xent: 1.63; lr: 0.0000104; 100 docs/s;  11559 sec
[2020-07-23 21:31:17,769 INFO] Step 36900/50000; xent: 1.55; lr: 0.0000104; 104 docs/s;  11574 sec
[2020-07-23 21:31:33,025 INFO] Step 36950/50000; xent: 1.52; lr: 0.0000104; 104 docs/s;  11589 sec
[2020-07-23 21:31:34,277 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.535.bert.pt, number of examples: 2000
[2020-07-23 21:31:48,366 INFO] Step 37000/50000; xent: 1.44; lr: 0.0000104; 104 docs/s;  11605 sec
[2020-07-23 21:32:03,655 INFO] Step 37050/50000; xent: 1.40; lr: 0.0000104; 103 docs/s;  11620 sec
[2020-07-23 21:32:12,845 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.88.bert.pt, number of examples: 1999
[2020-07-23 21:32:18,985 INFO] Step 37100/50000; xent: 1.43; lr: 0.0000104; 103 docs/s;  11635 sec
[2020-07-23 21:32:34,286 INFO] Step 37150/50000; xent: 1.52; lr: 0.0000104; 101 docs/s;  11651 sec
[2020-07-23 21:32:49,525 INFO] Step 37200/50000; xent: 1.48; lr: 0.0000104; 101 docs/s;  11666 sec
[2020-07-23 21:32:52,340 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.104.bert.pt, number of examples: 1996
[2020-07-23 21:33:05,003 INFO] Step 37250/50000; xent: 1.50; lr: 0.0000104; 103 docs/s;  11681 sec
[2020-07-23 21:33:20,318 INFO] Step 37300/50000; xent: 1.54; lr: 0.0000104; 104 docs/s;  11697 sec
[2020-07-23 21:33:31,026 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.606.bert.pt, number of examples: 1997
[2020-07-23 21:33:35,601 INFO] Step 37350/50000; xent: 1.44; lr: 0.0000103; 101 docs/s;  11712 sec
[2020-07-23 21:33:50,947 INFO] Step 37400/50000; xent: 1.52; lr: 0.0000103; 100 docs/s;  11727 sec
[2020-07-23 21:34:06,231 INFO] Step 37450/50000; xent: 1.39; lr: 0.0000103; 102 docs/s;  11742 sec
[2020-07-23 21:34:10,801 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.562.bert.pt, number of examples: 1999
[2020-07-23 21:34:21,497 INFO] Step 37500/50000; xent: 1.53; lr: 0.0000103; 101 docs/s;  11758 sec
[2020-07-23 21:34:36,764 INFO] Step 37550/50000; xent: 1.43; lr: 0.0000103; 103 docs/s;  11773 sec
[2020-07-23 21:34:49,667 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.850.bert.pt, number of examples: 1999
[2020-07-23 21:34:52,142 INFO] Step 37600/50000; xent: 1.44; lr: 0.0000103; 104 docs/s;  11788 sec
[2020-07-23 21:35:07,348 INFO] Step 37650/50000; xent: 1.53; lr: 0.0000103; 102 docs/s;  11804 sec
[2020-07-23 21:35:22,560 INFO] Step 37700/50000; xent: 1.42; lr: 0.0000103; 102 docs/s;  11819 sec
[2020-07-23 21:35:28,730 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.876.bert.pt, number of examples: 1999
[2020-07-23 21:35:37,860 INFO] Step 37750/50000; xent: 1.54; lr: 0.0000103; 101 docs/s;  11834 sec
[2020-07-23 21:35:53,145 INFO] Step 37800/50000; xent: 1.61; lr: 0.0000103; 102 docs/s;  11849 sec
[2020-07-23 21:36:08,114 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.543.bert.pt, number of examples: 1997
[2020-07-23 21:36:08,423 INFO] Step 37850/50000; xent: 1.59; lr: 0.0000103; 102 docs/s;  11865 sec
[2020-07-23 21:36:23,681 INFO] Step 37900/50000; xent: 1.56; lr: 0.0000103;  98 docs/s;  11880 sec
[2020-07-23 21:36:38,934 INFO] Step 37950/50000; xent: 1.47; lr: 0.0000103; 100 docs/s;  11895 sec
[2020-07-23 21:36:48,548 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.147.bert.pt, number of examples: 1994
[2020-07-23 21:36:54,321 INFO] Step 38000/50000; xent: 1.50; lr: 0.0000103; 100 docs/s;  11911 sec
[2020-07-23 21:37:09,646 INFO] Step 38050/50000; xent: 1.40; lr: 0.0000103; 104 docs/s;  11926 sec
[2020-07-23 21:37:25,068 INFO] Step 38100/50000; xent: 1.47; lr: 0.0000102; 105 docs/s;  11941 sec
[2020-07-23 21:37:26,661 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.620.bert.pt, number of examples: 1999
[2020-07-23 21:37:40,504 INFO] Step 38150/50000; xent: 1.48; lr: 0.0000102; 101 docs/s;  11957 sec
[2020-07-23 21:37:55,804 INFO] Step 38200/50000; xent: 1.48; lr: 0.0000102; 101 docs/s;  11972 sec
[2020-07-23 21:38:06,549 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.934.bert.pt, number of examples: 1998
[2020-07-23 21:38:11,091 INFO] Step 38250/50000; xent: 1.48; lr: 0.0000102; 100 docs/s;  11987 sec
[2020-07-23 21:38:26,465 INFO] Step 38300/50000; xent: 1.54; lr: 0.0000102; 100 docs/s;  12003 sec
[2020-07-23 21:38:41,808 INFO] Step 38350/50000; xent: 1.46; lr: 0.0000102; 100 docs/s;  12018 sec
[2020-07-23 21:38:46,461 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.175.bert.pt, number of examples: 1996
[2020-07-23 21:38:57,181 INFO] Step 38400/50000; xent: 1.52; lr: 0.0000102; 101 docs/s;  12033 sec
[2020-07-23 21:39:12,519 INFO] Step 38450/50000; xent: 1.51; lr: 0.0000102; 102 docs/s;  12049 sec
[2020-07-23 21:39:25,972 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.341.bert.pt, number of examples: 1995
[2020-07-23 21:39:27,785 INFO] Step 38500/50000; xent: 1.48; lr: 0.0000102; 101 docs/s;  12064 sec
[2020-07-23 21:39:42,983 INFO] Step 38550/50000; xent: 1.48; lr: 0.0000102; 102 docs/s;  12079 sec
[2020-07-23 21:39:58,281 INFO] Step 38600/50000; xent: 1.47; lr: 0.0000102; 101 docs/s;  12095 sec
[2020-07-23 21:40:05,341 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.808.bert.pt, number of examples: 1992
[2020-07-23 21:40:13,603 INFO] Step 38650/50000; xent: 1.52; lr: 0.0000102; 101 docs/s;  12110 sec
[2020-07-23 21:40:28,889 INFO] Step 38700/50000; xent: 1.49; lr: 0.0000102; 103 docs/s;  12125 sec
[2020-07-23 21:40:44,153 INFO] Step 38750/50000; xent: 1.52; lr: 0.0000102; 103 docs/s;  12140 sec
[2020-07-23 21:40:44,206 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.799.bert.pt, number of examples: 1997
[2020-07-23 21:40:59,536 INFO] Step 38800/50000; xent: 1.48; lr: 0.0000102; 103 docs/s;  12156 sec
[2020-07-23 21:41:14,818 INFO] Step 38850/50000; xent: 1.56; lr: 0.0000101; 104 docs/s;  12171 sec
[2020-07-23 21:41:23,054 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.184.bert.pt, number of examples: 1990
[2020-07-23 21:41:30,135 INFO] Step 38900/50000; xent: 1.56; lr: 0.0000101; 102 docs/s;  12186 sec
[2020-07-23 21:41:45,445 INFO] Step 38950/50000; xent: 1.57; lr: 0.0000101; 101 docs/s;  12202 sec
[2020-07-23 21:42:00,712 INFO] Step 39000/50000; xent: 1.55; lr: 0.0000101; 101 docs/s;  12217 sec
[2020-07-23 21:42:02,299 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.38.bert.pt, number of examples: 1999
[2020-07-23 21:42:15,993 INFO] Step 39050/50000; xent: 1.61; lr: 0.0000101; 103 docs/s;  12232 sec
[2020-07-23 21:42:31,198 INFO] Step 39100/50000; xent: 1.60; lr: 0.0000101; 103 docs/s;  12247 sec
[2020-07-23 21:42:41,309 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.426.bert.pt, number of examples: 1991
[2020-07-23 21:42:46,473 INFO] Step 39150/50000; xent: 1.51; lr: 0.0000101; 100 docs/s;  12263 sec
[2020-07-23 21:43:01,777 INFO] Step 39200/50000; xent: 1.53; lr: 0.0000101; 100 docs/s;  12278 sec
[2020-07-23 21:43:17,050 INFO] Step 39250/50000; xent: 1.47; lr: 0.0000101; 100 docs/s;  12293 sec
[2020-07-23 21:43:21,083 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.205.bert.pt, number of examples: 1998
[2020-07-23 21:43:32,475 INFO] Step 39300/50000; xent: 1.62; lr: 0.0000101; 100 docs/s;  12309 sec
[2020-07-23 21:43:47,788 INFO] Step 39350/50000; xent: 1.63; lr: 0.0000101; 102 docs/s;  12324 sec
[2020-07-23 21:44:00,638 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.947.bert.pt, number of examples: 1994
[2020-07-23 21:44:03,081 INFO] Step 39400/50000; xent: 1.63; lr: 0.0000101; 101 docs/s;  12339 sec
[2020-07-23 21:44:18,483 INFO] Step 39450/50000; xent: 1.54; lr: 0.0000101; 104 docs/s;  12355 sec
[2020-07-23 21:44:33,835 INFO] Step 39500/50000; xent: 1.61; lr: 0.0000101; 104 docs/s;  12370 sec
[2020-07-23 21:44:39,049 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.401.bert.pt, number of examples: 1992
[2020-07-23 21:44:49,197 INFO] Step 39550/50000; xent: 1.54; lr: 0.0000101; 104 docs/s;  12385 sec
[2020-07-23 21:45:04,323 INFO] Step 39600/50000; xent: 1.57; lr: 0.0000101; 103 docs/s;  12401 sec
[2020-07-23 21:45:17,555 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.978.bert.pt, number of examples: 1997
[2020-07-23 21:45:19,722 INFO] Step 39650/50000; xent: 1.54; lr: 0.0000100; 104 docs/s;  12416 sec
[2020-07-23 21:45:35,195 INFO] Step 39700/50000; xent: 1.46; lr: 0.0000100; 104 docs/s;  12431 sec
[2020-07-23 21:45:50,540 INFO] Step 39750/50000; xent: 1.44; lr: 0.0000100; 103 docs/s;  12447 sec
[2020-07-23 21:45:56,074 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.680.bert.pt, number of examples: 1998
[2020-07-23 21:46:05,897 INFO] Step 39800/50000; xent: 1.50; lr: 0.0000100; 102 docs/s;  12462 sec
[2020-07-23 21:46:21,222 INFO] Step 39850/50000; xent: 1.46; lr: 0.0000100; 100 docs/s;  12477 sec
[2020-07-23 21:46:35,912 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.960.bert.pt, number of examples: 2000
[2020-07-23 21:46:36,522 INFO] Step 39900/50000; xent: 1.50; lr: 0.0000100; 100 docs/s;  12493 sec
[2020-07-23 21:46:51,822 INFO] Step 39950/50000; xent: 1.40; lr: 0.0000100; 104 docs/s;  12508 sec
[2020-07-23 21:47:07,022 INFO] Step 40000/50000; xent: 1.36; lr: 0.0000100; 104 docs/s;  12523 sec
[2020-07-23 21:47:07,023 INFO] Saving checkpoint ./models/models_check_points/model_step_40000.pt
[2020-07-23 21:47:15,134 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.337.bert.pt, number of examples: 1997
[2020-07-23 21:47:23,046 INFO] Step 40050/50000; xent: 1.43; lr: 0.0000100;  98 docs/s;  12539 sec
[2020-07-23 21:47:38,337 INFO] Step 40100/50000; xent: 1.56; lr: 0.0000100; 101 docs/s;  12555 sec
[2020-07-23 21:47:53,654 INFO] Step 40150/50000; xent: 1.48; lr: 0.0000100; 102 docs/s;  12570 sec
[2020-07-23 21:47:54,614 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.705.bert.pt, number of examples: 1996
[2020-07-23 21:48:09,074 INFO] Step 40200/50000; xent: 1.54; lr: 0.0000100; 104 docs/s;  12585 sec
[2020-07-23 21:48:24,234 INFO] Step 40250/50000; xent: 1.58; lr: 0.0000100; 102 docs/s;  12600 sec
[2020-07-23 21:48:33,405 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.634.bert.pt, number of examples: 1997
[2020-07-23 21:48:39,513 INFO] Step 40300/50000; xent: 1.51; lr: 0.0000100; 102 docs/s;  12616 sec
[2020-07-23 21:48:54,902 INFO] Step 40350/50000; xent: 1.59; lr: 0.0000100; 103 docs/s;  12631 sec
[2020-07-23 21:49:10,148 INFO] Step 40400/50000; xent: 1.59; lr: 0.0000100; 103 docs/s;  12646 sec
[2020-07-23 21:49:12,358 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.752.bert.pt, number of examples: 2000
[2020-07-23 21:49:25,509 INFO] Step 40450/50000; xent: 1.62; lr: 0.0000099; 104 docs/s;  12662 sec
[2020-07-23 21:49:40,851 INFO] Step 40500/50000; xent: 1.59; lr: 0.0000099; 104 docs/s;  12677 sec
[2020-07-23 21:49:50,914 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.910.bert.pt, number of examples: 1990
[2020-07-23 21:49:56,113 INFO] Step 40550/50000; xent: 1.64; lr: 0.0000099; 102 docs/s;  12692 sec
[2020-07-23 21:50:11,426 INFO] Step 40600/50000; xent: 1.71; lr: 0.0000099;  99 docs/s;  12708 sec
[2020-07-23 21:50:26,680 INFO] Step 40650/50000; xent: 1.67; lr: 0.0000099; 100 docs/s;  12723 sec
[2020-07-23 21:50:30,700 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.322.bert.pt, number of examples: 1997
[2020-07-23 21:50:42,003 INFO] Step 40700/50000; xent: 1.57; lr: 0.0000099; 101 docs/s;  12738 sec
[2020-07-23 21:50:57,374 INFO] Step 40750/50000; xent: 1.50; lr: 0.0000099; 103 docs/s;  12754 sec
[2020-07-23 21:51:09,878 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.941.bert.pt, number of examples: 1998
[2020-07-23 21:51:12,546 INFO] Step 40800/50000; xent: 1.50; lr: 0.0000099; 101 docs/s;  12769 sec
[2020-07-23 21:51:27,911 INFO] Step 40850/50000; xent: 1.52; lr: 0.0000099; 102 docs/s;  12784 sec
[2020-07-23 21:51:43,157 INFO] Step 40900/50000; xent: 1.46; lr: 0.0000099; 101 docs/s;  12799 sec
[2020-07-23 21:51:49,103 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.772.bert.pt, number of examples: 1997
[2020-07-23 21:51:58,540 INFO] Step 40950/50000; xent: 1.61; lr: 0.0000099; 102 docs/s;  12815 sec
[2020-07-23 21:52:13,766 INFO] Step 41000/50000; xent: 1.68; lr: 0.0000099; 102 docs/s;  12830 sec
[2020-07-23 21:52:28,215 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.987.bert.pt, number of examples: 2001
[2020-07-23 21:52:29,121 INFO] Step 41050/50000; xent: 1.65; lr: 0.0000099; 103 docs/s;  12845 sec
[2020-07-23 21:52:44,479 INFO] Step 41100/50000; xent: 1.46; lr: 0.0000099; 103 docs/s;  12861 sec
[2020-07-23 21:52:59,724 INFO] Step 41150/50000; xent: 1.48; lr: 0.0000099; 103 docs/s;  12876 sec
[2020-07-23 21:53:07,168 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.242.bert.pt, number of examples: 1993
[2020-07-23 21:53:15,144 INFO] Step 41200/50000; xent: 1.50; lr: 0.0000099; 102 docs/s;  12891 sec
[2020-07-23 21:53:30,414 INFO] Step 41250/50000; xent: 1.58; lr: 0.0000098; 101 docs/s;  12907 sec
[2020-07-23 21:53:45,605 INFO] Step 41300/50000; xent: 1.52; lr: 0.0000098;  99 docs/s;  12922 sec
[2020-07-23 21:53:46,871 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.945.bert.pt, number of examples: 1994
[2020-07-23 21:54:00,990 INFO] Step 41350/50000; xent: 1.65; lr: 0.0000098; 101 docs/s;  12937 sec
[2020-07-23 21:54:16,345 INFO] Step 41400/50000; xent: 1.53; lr: 0.0000098; 102 docs/s;  12953 sec
[2020-07-23 21:54:26,138 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.635.bert.pt, number of examples: 1998
[2020-07-23 21:54:31,628 INFO] Step 41450/50000; xent: 1.54; lr: 0.0000098; 102 docs/s;  12968 sec
[2020-07-23 21:54:46,938 INFO] Step 41500/50000; xent: 1.62; lr: 0.0000098; 102 docs/s;  12983 sec
[2020-07-23 21:55:02,252 INFO] Step 41550/50000; xent: 1.62; lr: 0.0000098; 103 docs/s;  12998 sec
[2020-07-23 21:55:05,269 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.82.bert.pt, number of examples: 1998
[2020-07-23 21:55:17,568 INFO] Step 41600/50000; xent: 1.48; lr: 0.0000098; 103 docs/s;  13014 sec
[2020-07-23 21:55:32,888 INFO] Step 41650/50000; xent: 1.49; lr: 0.0000098; 103 docs/s;  13029 sec
[2020-07-23 21:55:43,962 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.279.bert.pt, number of examples: 1995
[2020-07-23 21:55:48,250 INFO] Step 41700/50000; xent: 1.42; lr: 0.0000098; 102 docs/s;  13044 sec
[2020-07-23 21:56:03,462 INFO] Step 41750/50000; xent: 1.58; lr: 0.0000098; 102 docs/s;  13060 sec
[2020-07-23 21:56:18,789 INFO] Step 41800/50000; xent: 1.52; lr: 0.0000098; 103 docs/s;  13075 sec
[2020-07-23 21:56:23,089 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.284.bert.pt, number of examples: 2000
[2020-07-23 21:56:34,148 INFO] Step 41850/50000; xent: 1.57; lr: 0.0000098;  99 docs/s;  13090 sec
[2020-07-23 21:56:49,522 INFO] Step 41900/50000; xent: 1.58; lr: 0.0000098;  99 docs/s;  13106 sec
[2020-07-23 21:57:03,357 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.818.bert.pt, number of examples: 1984
[2020-07-23 21:57:04,886 INFO] Step 41950/50000; xent: 1.58; lr: 0.0000098; 100 docs/s;  13121 sec
[2020-07-23 21:57:20,314 INFO] Step 42000/50000; xent: 1.42; lr: 0.0000098; 103 docs/s;  13137 sec
[2020-07-23 21:57:35,560 INFO] Step 42050/50000; xent: 1.42; lr: 0.0000098; 101 docs/s;  13152 sec
[2020-07-23 21:57:42,338 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.214.bert.pt, number of examples: 1998
[2020-07-23 21:57:50,882 INFO] Step 42100/50000; xent: 1.57; lr: 0.0000097; 101 docs/s;  13167 sec
[2020-07-23 21:58:06,184 INFO] Step 42150/50000; xent: 1.62; lr: 0.0000097; 100 docs/s;  13182 sec
[2020-07-23 21:58:21,455 INFO] Step 42200/50000; xent: 1.64; lr: 0.0000097; 100 docs/s;  13198 sec
[2020-07-23 21:58:22,434 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.415.bert.pt, number of examples: 1990
[2020-07-23 21:58:36,757 INFO] Step 42250/50000; xent: 1.59; lr: 0.0000097; 100 docs/s;  13213 sec
[2020-07-23 21:58:51,982 INFO] Step 42300/50000; xent: 1.61; lr: 0.0000097; 100 docs/s;  13228 sec
[2020-07-23 21:59:02,067 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.195.bert.pt, number of examples: 1996
[2020-07-23 21:59:07,295 INFO] Step 42350/50000; xent: 1.58; lr: 0.0000097; 101 docs/s;  13244 sec
[2020-07-23 21:59:22,502 INFO] Step 42400/50000; xent: 1.53; lr: 0.0000097; 100 docs/s;  13259 sec
[2020-07-23 21:59:37,776 INFO] Step 42450/50000; xent: 1.56; lr: 0.0000097; 100 docs/s;  13274 sec
[2020-07-23 21:59:41,808 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.887.bert.pt, number of examples: 1996
[2020-07-23 21:59:53,211 INFO] Step 42500/50000; xent: 1.32; lr: 0.0000097; 104 docs/s;  13289 sec
[2020-07-23 22:00:08,469 INFO] Step 42550/50000; xent: 1.45; lr: 0.0000097; 104 docs/s;  13305 sec
[2020-07-23 22:00:20,069 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.900.bert.pt, number of examples: 1993
[2020-07-23 22:00:23,695 INFO] Step 42600/50000; xent: 1.41; lr: 0.0000097; 104 docs/s;  13320 sec
[2020-07-23 22:00:39,018 INFO] Step 42650/50000; xent: 1.45; lr: 0.0000097; 103 docs/s;  13335 sec
[2020-07-23 22:00:54,383 INFO] Step 42700/50000; xent: 1.46; lr: 0.0000097; 105 docs/s;  13351 sec
[2020-07-23 22:00:58,418 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.513.bert.pt, number of examples: 1981
[2020-07-23 22:01:09,709 INFO] Step 42750/50000; xent: 1.37; lr: 0.0000097; 102 docs/s;  13366 sec
[2020-07-23 22:01:24,946 INFO] Step 42800/50000; xent: 1.34; lr: 0.0000097; 102 docs/s;  13381 sec
[2020-07-23 22:01:37,487 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.266.bert.pt, number of examples: 1992
[2020-07-23 22:01:40,241 INFO] Step 42850/50000; xent: 1.35; lr: 0.0000097; 102 docs/s;  13396 sec
[2020-07-23 22:01:55,509 INFO] Step 42900/50000; xent: 1.52; lr: 0.0000097; 104 docs/s;  13412 sec
[2020-07-23 22:02:10,880 INFO] Step 42950/50000; xent: 1.48; lr: 0.0000097; 104 docs/s;  13427 sec
[2020-07-23 22:02:15,777 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.847.bert.pt, number of examples: 1992
[2020-07-23 22:02:26,180 INFO] Step 43000/50000; xent: 1.66; lr: 0.0000096; 102 docs/s;  13442 sec
[2020-07-23 22:02:41,364 INFO] Step 43050/50000; xent: 1.69; lr: 0.0000096; 102 docs/s;  13458 sec
[2020-07-23 22:02:54,919 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.545.bert.pt, number of examples: 1993
[2020-07-23 22:02:56,762 INFO] Step 43100/50000; xent: 1.69; lr: 0.0000096; 101 docs/s;  13473 sec
[2020-07-23 22:03:12,120 INFO] Step 43150/50000; xent: 1.52; lr: 0.0000096; 102 docs/s;  13488 sec
[2020-07-23 22:03:27,383 INFO] Step 43200/50000; xent: 1.61; lr: 0.0000096; 102 docs/s;  13504 sec
[2020-07-23 22:03:34,160 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.833.bert.pt, number of examples: 1995
[2020-07-23 22:03:42,749 INFO] Step 43250/50000; xent: 1.66; lr: 0.0000096; 102 docs/s;  13519 sec
[2020-07-23 22:03:58,059 INFO] Step 43300/50000; xent: 1.60; lr: 0.0000096; 102 docs/s;  13534 sec
[2020-07-23 22:04:13,216 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.636.bert.pt, number of examples: 1998
[2020-07-23 22:04:13,524 INFO] Step 43350/50000; xent: 1.56; lr: 0.0000096; 103 docs/s;  13550 sec
[2020-07-23 22:04:28,782 INFO] Step 43400/50000; xent: 1.67; lr: 0.0000096; 101 docs/s;  13565 sec
[2020-07-23 22:04:44,079 INFO] Step 43450/50000; xent: 1.53; lr: 0.0000096; 102 docs/s;  13580 sec
[2020-07-23 22:04:52,639 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.623.bert.pt, number of examples: 2001
[2020-07-23 22:04:59,349 INFO] Step 43500/50000; xent: 1.56; lr: 0.0000096; 101 docs/s;  13596 sec
[2020-07-23 22:05:14,631 INFO] Step 43550/50000; xent: 1.61; lr: 0.0000096; 100 docs/s;  13611 sec
[2020-07-23 22:05:29,892 INFO] Step 43600/50000; xent: 1.57; lr: 0.0000096;  99 docs/s;  13626 sec
[2020-07-23 22:05:32,697 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.74.bert.pt, number of examples: 1998
[2020-07-23 22:05:45,355 INFO] Step 43650/50000; xent: 1.48; lr: 0.0000096; 103 docs/s;  13642 sec
[2020-07-23 22:06:00,771 INFO] Step 43700/50000; xent: 1.57; lr: 0.0000096; 103 docs/s;  13657 sec
[2020-07-23 22:06:11,498 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.628.bert.pt, number of examples: 1996
[2020-07-23 22:06:16,091 INFO] Step 43750/50000; xent: 1.56; lr: 0.0000096; 102 docs/s;  13672 sec
[2020-07-23 22:06:31,296 INFO] Step 43800/50000; xent: 1.70; lr: 0.0000096; 102 docs/s;  13688 sec
[2020-07-23 22:06:46,693 INFO] Step 43850/50000; xent: 1.69; lr: 0.0000096; 103 docs/s;  13703 sec
[2020-07-23 22:06:50,411 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.845.bert.pt, number of examples: 1978
[2020-07-23 22:07:02,030 INFO] Step 43900/50000; xent: 1.63; lr: 0.0000095; 103 docs/s;  13718 sec
[2020-07-23 22:07:17,287 INFO] Step 43950/50000; xent: 1.66; lr: 0.0000095; 103 docs/s;  13734 sec
[2020-07-23 22:07:28,857 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.839.bert.pt, number of examples: 1978
[2020-07-23 22:07:32,537 INFO] Step 44000/50000; xent: 1.57; lr: 0.0000095; 103 docs/s;  13749 sec
[2020-07-23 22:07:47,892 INFO] Step 44050/50000; xent: 1.50; lr: 0.0000095; 106 docs/s;  13764 sec
[2020-07-23 22:08:03,213 INFO] Step 44100/50000; xent: 1.48; lr: 0.0000095; 106 docs/s;  13779 sec
[2020-07-23 22:08:06,263 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.69.bert.pt, number of examples: 1994
[2020-07-23 22:08:18,560 INFO] Step 44150/50000; xent: 1.59; lr: 0.0000095; 102 docs/s;  13795 sec
[2020-07-23 22:08:33,873 INFO] Step 44200/50000; xent: 1.48; lr: 0.0000095; 102 docs/s;  13810 sec
[2020-07-23 22:08:45,262 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.102.bert.pt, number of examples: 1997
[2020-07-23 22:08:49,265 INFO] Step 44250/50000; xent: 1.45; lr: 0.0000095; 102 docs/s;  13825 sec
[2020-07-23 22:09:04,544 INFO] Step 44300/50000; xent: 1.46; lr: 0.0000095; 103 docs/s;  13841 sec
[2020-07-23 22:09:19,752 INFO] Step 44350/50000; xent: 1.48; lr: 0.0000095; 103 docs/s;  13856 sec
[2020-07-23 22:09:24,129 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.100.bert.pt, number of examples: 1995
[2020-07-23 22:09:35,182 INFO] Step 44400/50000; xent: 1.46; lr: 0.0000095; 104 docs/s;  13871 sec
[2020-07-23 22:09:50,675 INFO] Step 44450/50000; xent: 1.42; lr: 0.0000095; 104 docs/s;  13887 sec
[2020-07-23 22:10:02,735 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.781.bert.pt, number of examples: 1997
[2020-07-23 22:10:06,035 INFO] Step 44500/50000; xent: 1.44; lr: 0.0000095; 101 docs/s;  13902 sec
[2020-07-23 22:10:21,382 INFO] Step 44550/50000; xent: 1.58; lr: 0.0000095; 103 docs/s;  13918 sec
[2020-07-23 22:10:36,586 INFO] Step 44600/50000; xent: 1.51; lr: 0.0000095; 103 docs/s;  13933 sec
[2020-07-23 22:10:41,507 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.304.bert.pt, number of examples: 1996
[2020-07-23 22:10:51,801 INFO] Step 44650/50000; xent: 1.57; lr: 0.0000095; 104 docs/s;  13948 sec
[2020-07-23 22:11:07,155 INFO] Step 44700/50000; xent: 1.51; lr: 0.0000095; 103 docs/s;  13963 sec
[2020-07-23 22:11:20,254 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.819.bert.pt, number of examples: 1995
[2020-07-23 22:11:22,392 INFO] Step 44750/50000; xent: 1.42; lr: 0.0000095; 104 docs/s;  13979 sec
[2020-07-23 22:11:37,685 INFO] Step 44800/50000; xent: 1.41; lr: 0.0000094; 104 docs/s;  13994 sec
[2020-07-23 22:11:52,909 INFO] Step 44850/50000; xent: 1.40; lr: 0.0000094; 103 docs/s;  14009 sec
[2020-07-23 22:11:58,745 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.697.bert.pt, number of examples: 2000
[2020-07-23 22:12:08,211 INFO] Step 44900/50000; xent: 1.39; lr: 0.0000094; 102 docs/s;  14024 sec
[2020-07-23 22:12:23,541 INFO] Step 44950/50000; xent: 1.51; lr: 0.0000094; 103 docs/s;  14040 sec
[2020-07-23 22:12:37,739 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.588.bert.pt, number of examples: 1998
[2020-07-23 22:12:38,954 INFO] Step 45000/50000; xent: 1.47; lr: 0.0000094; 102 docs/s;  14055 sec
[2020-07-23 22:12:38,955 INFO] Saving checkpoint ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:12:55,045 INFO] Step 45050/50000; xent: 1.48; lr: 0.0000094;  95 docs/s;  14071 sec
[2020-07-23 22:13:10,441 INFO] Step 45100/50000; xent: 1.49; lr: 0.0000094; 102 docs/s;  14087 sec
[2020-07-23 22:13:18,169 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.192.bert.pt, number of examples: 1997
[2020-07-23 22:13:25,735 INFO] Step 45150/50000; xent: 1.41; lr: 0.0000094; 101 docs/s;  14102 sec
[2020-07-23 22:13:40,954 INFO] Step 45200/50000; xent: 1.51; lr: 0.0000094; 103 docs/s;  14117 sec
[2020-07-23 22:13:56,332 INFO] Step 45250/50000; xent: 1.56; lr: 0.0000094; 103 docs/s;  14133 sec
[2020-07-23 22:13:57,237 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.250.bert.pt, number of examples: 1997
[2020-07-23 22:14:11,654 INFO] Step 45300/50000; xent: 1.54; lr: 0.0000094; 101 docs/s;  14148 sec
[2020-07-23 22:14:27,056 INFO] Step 45350/50000; xent: 1.48; lr: 0.0000094; 101 docs/s;  14163 sec
[2020-07-23 22:14:36,842 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.478.bert.pt, number of examples: 1996
[2020-07-23 22:14:42,378 INFO] Step 45400/50000; xent: 1.52; lr: 0.0000094; 101 docs/s;  14179 sec
[2020-07-23 22:14:57,684 INFO] Step 45450/50000; xent: 1.45; lr: 0.0000094; 102 docs/s;  14194 sec
[2020-07-23 22:15:12,932 INFO] Step 45500/50000; xent: 1.48; lr: 0.0000094; 102 docs/s;  14209 sec
[2020-07-23 22:15:15,731 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.933.bert.pt, number of examples: 1997
[2020-07-23 22:15:28,177 INFO] Step 45550/50000; xent: 1.55; lr: 0.0000094;  99 docs/s;  14224 sec
[2020-07-23 22:15:43,856 INFO] Step 45600/50000; xent: 1.49; lr: 0.0000094;  98 docs/s;  14240 sec
[2020-07-23 22:15:56,558 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.840.bert.pt, number of examples: 1992
[2020-07-23 22:15:59,378 INFO] Step 45650/50000; xent: 1.55; lr: 0.0000094;  98 docs/s;  14256 sec
[2020-07-23 22:16:14,630 INFO] Step 45700/50000; xent: 1.58; lr: 0.0000094; 104 docs/s;  14271 sec
[2020-07-23 22:16:29,930 INFO] Step 45750/50000; xent: 1.57; lr: 0.0000094; 105 docs/s;  14286 sec
[2020-07-23 22:16:34,475 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.324.bert.pt, number of examples: 1996
[2020-07-23 22:16:45,120 INFO] Step 45800/50000; xent: 1.44; lr: 0.0000093; 104 docs/s;  14301 sec
[2020-07-23 22:17:00,519 INFO] Step 45850/50000; xent: 1.49; lr: 0.0000093; 102 docs/s;  14317 sec
[2020-07-23 22:17:13,749 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.287.bert.pt, number of examples: 1999
[2020-07-23 22:17:16,220 INFO] Step 45900/50000; xent: 1.47; lr: 0.0000093; 100 docs/s;  14332 sec
[2020-07-23 22:17:31,597 INFO] Step 45950/50000; xent: 1.45; lr: 0.0000093; 102 docs/s;  14348 sec
[2020-07-23 22:17:46,814 INFO] Step 46000/50000; xent: 1.43; lr: 0.0000093; 103 docs/s;  14363 sec
[2020-07-23 22:17:52,739 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.676.bert.pt, number of examples: 1999
[2020-07-23 22:18:02,301 INFO] Step 46050/50000; xent: 1.51; lr: 0.0000093;  99 docs/s;  14379 sec
[2020-07-23 22:18:17,740 INFO] Step 46100/50000; xent: 1.51; lr: 0.0000093;  98 docs/s;  14394 sec
[2020-07-23 22:18:33,415 INFO] Step 46150/50000; xent: 1.49; lr: 0.0000093;  96 docs/s;  14410 sec
[2020-07-23 22:18:33,783 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.693.bert.pt, number of examples: 1998
[2020-07-23 22:18:49,073 INFO] Step 46200/50000; xent: 1.46; lr: 0.0000093;  99 docs/s;  14425 sec
[2020-07-23 22:19:04,644 INFO] Step 46250/50000; xent: 1.47; lr: 0.0000093; 100 docs/s;  14441 sec
[2020-07-23 22:19:14,011 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.46.bert.pt, number of examples: 1991
[2020-07-23 22:19:20,169 INFO] Step 46300/50000; xent: 1.48; lr: 0.0000093; 101 docs/s;  14456 sec
[2020-07-23 22:19:35,615 INFO] Step 46350/50000; xent: 1.54; lr: 0.0000093; 101 docs/s;  14472 sec
[2020-07-23 22:19:51,083 INFO] Step 46400/50000; xent: 1.47; lr: 0.0000093; 101 docs/s;  14487 sec
[2020-07-23 22:19:53,273 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.764.bert.pt, number of examples: 1999
[2020-07-23 22:20:06,534 INFO] Step 46450/50000; xent: 1.53; lr: 0.0000093; 101 docs/s;  14503 sec
[2020-07-23 22:20:21,866 INFO] Step 46500/50000; xent: 1.52; lr: 0.0000093; 104 docs/s;  14518 sec
[2020-07-23 22:20:32,092 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.556.bert.pt, number of examples: 1992
[2020-07-23 22:20:37,279 INFO] Step 46550/50000; xent: 1.51; lr: 0.0000093; 103 docs/s;  14534 sec
[2020-07-23 22:20:52,590 INFO] Step 46600/50000; xent: 1.48; lr: 0.0000093; 100 docs/s;  14549 sec
[2020-07-23 22:21:07,931 INFO] Step 46650/50000; xent: 1.48; lr: 0.0000093; 100 docs/s;  14564 sec
[2020-07-23 22:21:12,031 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.156.bert.pt, number of examples: 1992
[2020-07-23 22:21:23,345 INFO] Step 46700/50000; xent: 1.45; lr: 0.0000093; 100 docs/s;  14580 sec
[2020-07-23 22:21:38,641 INFO] Step 46750/50000; xent: 1.39; lr: 0.0000092; 103 docs/s;  14595 sec
[2020-07-23 22:21:51,215 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.975.bert.pt, number of examples: 1995
[2020-07-23 22:21:53,988 INFO] Step 46800/50000; xent: 1.43; lr: 0.0000092; 101 docs/s;  14610 sec
[2020-07-23 22:22:09,357 INFO] Step 46850/50000; xent: 1.55; lr: 0.0000092; 100 docs/s;  14626 sec
[2020-07-23 22:22:24,963 INFO] Step 46900/50000; xent: 1.44; lr: 0.0000092; 101 docs/s;  14641 sec
[2020-07-23 22:22:30,894 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.592.bert.pt, number of examples: 2001
[2020-07-23 22:22:40,576 INFO] Step 46950/50000; xent: 1.47; lr: 0.0000092;  99 docs/s;  14657 sec
[2020-07-23 22:22:56,257 INFO] Step 47000/50000; xent: 1.49; lr: 0.0000092; 102 docs/s;  14672 sec
[2020-07-23 22:23:10,716 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.61.bert.pt, number of examples: 1999
[2020-07-23 22:23:11,952 INFO] Step 47050/50000; xent: 1.43; lr: 0.0000092; 100 docs/s;  14688 sec
[2020-07-23 22:23:27,583 INFO] Step 47100/50000; xent: 1.55; lr: 0.0000092; 101 docs/s;  14704 sec
[2020-07-23 22:23:43,343 INFO] Step 47150/50000; xent: 1.46; lr: 0.0000092; 100 docs/s;  14720 sec
[2020-07-23 22:23:50,542 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.234.bert.pt, number of examples: 1999
[2020-07-23 22:23:58,995 INFO] Step 47200/50000; xent: 1.54; lr: 0.0000092;  99 docs/s;  14735 sec
[2020-07-23 22:24:14,837 INFO] Step 47250/50000; xent: 1.62; lr: 0.0000092; 100 docs/s;  14751 sec
[2020-07-23 22:24:30,338 INFO] Step 47300/50000; xent: 1.66; lr: 0.0000092; 100 docs/s;  14767 sec
[2020-07-23 22:24:30,692 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.793.bert.pt, number of examples: 1996
[2020-07-23 22:24:45,878 INFO] Step 47350/50000; xent: 1.61; lr: 0.0000092;  98 docs/s;  14782 sec
[2020-07-23 22:25:01,396 INFO] Step 47400/50000; xent: 1.62; lr: 0.0000092;  98 docs/s;  14798 sec
[2020-07-23 22:25:11,400 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.696.bert.pt, number of examples: 1998
[2020-07-23 22:25:16,997 INFO] Step 47450/50000; xent: 1.52; lr: 0.0000092;  99 docs/s;  14813 sec
[2020-07-23 22:25:32,408 INFO] Step 47500/50000; xent: 1.44; lr: 0.0000092; 101 docs/s;  14829 sec
[2020-07-23 22:25:47,787 INFO] Step 47550/50000; xent: 1.47; lr: 0.0000092; 102 docs/s;  14844 sec
[2020-07-23 22:25:50,885 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.745.bert.pt, number of examples: 1998
[2020-07-23 22:26:03,360 INFO] Step 47600/50000; xent: 1.40; lr: 0.0000092; 100 docs/s;  14860 sec
[2020-07-23 22:26:18,868 INFO] Step 47650/50000; xent: 1.36; lr: 0.0000092; 100 docs/s;  14875 sec
[2020-07-23 22:26:30,806 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.861.bert.pt, number of examples: 2001
[2020-07-23 22:26:34,605 INFO] Step 47700/50000; xent: 1.34; lr: 0.0000092; 100 docs/s;  14891 sec
[2020-07-23 22:26:50,321 INFO] Step 47750/50000; xent: 1.46; lr: 0.0000092; 101 docs/s;  14907 sec
[2020-07-23 22:27:05,721 INFO] Step 47800/50000; xent: 1.42; lr: 0.0000091; 102 docs/s;  14922 sec
[2020-07-23 22:27:10,604 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.868.bert.pt, number of examples: 2000
[2020-07-23 22:27:21,469 INFO] Step 47850/50000; xent: 1.55; lr: 0.0000091; 100 docs/s;  14938 sec
[2020-07-23 22:27:37,147 INFO] Step 47900/50000; xent: 1.51; lr: 0.0000091;  99 docs/s;  14953 sec
[2020-07-23 22:27:50,547 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.618.bert.pt, number of examples: 1996
[2020-07-23 22:27:52,778 INFO] Step 47950/50000; xent: 1.56; lr: 0.0000091; 100 docs/s;  14969 sec
[2020-07-23 22:28:08,358 INFO] Step 48000/50000; xent: 1.60; lr: 0.0000091; 100 docs/s;  14985 sec
[2020-07-23 22:28:24,068 INFO] Step 48050/50000; xent: 1.61; lr: 0.0000091; 100 docs/s;  15000 sec
[2020-07-23 22:28:30,615 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.375.bert.pt, number of examples: 1989
[2020-07-23 22:28:39,708 INFO] Step 48100/50000; xent: 1.62; lr: 0.0000091;  98 docs/s;  15016 sec
[2020-07-23 22:28:55,630 INFO] Step 48150/50000; xent: 1.53; lr: 0.0000091;  97 docs/s;  15032 sec
[2020-07-23 22:29:11,275 INFO] Step 48200/50000; xent: 1.56; lr: 0.0000091;  99 docs/s;  15047 sec
[2020-07-23 22:29:11,320 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.658.bert.pt, number of examples: 1999
[2020-07-23 22:29:27,350 INFO] Step 48250/50000; xent: 1.59; lr: 0.0000091;  95 docs/s;  15064 sec
[2020-07-23 22:29:42,869 INFO] Step 48300/50000; xent: 1.61; lr: 0.0000091;  97 docs/s;  15079 sec
[2020-07-23 22:29:52,852 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.711.bert.pt, number of examples: 1999
[2020-07-23 22:29:58,412 INFO] Step 48350/50000; xent: 1.61; lr: 0.0000091;  97 docs/s;  15095 sec
[2020-07-23 22:30:13,923 INFO] Step 48400/50000; xent: 1.59; lr: 0.0000091; 100 docs/s;  15110 sec
[2020-07-23 22:30:29,435 INFO] Step 48450/50000; xent: 1.54; lr: 0.0000091; 100 docs/s;  15126 sec
[2020-07-23 22:30:32,839 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.763.bert.pt, number of examples: 1998
[2020-07-23 22:30:44,865 INFO] Step 48500/50000; xent: 1.67; lr: 0.0000091; 102 docs/s;  15141 sec
[2020-07-23 22:31:00,254 INFO] Step 48550/50000; xent: 1.58; lr: 0.0000091; 103 docs/s;  15156 sec
[2020-07-23 22:31:11,733 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.92.bert.pt, number of examples: 1995
[2020-07-23 22:31:15,864 INFO] Step 48600/50000; xent: 1.60; lr: 0.0000091; 101 docs/s;  15172 sec
[2020-07-23 22:31:31,404 INFO] Step 48650/50000; xent: 1.48; lr: 0.0000091;  99 docs/s;  15188 sec
[2020-07-23 22:31:47,059 INFO] Step 48700/50000; xent: 1.41; lr: 0.0000091; 100 docs/s;  15203 sec
[2020-07-23 22:31:52,040 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.683.bert.pt, number of examples: 1995
[2020-07-23 22:32:02,430 INFO] Step 48750/50000; xent: 1.52; lr: 0.0000091; 100 docs/s;  15219 sec
[2020-07-23 22:32:17,998 INFO] Step 48800/50000; xent: 1.46; lr: 0.0000091; 100 docs/s;  15234 sec
[2020-07-23 22:32:32,289 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.353.bert.pt, number of examples: 1996
[2020-07-23 22:32:33,516 INFO] Step 48850/50000; xent: 1.52; lr: 0.0000090;  98 docs/s;  15250 sec
[2020-07-23 22:32:48,954 INFO] Step 48900/50000; xent: 1.40; lr: 0.0000090; 102 docs/s;  15265 sec
[2020-07-23 22:33:04,817 INFO] Step 48950/50000; xent: 1.46; lr: 0.0000090; 101 docs/s;  15281 sec
[2020-07-23 22:33:05,066 INFO] Device ID 0
[2020-07-23 22:33:05,066 INFO] Device cuda
[2020-07-23 22:33:05,081 INFO] Loading checkpoint from ./models/models_check_points/model_step_10000.pt
[2020-07-23 22:33:11,532 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.246.bert.pt, number of examples: 1998
[2020-07-23 22:33:18,770 INFO] Device ID 0
[2020-07-23 22:33:18,770 INFO] Device cuda
[2020-07-23 22:33:18,790 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:33:20,729 INFO] Step 49000/50000; xent: 1.51; lr: 0.0000090;  99 docs/s;  15297 sec
[2020-07-23 22:33:21,448 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 22:33:21,452 INFO] * number of parameters: 113297921
[2020-07-23 22:33:36,612 INFO] Step 49050/50000; xent: 1.56; lr: 0.0000090;  96 docs/s;  15313 sec
[2020-07-23 22:33:51,856 INFO] Device ID 0
[2020-07-23 22:33:51,856 INFO] Device cuda
[2020-07-23 22:33:51,874 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:33:52,422 INFO] Step 49100/50000; xent: 1.57; lr: 0.0000090;  98 docs/s;  15329 sec
[2020-07-23 22:33:52,813 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.558.bert.pt, number of examples: 1996
[2020-07-23 22:33:54,514 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 22:33:54,518 INFO] * number of parameters: 113297921
[2020-07-23 22:34:08,248 INFO] Step 49150/50000; xent: 1.44; lr: 0.0000090;  97 docs/s;  15344 sec
[2020-07-23 22:34:23,815 INFO] Step 49200/50000; xent: 1.44; lr: 0.0000090;  97 docs/s;  15360 sec
[2020-07-23 22:34:27,062 INFO] Device ID 0
[2020-07-23 22:34:27,062 INFO] Device cuda
[2020-07-23 22:34:27,077 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:34:29,746 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 22:34:29,751 INFO] * number of parameters: 113297921
[2020-07-23 22:34:34,305 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.874.bert.pt, number of examples: 2001
[2020-07-23 22:34:39,562 INFO] Step 49250/50000; xent: 1.53; lr: 0.0000090;  97 docs/s;  15376 sec
[2020-07-23 22:34:54,791 INFO] Step 49300/50000; xent: 1.61; lr: 0.0000090; 102 docs/s;  15391 sec
[2020-07-23 22:35:10,221 INFO] Step 49350/50000; xent: 1.52; lr: 0.0000090; 101 docs/s;  15406 sec
[2020-07-23 22:35:13,649 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.21.bert.pt, number of examples: 1999
[2020-07-23 22:35:25,580 INFO] Step 49400/50000; xent: 1.46; lr: 0.0000090; 102 docs/s;  15422 sec
[2020-07-23 22:35:41,101 INFO] Step 49450/50000; xent: 1.42; lr: 0.0000090; 103 docs/s;  15437 sec
[2020-07-23 22:35:53,255 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.269.bert.pt, number of examples: 1999
[2020-07-23 22:35:56,647 INFO] Step 49500/50000; xent: 1.41; lr: 0.0000090;  99 docs/s;  15453 sec
[2020-07-23 22:36:12,806 INFO] Step 49550/50000; xent: 1.39; lr: 0.0000090;  98 docs/s;  15469 sec
[2020-07-23 22:36:28,288 INFO] Step 49600/50000; xent: 1.46; lr: 0.0000090; 102 docs/s;  15485 sec
[2020-07-23 22:36:33,017 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.57.bert.pt, number of examples: 1997
[2020-07-23 22:36:44,016 INFO] Step 49650/50000; xent: 1.50; lr: 0.0000090;  99 docs/s;  15500 sec
[2020-07-23 22:36:59,538 INFO] Step 49700/50000; xent: 1.43; lr: 0.0000090; 102 docs/s;  15516 sec
[2020-07-23 22:37:12,803 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.771.bert.pt, number of examples: 1997
[2020-07-23 22:37:14,958 INFO] Step 49750/50000; xent: 1.51; lr: 0.0000090; 101 docs/s;  15531 sec
[2020-07-23 22:37:30,458 INFO] Step 49800/50000; xent: 1.53; lr: 0.0000090; 103 docs/s;  15547 sec
[2020-07-23 22:37:46,272 INFO] Step 49850/50000; xent: 1.60; lr: 0.0000090; 101 docs/s;  15562 sec
[2020-07-23 22:37:52,213 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.582.bert.pt, number of examples: 2000
[2020-07-23 22:38:01,806 INFO] Step 49900/50000; xent: 1.61; lr: 0.0000090; 100 docs/s;  15578 sec
[2020-07-23 22:38:17,112 INFO] Step 49950/50000; xent: 1.63; lr: 0.0000089; 100 docs/s;  15593 sec
[2020-07-23 22:38:31,881 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.773.bert.pt, number of examples: 1997
[2020-07-23 22:38:32,484 INFO] Step 50000/50000; xent: 1.65; lr: 0.0000089; 101 docs/s;  15609 sec
[2020-07-23 22:38:32,486 INFO] Saving checkpoint ./models/models_check_points/model_step_50000.pt
[2020-07-23 22:38:33,280 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.731.bert.pt, number of examples: 1990
[2020-07-23 22:57:45,955 INFO] Device ID 0
[2020-07-23 22:57:45,955 INFO] Device cuda
[2020-07-23 22:57:45,968 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:57:48,264 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 22:57:48,267 INFO] * number of parameters: 113297921
[2020-07-23 22:58:06,811 INFO] Device ID 0
[2020-07-23 22:58:06,811 INFO] Device cuda
[2020-07-23 22:58:06,823 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 22:58:09,110 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 22:58:09,113 INFO] * number of parameters: 113297921
[2020-07-23 23:03:10,081 INFO] Device ID 0
[2020-07-23 23:03:10,081 INFO] Device cuda
[2020-07-23 23:03:10,094 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 23:03:12,383 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 23:03:12,386 INFO] * number of parameters: 113297921
[2020-07-23 23:03:51,660 INFO] Device ID 0
[2020-07-23 23:03:51,660 INFO] Device cuda
[2020-07-23 23:03:51,674 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 23:03:53,957 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 23:03:53,960 INFO] * number of parameters: 113297921
[2020-07-23 23:04:10,537 INFO] Device ID 0
[2020-07-23 23:04:10,537 INFO] Device cuda
[2020-07-23 23:04:10,550 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 23:04:12,838 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 23:04:12,841 INFO] * number of parameters: 113297921
[2020-07-23 23:04:47,951 INFO] Device ID 0
[2020-07-23 23:04:47,951 INFO] Device cuda
[2020-07-23 23:04:47,964 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-23 23:04:50,296 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-23 23:04:50,299 INFO] * number of parameters: 113297921
[2020-07-24 01:52:10,492 INFO] Device ID 0
[2020-07-24 01:52:10,493 INFO] Device cuda
[2020-07-24 01:52:10,506 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-24 01:52:12,775 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 1997
[2020-07-24 01:52:12,778 INFO] * number of parameters: 113297921
[2020-07-24 01:52:23,784 INFO] Validation xent: 3.07742 at step 45000
[2020-07-24 02:03:39,722 INFO] Device ID 0
[2020-07-24 02:03:39,722 INFO] Device cuda
[2020-07-24 02:03:39,735 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-24 02:04:01,746 INFO] Device ID 0
[2020-07-24 02:04:01,746 INFO] Device cuda
[2020-07-24 02:04:01,759 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-24 02:04:04,023 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 0
[2020-07-24 02:04:04,026 INFO] * number of parameters: 113297921
[2020-07-24 02:04:04,048 INFO] Validation xent: 0 at step 45000
[2020-07-24 02:08:49,129 INFO] Device ID 0
[2020-07-24 02:08:49,129 INFO] Device cuda
[2020-07-24 02:08:49,141 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-24 02:09:08,332 INFO] Device ID 0
[2020-07-24 02:09:08,332 INFO] Device cuda
[2020-07-24 02:09:08,345 INFO] Loading checkpoint from ./models/models_check_points/model_step_45000.pt
[2020-07-24 02:09:10,580 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 700
[2020-07-24 02:09:10,583 INFO] * number of parameters: 113297921
[2020-07-24 02:09:15,268 INFO] Validation xent: 4.00068 at step 45000
[2020-07-24 02:28:55,139 INFO] Device ID 0
[2020-07-24 02:28:55,139 INFO] Device cuda
[2020-07-24 02:28:55,152 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 02:28:57,387 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 700
[2020-07-24 02:28:57,390 INFO] * number of parameters: 113297921
[2020-07-24 02:29:01,982 INFO] Validation xent: 4.27323 at step 50000
[2020-07-24 02:29:58,106 INFO] Device ID 0
[2020-07-24 02:29:58,106 INFO] Device cuda
[2020-07-24 02:29:58,118 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 02:30:17,411 INFO] Device ID 0
[2020-07-24 02:30:17,411 INFO] Device cuda
[2020-07-24 02:30:17,424 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 02:30:19,667 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 726
[2020-07-24 02:30:19,670 INFO] * number of parameters: 113297921
[2020-07-24 02:30:24,235 INFO] Validation xent: 4.47228 at step 50000
[2020-07-24 02:34:58,079 INFO] Device ID 0
[2020-07-24 02:34:58,079 INFO] Device cuda
[2020-07-24 02:34:58,091 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 02:35:00,363 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 726
[2020-07-24 02:35:00,366 INFO] * number of parameters: 113297921
[2020-07-24 02:35:04,930 INFO] Validation xent: 4.47228 at step 50000
[2020-07-24 02:50:35,994 INFO] Device ID 0
[2020-07-24 02:50:35,994 INFO] Device cuda
[2020-07-24 02:50:36,009 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 02:50:38,463 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 02:50:38,466 INFO] * number of parameters: 113297921
[2020-07-24 02:52:34,220 INFO] Validation xent: 5.24907 at step 50000
[2020-07-24 03:05:26,712 INFO] Device ID 0
[2020-07-24 03:05:26,712 INFO] Device cuda
[2020-07-24 03:05:26,724 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:05:29,208 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:05:29,211 INFO] * number of parameters: 113297921
[2020-07-24 03:05:58,186 INFO] Device ID 0
[2020-07-24 03:05:58,186 INFO] Device cuda
[2020-07-24 03:05:58,198 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:06:00,635 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:06:00,638 INFO] * number of parameters: 113297921
[2020-07-24 03:09:02,335 INFO] Device ID 0
[2020-07-24 03:09:02,335 INFO] Device cuda
[2020-07-24 03:09:02,348 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:09:04,819 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:09:04,822 INFO] * number of parameters: 113297921
[2020-07-24 03:13:04,344 INFO] Device ID 0
[2020-07-24 03:13:04,344 INFO] Device cuda
[2020-07-24 03:13:04,357 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:13:06,863 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:13:06,866 INFO] * number of parameters: 113297921
[2020-07-24 03:15:02,801 INFO] Validation xent: 5.24907 at step 50000
[2020-07-24 03:16:50,072 INFO] Device ID 0
[2020-07-24 03:16:50,072 INFO] Device cuda
[2020-07-24 03:16:50,085 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:18:04,824 INFO] Device ID 0
[2020-07-24 03:18:04,824 INFO] Device cuda
[2020-07-24 03:18:04,837 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:18:07,329 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:18:07,332 INFO] * number of parameters: 113297921
[2020-07-24 03:19:31,927 INFO] Device ID 0
[2020-07-24 03:19:31,928 INFO] Device cuda
[2020-07-24 03:19:31,940 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:19:34,393 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:19:34,396 INFO] * number of parameters: 113297921
[2020-07-24 03:19:53,354 INFO] Device ID 0
[2020-07-24 03:19:53,354 INFO] Device cuda
[2020-07-24 03:19:53,366 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:19:55,808 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:19:55,811 INFO] * number of parameters: 113297921
[2020-07-24 03:22:29,764 INFO] Device ID 0
[2020-07-24 03:22:29,764 INFO] Device cuda
[2020-07-24 03:22:29,777 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:22:32,237 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:22:32,239 INFO] * number of parameters: 113297921
[2020-07-24 03:22:44,228 INFO] Device ID 0
[2020-07-24 03:22:44,228 INFO] Device cuda
[2020-07-24 03:22:44,240 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:22:46,778 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:22:46,781 INFO] * number of parameters: 113297921
[2020-07-24 03:23:08,911 INFO] Device ID 0
[2020-07-24 03:23:08,911 INFO] Device cuda
[2020-07-24 03:23:08,925 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:23:11,398 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:23:11,401 INFO] * number of parameters: 113297921
[2020-07-24 03:23:28,331 INFO] Device ID 0
[2020-07-24 03:23:28,331 INFO] Device cuda
[2020-07-24 03:23:28,344 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:23:30,824 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:23:30,827 INFO] * number of parameters: 113297921
[2020-07-24 03:23:41,852 INFO] Device ID 0
[2020-07-24 03:23:41,852 INFO] Device cuda
[2020-07-24 03:23:41,863 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:23:44,322 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:23:44,325 INFO] * number of parameters: 113297921
[2020-07-24 03:25:04,669 INFO] Device ID 0
[2020-07-24 03:25:04,670 INFO] Device cuda
[2020-07-24 03:25:04,686 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:25:07,173 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:25:07,176 INFO] * number of parameters: 113297921
[2020-07-24 03:27:12,059 INFO] Device ID 0
[2020-07-24 03:27:12,060 INFO] Device cuda
[2020-07-24 03:27:12,072 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 03:27:14,521 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 03:27:14,524 INFO] * number of parameters: 113297921
[2020-07-24 03:29:10,348 INFO] Validation xent: 5.24907 at step 50000
[2020-07-24 12:05:36,984 INFO] Device ID 0
[2020-07-24 12:05:36,984 INFO] Device cuda
[2020-07-24 12:05:37,069 INFO] loading archive file ./models/pytorch_pretrained_bert/bert_pretrain/
[2020-07-24 12:05:37,069 INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[2020-07-24 12:05:39,497 INFO] Summarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): BertLayerNorm()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): BertLayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (encoder): TransformerInterEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2020-07-24 12:05:39,512 INFO] * number of parameters: 113297921
[2020-07-24 12:05:39,512 INFO] Start training...
[2020-07-24 12:05:39,528 INFO] Loading train dataset from ./data/bert_data\chinese_summary.train.177.bert.pt, number of examples: 1999
[2020-07-24 12:13:09,696 INFO] Device ID 0
[2020-07-24 12:13:09,696 INFO] Device cuda
[2020-07-24 12:13:09,774 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 12:13:12,623 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 18965
[2020-07-24 12:13:12,623 INFO] * number of parameters: 113297921
[2020-07-24 12:14:49,741 INFO] Validation xent: 5.24907 at step 50000
[2020-07-24 12:21:37,769 INFO] Device ID 0
[2020-07-24 12:21:37,769 INFO] Device cuda
[2020-07-24 12:21:37,847 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 12:39:08,599 INFO] Device ID 0
[2020-07-24 12:39:08,599 INFO] Device cuda
[2020-07-24 12:39:08,677 INFO] Loading checkpoint from ./models/models_check_points/model_step_50000.pt
[2020-07-24 12:39:11,396 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.0.bert.pt, number of examples: 10000
[2020-07-24 12:39:11,396 INFO] * number of parameters: 113297921
[2020-07-24 12:40:03,698 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.1.bert.pt, number of examples: 10000
[2020-07-24 12:40:54,125 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.10.bert.pt, number of examples: 10000
[2020-07-24 12:41:46,279 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.100.bert.pt, number of examples: 10000
[2020-07-24 12:42:38,866 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.101.bert.pt, number of examples: 10000
[2020-07-24 12:43:30,702 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.102.bert.pt, number of examples: 10000
[2020-07-24 12:44:22,838 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.103.bert.pt, number of examples: 5636
[2020-07-24 12:44:52,854 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.11.bert.pt, number of examples: 10000
[2020-07-24 12:45:45,530 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.12.bert.pt, number of examples: 10000
[2020-07-24 12:46:38,968 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.13.bert.pt, number of examples: 10000
[2020-07-24 12:47:31,635 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.14.bert.pt, number of examples: 10000
[2020-07-24 12:48:24,001 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.15.bert.pt, number of examples: 10000
[2020-07-24 12:49:17,404 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.16.bert.pt, number of examples: 10000
[2020-07-24 12:50:11,665 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.17.bert.pt, number of examples: 10000
[2020-07-24 12:51:05,203 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.18.bert.pt, number of examples: 10000
[2020-07-24 12:51:59,542 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.19.bert.pt, number of examples: 10000
[2020-07-24 12:52:53,819 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.2.bert.pt, number of examples: 10000
[2020-07-24 12:53:48,362 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.20.bert.pt, number of examples: 10000
[2020-07-24 12:54:41,526 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.21.bert.pt, number of examples: 10000
[2020-07-24 12:55:34,887 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.22.bert.pt, number of examples: 10000
[2020-07-24 12:56:28,386 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.23.bert.pt, number of examples: 10000
[2020-07-24 12:57:25,160 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.24.bert.pt, number of examples: 10000
[2020-07-24 12:58:21,846 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.25.bert.pt, number of examples: 10000
[2020-07-24 12:59:17,826 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.26.bert.pt, number of examples: 10000
[2020-07-24 13:00:13,788 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.27.bert.pt, number of examples: 10000
[2020-07-24 13:01:09,486 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.28.bert.pt, number of examples: 10000
[2020-07-24 13:02:03,930 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.29.bert.pt, number of examples: 10000
[2020-07-24 13:02:58,146 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.3.bert.pt, number of examples: 10000
[2020-07-24 13:03:50,946 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.30.bert.pt, number of examples: 10000
[2020-07-24 13:04:44,101 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.31.bert.pt, number of examples: 10000
[2020-07-24 13:05:38,677 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.32.bert.pt, number of examples: 10000
[2020-07-24 13:06:32,515 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.33.bert.pt, number of examples: 10000
[2020-07-24 13:07:24,314 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.34.bert.pt, number of examples: 10000
[2020-07-24 13:08:16,808 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.35.bert.pt, number of examples: 10000
[2020-07-24 13:09:09,508 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.36.bert.pt, number of examples: 10000
[2020-07-24 13:10:02,296 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.37.bert.pt, number of examples: 10000
[2020-07-24 13:10:55,081 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.38.bert.pt, number of examples: 10000
[2020-07-24 13:11:49,209 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.39.bert.pt, number of examples: 10000
[2020-07-24 13:12:41,791 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.4.bert.pt, number of examples: 10000
[2020-07-24 13:13:35,756 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.40.bert.pt, number of examples: 10000
[2020-07-24 13:14:28,928 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.41.bert.pt, number of examples: 10000
[2020-07-24 13:15:21,610 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.42.bert.pt, number of examples: 10000
[2020-07-24 13:16:14,142 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.43.bert.pt, number of examples: 10000
[2020-07-24 13:17:08,161 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.44.bert.pt, number of examples: 10000
[2020-07-24 13:18:01,335 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.45.bert.pt, number of examples: 10000
[2020-07-24 13:18:54,424 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.46.bert.pt, number of examples: 10000
[2020-07-24 13:19:47,108 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.47.bert.pt, number of examples: 10000
[2020-07-24 13:20:40,666 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.48.bert.pt, number of examples: 10000
[2020-07-24 13:21:32,631 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.49.bert.pt, number of examples: 10000
[2020-07-24 13:22:24,380 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.5.bert.pt, number of examples: 10000
[2020-07-24 13:23:15,174 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.50.bert.pt, number of examples: 10000
[2020-07-24 13:24:07,167 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.51.bert.pt, number of examples: 10000
[2020-07-24 13:24:58,798 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.52.bert.pt, number of examples: 10000
[2020-07-24 13:25:51,856 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.53.bert.pt, number of examples: 10000
[2020-07-24 13:26:44,002 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.54.bert.pt, number of examples: 10000
[2020-07-24 13:27:38,912 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.55.bert.pt, number of examples: 10000
[2020-07-24 13:28:32,031 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.56.bert.pt, number of examples: 10000
[2020-07-24 13:29:25,554 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.57.bert.pt, number of examples: 10000
[2020-07-24 13:30:19,240 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.58.bert.pt, number of examples: 10000
[2020-07-24 13:31:12,517 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.59.bert.pt, number of examples: 10000
[2020-07-24 13:32:04,910 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.6.bert.pt, number of examples: 10000
[2020-07-24 13:32:56,299 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.60.bert.pt, number of examples: 10000
[2020-07-24 13:33:47,593 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.61.bert.pt, number of examples: 10000
[2020-07-24 13:34:39,049 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.62.bert.pt, number of examples: 10000
[2020-07-24 13:35:30,807 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.63.bert.pt, number of examples: 10000
[2020-07-24 13:36:22,238 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.64.bert.pt, number of examples: 10000
[2020-07-24 13:37:15,253 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.65.bert.pt, number of examples: 10000
[2020-07-24 13:38:07,589 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.66.bert.pt, number of examples: 10000
[2020-07-24 13:38:59,645 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.67.bert.pt, number of examples: 10000
[2020-07-24 13:39:51,779 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.68.bert.pt, number of examples: 10000
[2020-07-24 13:40:45,344 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.69.bert.pt, number of examples: 10000
[2020-07-24 13:41:38,240 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.7.bert.pt, number of examples: 10000
[2020-07-24 13:42:30,570 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.70.bert.pt, number of examples: 10000
[2020-07-24 13:43:23,540 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.71.bert.pt, number of examples: 10000
[2020-07-24 13:44:16,865 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.72.bert.pt, number of examples: 10000
[2020-07-24 13:45:09,463 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.73.bert.pt, number of examples: 10000
[2020-07-24 13:46:02,468 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.74.bert.pt, number of examples: 10000
[2020-07-24 13:46:54,679 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.75.bert.pt, number of examples: 10000
[2020-07-24 13:47:46,503 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.76.bert.pt, number of examples: 10000
[2020-07-24 13:48:39,790 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.77.bert.pt, number of examples: 10000
[2020-07-24 13:49:33,229 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.78.bert.pt, number of examples: 10000
[2020-07-24 13:50:24,626 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.79.bert.pt, number of examples: 10000
[2020-07-24 13:51:15,796 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.8.bert.pt, number of examples: 10000
[2020-07-24 13:52:08,434 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.80.bert.pt, number of examples: 10000
[2020-07-24 13:53:00,394 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.81.bert.pt, number of examples: 10000
[2020-07-24 13:53:51,880 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.82.bert.pt, number of examples: 10000
[2020-07-24 13:54:42,829 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.83.bert.pt, number of examples: 10000
[2020-07-24 13:55:34,547 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.84.bert.pt, number of examples: 10000
[2020-07-24 13:56:26,083 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.85.bert.pt, number of examples: 10000
[2020-07-24 13:57:17,478 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.86.bert.pt, number of examples: 10000
[2020-07-24 13:58:08,790 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.87.bert.pt, number of examples: 10000
[2020-07-24 13:59:00,197 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.88.bert.pt, number of examples: 10000
[2020-07-24 13:59:52,955 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.89.bert.pt, number of examples: 10000
[2020-07-24 14:00:44,444 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.9.bert.pt, number of examples: 10000
[2020-07-24 14:01:36,046 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.90.bert.pt, number of examples: 10000
[2020-07-24 14:02:27,360 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.91.bert.pt, number of examples: 10000
[2020-07-24 14:03:19,117 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.92.bert.pt, number of examples: 10000
[2020-07-24 14:04:10,803 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.93.bert.pt, number of examples: 10000
[2020-07-24 14:05:03,696 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.94.bert.pt, number of examples: 10000
[2020-07-24 14:05:55,857 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.95.bert.pt, number of examples: 10000
[2020-07-24 14:06:47,474 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.96.bert.pt, number of examples: 10000
[2020-07-24 14:07:39,544 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.97.bert.pt, number of examples: 10000
[2020-07-24 14:08:31,726 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.98.bert.pt, number of examples: 10000
[2020-07-24 14:09:24,299 INFO] Loading test dataset from ./data/predict_data\chinese_summary.test.99.bert.pt, number of examples: 10000
[2020-07-24 14:10:17,860 INFO] Validation xent: 4.98524 at step 50000
